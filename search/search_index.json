{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sparse","text":"<p>This implements sparse arrays of arbitrary dimension on top of numpy and scipy.sparse. It generalizes the scipy.sparse.coo_matrix and scipy.sparse.dok_matrix layouts, but extends beyond just rows and columns to an arbitrary number of dimensions.</p> <p>Additionally, this project maintains compatibility with the numpy.ndarray interface rather than the numpy.matrix interface used in scipy.sparse</p> <p>These differences make this project useful in certain situations where scipy.sparse matrices are not well suited, but it should not be considered a full replacement. The data structures in pydata/sparse complement and can be used in conjunction with the fast linear algebra routines inside scipy.sparse. A format conversion or copy may be required.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>Sparse arrays, or arrays that are mostly empty or filled with zeros, are common in many scientific applications. To save space we often avoid storing these arrays in traditional dense formats, and instead choose different data structures. Our choice of data structure can significantly affect our storage and computational costs when working with these arrays.</p>"},{"location":"#design","title":"Design","text":"<p>The main data structure in this library follows the Coordinate List (COO) layout for sparse matrices, but extends it to multiple dimensions.</p> <p>The COO layout, which stores the row index, column index, and value of every element:</p> row col data 0 0 10 0 2 13 1 3 9 3 8 21 <p>It is straightforward to extend the COO layout to an arbitrary number of dimensions:</p> dim1 dim2 dim3 ... data 0 0 0 . 10 0 0 3 . 13 0 2 2 . 9 3 1 4 . 21 <p>This makes it easy to store a multidimensional sparse array, but we still need to reimplement all of the array operations like transpose, reshape, slicing, tensordot, reductions, etc., which can be challenging in general.</p> <p>This library also includes several other data structures. Similar to COO, the Dictionary of Keys (DOK) format for sparse matrices generalizes well to an arbitrary number of dimensions. DOK is well-suited for writing and mutating. Most other operations are not supported for DOK. A common workflow may involve writing an array with DOK and then converting to another format for other operations.</p> <p>The Compressed Sparse Row/Column (CSR/CSC) formats are widely used in scientific computing are now supported by pydata/sparse. The CSR/CSC formats excel at compression and mathematical operations. While these formats are restricted to two dimensions, pydata/sparse supports the GCXS sparse array format, based on GCRS/GCCS from which generalizes CSR/CSC to n-dimensional arrays. Like their two-dimensional CSR/CSC counterparts, GCXS arrays compress well. Whereas the storage cost of COO depends heavily on the number of dimensions of the array, the number of dimensions only minimally affects the storage cost of GCXS arrays, which results in favorable compression ratios across many use cases.</p> <p>Together these formats cover a wide array of applications of sparsity. Additionally, with each format complying with the numpy.ndarray interface and following the appropriate dispatching protocols, pydata/sparse arrays can interact with other array libraries and seamlessly take part in pydata-ecosystem-based workflows.</p>"},{"location":"#license","title":"LICENSE","text":"<p>This library is licensed under BSD-3</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#0151-2024-01-10","title":"0.15.1 / 2024-01-10","text":"<ul> <li>Fix regression where with XArray by supporting all API functions via the Array API standard. (:pr:<code>622</code> thanks :ghuser:<code>hameerabbasi</code>)</li> </ul>"},{"location":"changelog/#0150-2024-01-09","title":"0.15.0 / 2024-01-09","text":"<ul> <li>Fix regression where DeprecationWarnings were being fired unexpectedly. (PR581) thanks @hameerabbasi</li> <li>Extended :obj:<code>sparse.einsum</code> support (:pr:<code>579</code> thanks :ghuser:<code>HadrienNU</code>)</li> <li>General code clean-up (:pr:<code>586</code> thanks :ghuser:<code>MHRasmy</code>, :pr:<code>598</code> thanks :ghuser:<code>jamestwebber</code>)</li> <li>Bug fixes with respect to NumPy compatibility  (:pr:<code>598</code> thanks :ghuser:<code>hameerabbasi</code>, :pr:<code>609</code> thanks :ghuser:<code>Illviljan</code>, :pr:<code>620</code> thanks :ghuser:<code>mtsokol</code>)</li> <li>Bug fixes with respect to GCXS (:pr:<code>611</code> thanks :ghuser:<code>EuGig</code>, :pr:<code>601</code> thanks :ghuser:<code>jamestwebber</code>)</li> <li><code>Array API standard &lt;https://data-apis.org/array-api/latest/&gt;</code>_ support (:pr:<code>612</code>, :pr:<code>613</code>, :pr:<code>614</code>, :pr:<code>615</code>, :pr:<code>619</code>, :pr:<code>620</code> thanks :ghuser:<code>mtsokol</code>)</li> <li><code>matrepr</code> support for display of sparse data (:pr:<code>605</code>, :pr:<code>606</code> thanks :ghuser:<code>alugowski</code>).</li> <li>Larger code clean-up with Ruff formatter and linter (:pr:<code>617</code>, :pr:<code>621</code> thanks :ghuser:<code>hameerabbasi</code>)</li> <li>Packaging and maintenance (:pr:<code>616</code>, :commit:<code>b5954e68d3d6e35a62f7401d1d4fb84ea04414dd</code>, :commit:<code>dda93d3ea9521881c721c3ba875c769c9c5a79d4</code> thanks :ghuser:<code>hameerabbasi</code>)</li> </ul>"},{"location":"changelog/#0140-2023-02-24","title":"0.14.0 / 2023-02-24","text":"<ul> <li>:obj:<code>sparse.einsum</code> support (:pr:<code>564</code> thanks   :ghuser:<code>jcmgray</code>)</li> <li>Some bug-fixes (:pr:<code>524</code>, :pr:<code>527</code>, :pr:<code>555</code> thanks :ghuser:<code>hameerabbasi</code>, :pr:<code>569</code>, thanks :ghuser:<code>jamestwebber</code>, :pr:<code>534</code>, thanks :ghuser:<code>sarveshbhatnagar</code>)</li> <li>Some performance improvements (:pr:<code>570</code>, thanks :ghuser:<code>jamestwebber</code>, :pr:<code>540</code>, thanks :ghuser:<code>smldub</code>).</li> <li>Miscellaneous maintenance fixes.</li> </ul>"},{"location":"changelog/#0130-2021-08-28","title":"0.13.0 / 2021-08-28","text":"<ul> <li>GCXS improvements and changes. (:pr:<code>448</code>, :pr:<code>450</code>, :pr:<code>455</code>, thanks   :ghuser:<code>sayandip18</code>).</li> <li>Maintainence fixes (:pr:<code>462</code>, :pr:<code>466</code>, :commit:<code>1ccb85da581be65a0345b399e00fd3c325700d95</code>,   :commit:<code>5547b4e92dc8d61492e9dc10ba00175c1a6637fa</code>   :commit:<code>00c0e5514de2aab8b9a0be16b5da470b091d9eb9</code>, :commit:<code>fcd3020dd08c7022a44f709173fe23969d3e8f7c</code>,   thanks :ghuser:<code>hameerabbasi</code>)</li> <li>:obj:<code>sparse.DOK.from_scipy_sparse</code> method (:pr:<code>464</code>, :issue:<code>463</code>, thanks   :ghuser:<code>hameerabbasi</code>).</li> <li>Black re-formatting (:pr:<code>471</code>, :pr:<code>484</code>, thanks :ghuser:<code>GenevieveBuckley</code>, :ghuser:<code>sayandip18</code>)</li> <li>Add :obj:<code>sparse.pad</code> (:pr:<code>474</code>, :issue:<code>438</code>, thanks :ghuser:<code>H4R5H1T-007</code>)</li> <li>Switch to GitHub Actions (:compare:<code>5547b4e92dc8d61492e9dc10ba00175c1a6637fa..a332f22c96a96e5ab9b4384342df67e8f3966f85</code>)</li> <li>Fix a number of bugs in format conversion. (:pr:<code>504</code>, :issue:<code>503</code>, thanks   :ghuser:<code>hameerabbasi</code>)</li> <li>Fix bug in :obj:<code>sparse.matmul</code> for higher-dimensional arrays. (:pr:<code>508</code>,   :issue:<code>506</code>, thanks :ghuser:<code>sayandip18</code>).</li> <li>Fix scalar conversion to COO (:issue:<code>510</code>, :pr:<code>511</code>, thanks :ghuser:<code>hameerabbasi</code>)</li> <li>Fix OOB memory accesses (:issue:<code>515</code>, :commit:<code>1e24a7e29786e888dee4c02153309986ae4b5dde</code>   thanks :ghuser:<code>hameerabbasi</code>)</li> <li>Fixes element-wise ops with scalar COO array. (:issue:<code>505</code>, :commit:<code>5211441ec685233657ab7156f99eb67e660cee86</code>,   thanks :ghuser:<code>hameerabbasi</code>)</li> <li>Fix scalar broadcast_to with <code>nnz==0</code>. (:issue:<code>513</code>, :commit:<code>bfabaa0805e811884e79c4bdbfd14316986d65e4</code>,   thanks :ghuser:<code>hameerabbasi</code>)</li> <li>Add order parameter to <code>{zero, ones, full}[_like]</code>. (:issue:<code>514</code>, :commit:<code>37de1d0141c4375962ecdf18337c2dd0f667b60c</code>,   thanks :ghuser:<code>hameerabbasi</code>)</li> <li>Fix tensordot typing bugs. (:issue:<code>493</code>, :issue:<code>499</code>, :commit:<code>37de1d0141c4375962ecdf18337c2dd0f667b60c</code>,   thanks :ghuser:<code>hameerabbasi</code>).</li> </ul>"},{"location":"changelog/#0120-2021-03-19","title":"0.12.0 / 2021-03-19","text":"<p>There are a number of large changes in this release. For example, we have implemented the :obj:<code>GCXS</code> type, and its specializations :obj:<code>CSR</code> and :obj:<code>CSC</code>. We plan on gradually improving the performance of these.</p> <ul> <li>A number of :obj:<code>GCXS</code> fixes and additions (:pr:<code>409</code>, :pr:<code>407</code>, :pr:<code>414</code>,   :pr:<code>417</code>, :pr:<code>419</code> thanks :ghuser:<code>daletovar</code>)</li> <li>Ability to change the index dtype for better storage characteristics. (:pr:<code>441</code>,   thanks :ghuser:<code>daletovar</code>)</li> <li>Some work on :obj:<code>DOK</code> arrays to bring them closer to the other formats (:pr:<code>435</code>,   :pr:<code>437</code>, :pr:<code>439</code>, :pr:<code>440</code>, thanks :ghuser:<code>DragaDoncila</code>)</li> <li>:obj:<code>CSR</code> and :obj:<code>CSC</code> specializations of :obj:<code>GCXS</code> (:pr:<code>442</code>, thanks :ghuser:<code>ivirshup</code>)   For now, this is experimental undocumented API, and subject to change.</li> <li>Fix a number of bugs (:pr:<code>407</code>, :issue:<code>406</code>)</li> <li>Add <code>nnz</code> parameter to :obj:<code>sparse.random</code> (:pr:<code>410</code>, thanks :ghuser:<code>emilmelnikov</code>)</li> </ul>"},{"location":"changelog/#0112-2020-09-04","title":"0.11.2 / 2020-09-04","text":"<ul> <li>Fix :obj:<code>TypingError</code> on :obj:<code>sparse.dot</code> with complex dtypes. (:issue:<code>403</code>, :pr:<code>404</code>)</li> </ul>"},{"location":"changelog/#0111-2020-08-31","title":"0.11.1 / 2020-08-31","text":"<ul> <li>Fix :obj:<code>ValueError</code> on :obj:<code>sparse.dot</code> with extremely small values. (:issue:<code>398</code>, :pr:<code>399</code>)</li> </ul>"},{"location":"changelog/#0110-2020-08-18","title":"0.11.0 / 2020-08-18","text":"<ul> <li>Improve the performance of :obj:<code>sparse.dot</code>. (:issue:<code>331</code>, :pr:<code>389</code>, thanks :ghuser:<code>daletovar</code>)</li> <li>Added the :obj:<code>COO.swapaxes</code> method. (:pr:<code>344</code>, thanks :ghuser:<code>lueckem</code>)</li> <li>Added multi-axis 1-D indexing support. (:pr:<code>343</code>, thanks :ghuser:<code>mikeymezher</code>)</li> <li>Fix :obj:<code>outer</code> for arrays that weren't one-dimensional. (:issue:<code>346</code>, :pr:<code>347</code>)</li> <li>Add <code>casting</code> kwarg to :obj:<code>COO.astype</code>. (:issue:<code>391</code>, :pr:<code>392</code>)</li> <li>Fix for :obj:<code>COO</code> constructor accepting invalid inputs. (:issue:<code>385</code>, :pr:<code>386</code>)</li> </ul>"},{"location":"changelog/#0100-2020-05-13","title":"0.10.0 / 2020-05-13","text":"<ul> <li>Fixed a bug where converting an empty DOK array to COO leads   to an incorrect dtype. (:issue:<code>314</code>, :pr:<code>315</code>)</li> <li>Change code formatter to black. (:pr:<code>284</code>)</li> <li>Add :obj:<code>COO.flatten</code> and :obj:<code>sparse.outer</code>. (:issue:<code>316</code>, :pr:<code>317</code>).</li> <li>Remove broadcasting restriction between sparse arrays and dense arrays.   (:issue:<code>306</code>, :pr:<code>318</code>)</li> <li>Implement deterministic dask tokenization. (:issue:<code>300</code>, :pr:<code>320</code>, thanks   :ghuser:<code>danielballan</code>)</li> <li>Improve testing around densification (:pr:<code>321</code>, thanks   :ghuser:<code>danielballan</code>)</li> <li>Simplify Numba extension. (:pr:<code>324</code>, thanks :ghuser:<code>eric-wieser</code>).</li> <li>Respect <code>copy=False</code> in <code>astype</code> (:pr:<code>328</code>, thanks :ghuser:<code>eric-wieser</code>).</li> <li>Replace linear_loc with ravel_multi_index, which is 3x faster. (:pr:<code>330</code>,   thanks :ghuser:<code>eric-wieser</code>).</li> <li>Add error msg to tensordot operation when <code>ndim==0</code> (:issue:<code>332</code>,   :pr:<code>333</code>, thanks :ghuser:<code>guilhermeleobas</code>).</li> <li>Maintainence fixes for Sphinx 3.0 and Numba 0.49, and dropping support for   Python 3.5. (:pr:<code>337</code>).</li> <li>Fixed signature for :obj:<code>numpy.clip</code>.</li> </ul>"},{"location":"changelog/#091-2020-01-23","title":"0.9.1 / 2020-01-23","text":"<ul> <li>Fixed a bug where indexing with an empty list could lead   to issues. (:issue:<code>281</code>, :pr:<code>282</code>)</li> <li>Change code formatter to black. (:pr:<code>284</code>)</li> <li>Add the :obj:<code>diagonal</code> and :obj:<code>diagonalize</code> functions.   (:issue:<code>288</code>, :pr:<code>289</code>, thanks :ghuser:<code>pettni</code>)</li> <li>Add HTML repr for notebooks. (:pr:<code>283</code>, thanks :ghuser:<code>daletovar</code>)</li> <li>Avoid making copy of <code>coords</code> when making a new :obj:<code>COO</code>   array.</li> <li>Add stack and concatenate for GCXS. (:issue:<code>301</code>, :pr:<code>303</code>, thanks   :ghuser:<code>daletovar</code>).</li> <li>Fix issue where functions dispatching to an attribute access wouldn't   work with <code>__array_function__</code>. (:issue:<code>308</code>, :pr:<code>309</code>).</li> <li>Add partial support for constructing and mirroring :obj:<code>COO</code> objects to   Numba.</li> </ul>"},{"location":"changelog/#080-2019-08-26","title":"0.8.0 / 2019-08-26","text":"<p>This release switches to Numba's new typed lists, a lot of back-end work with the CI infrastructure, so Linux, macOS and Windows are officially tested. It also includes bug fixes.</p> <p>It also adds in-progress, not yet public support for the GCXS format, which is a generalisation of CSR/CSC. (huge thanks to :ghuser:<code>daletovar</code>)</p> <ul> <li>Fixed a bug where an array with size == 1 and nnz == 0   could not be broadcast. (:issue:<code>242</code>, :pr:<code>243</code>)</li> <li>Add <code>std</code> and <code>var</code>. (:pr:<code>244</code>)</li> <li>Move to Azure Pipelines with CI for Windows, macOS and   Linux. (:pr:<code>245</code>, :pr:<code>246</code>, :pr:<code>247</code>, :pr:<code>248</code>)</li> <li>Add <code>resize</code>, and change <code>reshape</code> so it raises a   <code>ValueError</code> on shapes that don't correspond to the   same size. (:issue:<code>241</code>, :issue:<code>250</code>, :pr:<code>256</code>   thanks, :ghuser:<code>daletovar</code>)</li> <li>Add <code>isposinf</code> and <code>isneginf</code>. (:issue:<code>252</code>, :pr:<code>253</code>)</li> <li>Fix <code>tensordot</code> when nnz = 0. (:issue:<code>255</code>, :pr:<code>256</code>)</li> <li>Modifications to <code>__array_function__</code> to allow for sparse   XArrays. (:pr:<code>261</code>, thanks :ghuser:<code>nvictus</code>)</li> <li>Add not-yet-public support for GCXS. (:pr:<code>258</code>, thanks :ghuser:<code>daletovar</code>)</li> <li>Improvements to <code>__array_function__</code>. (:pr:<code>267</code>, :pr:<code>272</code>, thanks   :ghuser:<code>crusaderky</code>)</li> <li>Convert all Numba lists to typed lists. (:pr:<code>264</code>)</li> <li>Why write code when it exists elsewhere? (:pr:<code>277</code>)</li> <li>Fix some element-wise operations with scalars. (:pr:<code>278</code>)</li> <li>Private modules should be private, and tests should be in the package.   (:pr:<code>280</code>)</li> </ul>"},{"location":"changelog/#070-2019-03-14","title":"0.7.0 / 2019-03-14","text":"<p>This is a release that adds compatibility with NumPy's new <code>__array_function__</code> protocol, for details refer to <code>NEP-18 &lt;http://www.numpy.org/neps/nep-0018-array-function-protocol.html#coercion-to-a-numpy-array-as-a-catch-all-fallback&gt;</code>_.</p> <p>The other big change is that we dropped compatibility with Python 2. Users on Python 2 should use version 0.6.0.</p> <p>There are also some bug-fixes relating to fill-values.</p> <p>This was mainly a contributor-driven release.</p> <p>The full list of changes can be found below:</p> <ul> <li>Fixed a bug where going between :obj:<code>sparse.DOK</code> and   :obj:<code>sparse.COO</code> caused fill-values to be lost.   (:issue:<code>225</code>, :pr:<code>226</code>).</li> <li>Fixed warning for a matrix that was incorrectly considered   too dense. (:issue:<code>228</code>, :pr:<code>229</code>)</li> <li>Fixed some warnings in Python 3.7, the fix was needed.   in preparation for Python 3.8. (:pr:<code>233</code>, thanks :ghuser:<code>nils-werner</code>)</li> <li>Drop support for Python 2.7 (:issue:<code>234</code>, :pr:<code>235</code>, thanks   :ghuser:<code>hugovk</code>)</li> <li>Clearer error messages (:issue:<code>230</code>, :issue:<code>231</code>, :pr:<code>232</code>)</li> <li>Restructure requirements.txt files. (:pr:<code>236</code>)</li> <li>Support fill-value in reductions in specific cases. (:issue:<code>237</code>, :pr:<code>238</code>)</li> <li>Add <code>__array_function__</code> support. (:pr:<code>239</code>, thanks, :ghuser:<code>pentschev</code>)</li> <li>Cleaner code! (:pr:<code>240</code>)</li> </ul>"},{"location":"changelog/#060-2018-12-19","title":"0.6.0 / 2018-12-19","text":"<p>This release breaks backward-compatibility. Previously, if arrays were fed into NumPy functions, an attempt would be made to densify the array and apply the NumPy function. This was unintended behaviour in most cases, with the array filling up memory before raising a <code>MemoryError</code> if the array was too large.</p> <p>We have now changed this behaviour so that a <code>RuntimeError</code> is now raised if an attempt is made to automatically densify an array. To densify, use the explicit <code>.todense()</code> method.</p> <ul> <li>Fixed a bug where <code>np.matrix</code> could sometimes fail to   convert to a <code>COO</code>. (:issue:<code>199</code>, :pr:<code>200</code>).</li> <li>Make sure that <code>sparse @ sparse</code> returns a sparse array. (:issue:<code>201</code>, :pr:<code>203</code>)</li> <li>Bring <code>operator.matmul</code> behaviour in line with NumPy for <code>ndim &gt; 2</code>.   (:issue:<code>202</code>, :pr:<code>204</code>, :pr:<code>217</code>)</li> <li>Make sure <code>dtype</code> is preserved with the <code>out</code> kwarg. (:issue:<code>205</code>, :pr:<code>206</code>)</li> <li>Fix integer overflow in <code>reduce</code> on Windows. (:issue:<code>207</code>, :pr:<code>208</code>)</li> <li>Disallow auto-densification. (:issue:<code>218</code>, :pr:<code>220</code>)</li> <li>Add auto-densification configuration, and a configurable warning for checking   if the array is too dense. (:pr:<code>210</code>, :pr:<code>213</code>)</li> <li>Add pruning of fill-values to COO constructor. (:pr:<code>221</code>)</li> </ul>"},{"location":"changelog/#050-2018-10-12","title":"0.5.0 / 2018-10-12","text":"<ul> <li>Added :code:<code>COO.real</code>, :code:<code>COO.imag</code>, and :code:<code>COO.conj</code> (:pr:<code>196</code>).</li> <li>Added :code:<code>sparse.kron</code> function (:pr:<code>194</code>, :pr:<code>195</code>).</li> <li>Added :code:<code>order</code> parameter to :code:<code>COO.reshape</code> to make it work with   :code:<code>np.reshape</code> (:pr:<code>193</code>).</li> <li>Added :code:<code>COO.mean</code> and :code:<code>sparse.nanmean</code> (:pr:<code>190</code>).</li> <li>Added :code:<code>sparse.full</code> and :code:<code>sparse.full_like</code> (:pr:<code>189</code>).</li> <li>Added :code:<code>COO.clip</code> method (:pr:<code>185</code>).</li> <li>Added :code:<code>COO.copy</code> method, and changed pickle of :code:<code>COO</code> to not   include its cache (:pr:<code>184</code>).</li> <li>Added :code:<code>sparse.eye</code>, :code:<code>sparse.zeros</code>, :code:<code>sparse.zeros_like</code>,   :code:<code>sparse.ones</code>, and :code:<code>sparse.ones_like</code> (:pr:<code>183</code>).</li> </ul>"},{"location":"changelog/#041-2018-09-12","title":"0.4.1 / 2018-09-12","text":"<ul> <li>Allow mixed :code:<code>ndarray</code>-:code:<code>COO</code> operations if the result is sparse   (:issue:<code>124</code>, via :pr:<code>182</code>).</li> <li>Allow specifying a fill-value when converting from NumPy arrays   (:issue:<code>179</code>, via :pr:<code>180</code>).</li> <li>Added :code:<code>COO.any</code> and :code:<code>COO.all</code> methods (:pr:<code>175</code>).</li> <li>Indexing for :code:<code>COO</code> now accepts a single one-dimensional array index   (:pr:<code>172</code>).</li> <li>The fill-value can now be something other than zero or :code:<code>False</code>   (:pr:<code>165</code>).</li> <li>Added a :code:<code>sparse.roll</code> function (:pr:<code>160</code>).</li> <li>Numba code now releases the GIL. This leads to better multi-threaded   performance in Dask (:pr:<code>159</code>).</li> <li>A number of bugs occurred, so to resolve them, :code:<code>COO.coords.dtype</code> is   always :code:<code>np.int64</code>.  :code:<code>COO</code>, therefore, uses more memory than   before (:pr:<code>158</code>).</li> <li>Add support for saving and loading :code:<code>COO</code> files from disk (:issue:<code>153</code>,   via :pr:<code>154</code>).</li> <li>Support :code:<code>COO.nonzero</code> and :code:<code>np.argwhere</code> (:issue:<code>145</code>, via   :pr:<code>148</code>).</li> <li>Allow faux in-place operations (:issue:<code>80</code>, via :pr:<code>146</code>).</li> <li>:code:<code>COO</code> is now always canonical (:pr:<code>141</code>).</li> <li>Improve indexing performance (:pr:<code>128</code>).</li> <li>Improve element-wise performance (:pr:<code>127</code>).</li> <li>Reductions now support a negative axis (:issue:<code>117</code>, via :pr:<code>118</code>).</li> <li>Match behaviour of :code:<code>ufunc.reduce</code> from NumPy (:issue:<code>107</code>, via   :pr:<code>108</code>).</li> </ul>"},{"location":"changelog/#031-2018-04-12","title":"0.3.1 / 2018-04-12","text":"<ul> <li>Fix packaging error (:pr:<code>138</code>).</li> </ul>"},{"location":"changelog/#030-2018-02-22","title":"0.3.0 / 2018-02-22","text":"<ul> <li>Add NaN-skipping aggregations (:pr:<code>102</code>).</li> <li>Add equivalent to :code:<code>np.where</code> (:pr:<code>102</code>).</li> <li>N-input universal functions now work (:pr:<code>98</code>).</li> <li>Make :code:<code>dot</code> more consistent with NumPy (:pr:<code>96</code>).</li> <li>Create a base class :code:<code>SparseArray</code> (:pr:<code>92</code>).</li> <li>Minimum NumPy version is now 1.13 (:pr:<code>90</code>).</li> <li>Fix a bug where setting a :code:<code>DOK</code> element to zero did nothing   (:issue:<code>93</code>, via :pr:<code>94</code>).</li> </ul>"},{"location":"changelog/#020-2018-01-25","title":"0.2.0 / 2018-01-25","text":"<ul> <li>Support faster :code:<code>np.array(COO)</code> (:pr:<code>87</code>).</li> <li>Add :code:<code>DOK</code> type (:pr:<code>85</code>).</li> <li>Fix sum for large arrays (:issue:<code>82</code>, via :pr:<code>83</code>).</li> <li>Support :code:<code>.size</code> and :code:<code>.density</code> (:pr:<code>69</code>).</li> <li>Documentation added for the package (:pr:<code>43</code>).</li> <li>Minimum required SciPy version is now 0.19 (:pr:<code>70</code>).</li> <li>:code:<code>len(COO)</code> now works (:pr:<code>68</code>).</li> <li>:code:<code>scalar op COO</code> now works for all operators (:pr:<code>67</code>).</li> <li>Validate axes for :code:<code>.transpose()</code> (:pr:<code>61</code>).</li> <li>Extend indexing support (:pr:<code>57</code>).</li> <li>Add :code:<code>random</code> function for generating random sparse arrays (:pr:<code>41</code>).</li> <li>:code:<code>COO(COO)</code> now copies the original object (:pr:<code>55</code>).</li> <li>NumPy universal functions and reductions now work on :code:<code>COO</code> arrays   (:pr:<code>49</code>).</li> <li>Fix concatenate and stack for large arrays (:issue:<code>32</code>, via :pr:<code>51</code>).</li> <li>Fix :code:<code>nnz</code> for scalars (:issue:<code>47</code>, via :pr:<code>48</code>).</li> <li>Support more operators and remove all special cases (:pr:<code>46</code>).</li> <li>Add support for :code:<code>triu</code> and :code:<code>tril</code> (:pr:<code>40</code>).</li> <li>Add support for Ellipsis (:code:<code>...</code>) and :code:<code>None</code> when indexing   (:pr:<code>37</code>).</li> <li>Add support for bitwise bindary operations like :code:<code>&amp;</code> and :code:<code>|</code>   (:pr:<code>38</code>).</li> <li>Support broadcasting in element-wise operations (:pr:<code>35</code>).</li> </ul>"},{"location":"completed-tasks/","title":"Completed tasks","text":""},{"location":"conduct/","title":"Code of Conduct","text":""},{"location":"conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our    mistakes, and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the    overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or    advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political    attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email    address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a    professional setting</li> </ul>"},{"location":"conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at hameerabbasi@yahoo.com. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at [https://www.contributor-covenant.org/faq][]. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"construct/","title":"Construct Sparse Arrays","text":""},{"location":"construct/#from-coordinates-and-data","title":"From coordinates and data","text":"<p>You can construct COO arrays from coordinates and value data.</p> <p>The <code>cords</code> parameter contains the indices where the data is nonzero, and the <code>data</code> parameter contains the data corresponding to those indices. For example, the following code will generate a \\(5 \\times 5\\) diagonal matrix:</p> <pre><code>   &gt;&gt;&gt; import sparse\n\n   &gt;&gt;&gt; coords = [[0, 1, 2, 3, 4],\n   ...           [0, 1, 2, 3, 4]]\n   &gt;&gt;&gt; data = [10, 20, 30, 40, 50]\n   &gt;&gt;&gt; s = sparse.COO(coords, data, shape=(5, 5))\n   &gt;&gt;&gt; s\n   &lt;COO: shape=(5, 5), dtype=int64, nnz=5, fill_value=0&gt;\n        0    1    2    3    4\n     \u250c                         \u2510\n   0 \u2502 10                      \u2502\n   1 \u2502      20                 \u2502\n   2 \u2502           30            \u2502\n   3 \u2502                40       \u2502\n   4 \u2502                     50  \u2502\n     \u2514                         \u2518\n</code></pre> <p>In general <code>coords</code> should be a <code>(ndim, nnz)</code> shaped array. Each row of <code>coords</code> contains one dimension of the desired sparse array, and each column contains the index corresponding to that nonzero element. <code>data</code> contains the nonzero elements of the array corresponding to the indices in <code>coords</code>. Its shape should be <code>(nnz,)</code>.</p> <p>If <code>data</code> is the same across all the coordinates, it can be passed in as a scalar. For example, the following produces the \\(4 \\times 4\\) identity matrix:</p> <pre><code>   &gt;&gt;&gt; import sparse\n\n   &gt;&gt;&gt; coords = [[0, 1, 2, 3],\n   ...           [0, 1, 2, 3]]\n   &gt;&gt;&gt; data = 1\n   &gt;&gt;&gt; s = sparse.COO(coords, data, shape=(4, 4))\n   &gt;&gt;&gt; s\n   &lt;COO: shape=(4, 4), dtype=int64, nnz=4, fill_value=0&gt;\n        0    1    2    3\n     \u250c                    \u2510\n   0 \u2502  1                 \u2502\n   1 \u2502       1            \u2502\n   2 \u2502            1       \u2502\n   3 \u2502                 1  \u2502\n     \u2514                    \u2518\n</code></pre> <p>You can, and should, pass in numpy.ndarray objects for <code>coords</code> and <code>data</code>.</p> <p>In this case, the shape of the resulting array was determined from the maximum index in each dimension. If the array extends beyond the maximum index in <code>coords</code>, you should supply a shape explicitly. For example, if we did the following without the <code>shape</code> keyword argument, it would result in a \\(4 \\times 5\\) matrix, but maybe we wanted one that was actually \\(5 \\times 5\\).</p> <pre><code>   &gt;&gt;&gt; coords = [[0, 3, 2, 1], [4, 1, 2, 0]]\n   &gt;&gt;&gt; data = [1, 4, 2, 1]\n   &gt;&gt;&gt; s = COO(coords, data, shape=(5, 5))\n   &gt;&gt;&gt; s\n   &lt;COO: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n        0    1    2    3    4\n     \u250c                         \u2510\n   0 \u2502                      1  \u2502\n   1 \u2502  1                      \u2502\n   2 \u2502            2            \u2502\n   3 \u2502       4                 \u2502\n   4 \u2502                         \u2502\n     \u2514                         \u2518\n</code></pre> <p>COO arrays support arbitrary fill values. Fill values are the \"default\" value, or value to not store. This can be given a value other than zero. For example, the following builds a (bad) representation of a \\(2 \\times 2\\) identity matrix. Note that not all operations are supported for operations with nonzero fill values.</p> <pre><code>   &gt;&gt;&gt; coords = [[0, 1], [1, 0]]\n   &gt;&gt;&gt; data = [0, 0]\n   &gt;&gt;&gt; s = COO(coords, data, fill_value=1)\n   &gt;&gt;&gt; s\n   &lt;COO: shape=(2, 2), dtype=int64, nnz=2, fill_value=1&gt;\n        0    1\n     \u250c          \u2510\n   0 \u2502       0  \u2502\n   1 \u2502  0       \u2502\n     \u2514          \u2518\n</code></pre>"},{"location":"construct/#from-scipysparsespmatrix","title":"From scipy.sparse.spmatrix","text":"<p>To construct COO array from spmatrix objects, you can use the COO.from_scipy_sparse method. As an example, if <code>x</code> is a scipy.sparse.spmatrix, you can do the following to get an equivalent COO array:</p> <pre><code>   s = COO.from_scipy_sparse(x)\n</code></pre>"},{"location":"construct/#from-numpy-arrays","title":"From Numpy arrays","text":"<p>To construct COO arrays from numpy.ndarray objects, you can use the COO.from_numpy method. As an example, if <code>x</code> is a numpy.ndarray, you can do the following to get an equivalent COO array:</p> <pre><code>   s = COO.from_numpy(x)\n</code></pre>"},{"location":"construct/#generating-random-coo-objects","title":"Generating random COO objects","text":"<p>The sparse.random method can be used to create random COO arrays. For example, the following will generate a \\(10 \\times 10\\) matrix with \\(10\\) nonzero entries, each in the interval \\([0, 1)\\).</p> <pre><code>   s = sparse.random((10, 10), density=0.1)\n</code></pre> <p>Building COO Arrays from DOK Arrays</p> <p>It's possible to build COO arrays from DOK arrays, if it is not easy to construct the <code>coords</code> and <code>data</code> in a simple way. DOK arrays provide a simple builder interface to build COO arrays, but at this time, they can do little else.</p> <p>You can get started by defining the shape (and optionally, datatype) of the DOK array. If you do not specify a dtype, it is inferred from the value dictionary or is set to <code>dtype('float64')</code> if that is not present.</p> <pre><code>   s = DOK((6, 5, 2))\n   s2 = DOK((2, 3, 4), dtype=np.uint8)\n</code></pre> <p>After this, you can build the array by assigning arrays or scalars to elements or slices of the original array. Broadcasting rules are followed.</p> <pre><code>   s[1:3, 3:1:-1] = [[6, 5]]\n</code></pre> <p>DOK arrays also support fancy indexing assignment if and only if all dimensions are indexed.</p> <pre><code>   s[[0, 2], [2, 1], [0, 1]] = 5\n   s[[0, 3], [0, 4], [0, 1]] = [1, 5]\n</code></pre> <p>Alongside indexing assignment and retrieval, DOK arrays support any arbitrary broadcasting function to any number of arguments where the arguments can be SparseArray objects, scipy.sparse.spmatrix objects, or numpy.ndarray.</p> <pre><code>   x = sparse.random((10, 10), 0.5, format=\"dok\")\n   y = sparse.random((10, 10), 0.5, format=\"dok\")\n   sparse.elemwise(np.add, x, y)\n</code></pre> <p>DOK arrays also support standard ufuncs and operators, including comparison operators, in combination with other objects implementing the numpy ndarray._array_ufunc_ method. For example, the following code will perform elementwise equality comparison on the two arrays and return a new boolean DOK array.</p> <pre><code>   x = sparse.random((10, 10), 0.5, format=\"dok\")\n   y = np.random.random((10, 10))\n   x == y\n</code></pre> <p>DOK arrays are returned from elemwise functions and standard ufuncs if and only if all SparseArray objects are DOK arrays. Otherwise, a COO array or dense array are returned.</p> <p>At the end, you can convert the DOK array to a COO arrays.</p> <pre><code>   s3 = COO(s)\n</code></pre> <p>In addition, it is possible to access single elements and slices of the DOK array using normal Numpy indexing, as well as fancy indexing if and only if all dimensions are indexed. Slicing and fancy indexing will always return a new DOK array.</p> <pre><code>   s[1, 2, 1]  # 5\n   s[5, 1, 1]  # 0\n   s[[0, 3], [0, 4], [0, 1]] # &lt;DOK: shape=(2,), dtype=float64, nnz=2, fill_value=0.0&gt;\n</code></pre>"},{"location":"construct/#converting-coo-objects-to-other-formats","title":"Converting COO objects to other Formats","text":"<p>COO arrays can be converted to Numpy arrays, or to some spmatrix subclasses via the following methods:</p> <ul> <li>COO.todense: Converts to a numpy.ndarray unconditionally.</li> <li>COO.maybe_densify: Converts to a numpy.ndarray based on    certain constraints.</li> <li>COO.to_scipy_sparse: Converts to a scipy.sparse.coo_matrix if    the array is two dimensional.</li> <li>COO.tocsr: Converts to a scipy.sparse.csr_matrix if    the array is two dimensional.</li> <li>COO.tocsc: Converts to a scipy.sparse.csc_matrix if    the array is two dimensional.</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":""},{"location":"contributing/#general-guidelines","title":"General Guidelines","text":"<p>sparse is a community-driven project on GitHub. You can find our repository on GitHub. Feel free to open issues for new features or bugs, or open a pull request to fix a bug or add a new feature.</p> <p>If you haven't contributed to open-source before, we recommend you read this excellent guide by GitHub on how to contribute to open source. The guide is long, so you can gloss over things you're familiar with.</p> <p>If you're not already familiar with it, we follow the fork and pull model on GitHub.</p>"},{"location":"contributing/#filing-issues","title":"Filing Issues","text":"<p>If you find a bug or would like a new feature, you might want to consider filing a new issue on GitHub. Before you open a new issue, please make sure of the following:</p> <ul> <li>This should go without saying, but make sure what you are requesting is within   the scope of this project.</li> <li>The bug/feature is still present/missing on the <code>main</code> branch on GitHub.</li> <li>A similar issue or pull request isn't already open. If one already is, it's better   to contribute to the discussion there.</li> </ul>"},{"location":"contributing/#contributing-code","title":"Contributing Code","text":"<p>This project has a number of requirements for all code contributed.</p> <ul> <li>We use <code>pre-commit</code> to automatically lint the code and maintain code style.</li> <li>We use Numpy-style docstrings.</li> <li>It's ideal if user-facing API changes or new features have documentation added.</li> <li>100% code coverage is recommended for all new code in any submitted PR. Doctests   count toward coverage.</li> <li>Performance optimizations should have benchmarks added in <code>benchmarks</code>.</li> </ul>"},{"location":"contributing/#setting-up-your-development-environment","title":"Setting up Your Development Environment","text":"<p>The following bash script is all you need to set up your development environment, after forking and cloning the repository:</p> <pre><code>   pip install -e .[all]\n</code></pre>"},{"location":"contributing/#runningadding-unit-tests","title":"Running/Adding Unit Tests","text":"<p>It is best if all new functionality and/or bug fixes have unit tests added with each use-case.</p> <p>We use pytest as our unit testing framework, with the <code>pytest-cov</code> extension to check code coverage and <code>pytest-flake8</code> to check code style. You don't need to configure these extensions yourself. Once you've configured your environment, you can just <code>cd</code> to the root of your repository and run</p> <pre><code>   pytest --pyargs sparse\n</code></pre> <p>This automatically checks code style and functionality, and prints code coverage, even though it doesn't fail on low coverage.</p> <p>Unit tests are automatically run on Travis CI for pull requests.</p>"},{"location":"contributing/#coverage","title":"Coverage","text":"<p>The <code>pytest</code> script automatically reports coverage, both on the terminal for missing line numbers, and in annotated HTML form in <code>htmlcov/index.html</code>.</p> <p>Coverage is automatically checked on CodeCov for pull requests.</p>"},{"location":"contributing/#addingbuilding-the-documentation","title":"Adding/Building the Documentation","text":"<p>If a feature is stable and relatively finalized, it is time to add it to the documentation. If you are adding any private/public functions, it is best to add docstrings, to aid in reviewing code and also for the API reference.</p> <p>We use Numpy style docstrings and Material for MkDocs to document this library. MkDocs, in turn, uses Markdown as its markup language for adding code.</p> <p>We use mkdoctrings with the mkdocs-gen-files plugin to generate API references.</p> <p>To build the documentation, you can run</p> <pre><code>   mkdocs build\n   mkdocs serve\n</code></pre> <p>After this, you can see a version of the documentation on your local server.</p> <p>Documentation for pull requests is automatically built on CircleCI and can be found in the build artifacts.</p>"},{"location":"contributing/#adding-and-running-benchmarks","title":"Adding and Running Benchmarks","text":"<p>We use Airspeed Velocity to run benchmarks. We have it set up to use <code>conda</code>, but you can edit the configuration locally if you so wish.</p>"},{"location":"install/","title":"Install","text":"<p>You can install this library with <code>pip</code>:</p> <pre><code>   pip install sparse\n</code></pre> <p>You can also install from source from GitHub, either by pip installing directly:: <pre><code>   pip install git+https://github.com/pydata/sparse\n</code></pre> Or by cloning the repository and installing locally:: <pre><code>   git clone https://github.com/pydata/sparse.git\n   cd sparse/\n   pip install .\n</code></pre> Note that this library is under active development and so some API churn should be expected.</p>"},{"location":"operations/","title":"Operations on COO and GCXS arrays","text":""},{"location":"operations/#operators","title":"Operators","text":"<p>COO and GCXS objects support a number of operations. They interact with scalars, Numpy arrays, other COO and GCXS objects, scipy.sparse.spmatrix objects, all following standard Python and Numpy conventions.</p> <p>For example, the following Numpy expression produces equivalent results for both Numpy arrays, COO arrays, or a mix of the two:</p> <pre><code>   np.log(X.dot(beta.T) + 1)\n</code></pre> <p>However some operations are not supported, like operations that implicitly cause dense structures, or numpy functions that are not yet implemented for sparse arrays.</p> <pre><code>   np.linalg.cholesky(x)  # sparse cholesky not implemented\n</code></pre> <p>This page describes those valid operations, and their limitations.</p> <p>elemwise</p> <p>This function allows you to apply any arbitrary broadcasting function to any number of arguments where the arguments can be SparseArray objects or scipy.sparse.spmatrix objects. For example, the following will add two arrays:</p> <pre><code>   sparse.elemwise(np.add, x, y)\n</code></pre> <p>Warning</p> <p>Previously, elemwise was a method of the COO class. Now, it has been moved to the sparse module.</p> <p>Auto-Densification</p> <p>Operations that would result in dense matrices, such as operations with Numpy arrays raises a ValueError. For example, the following will raise a ValueError if <code>x</code> is a numpy.ndarray:</p> <pre><code>   x + y\n</code></pre> <p>However, all of the following are valid operations.</p> <pre><code>   x + 0\n   x != y\n   x + y\n   x == 5\n   5 * x\n   x / 7.3\n   x != 0\n   x == 0\n   ~x\n   x + 5\n</code></pre> <p>We also support operations with a nonzero fill value. These are operations that map zero values to nonzero values, such as <code>x + 1</code> or <code>~x</code>. In these cases, they will produce an output with a fill value of <code>1</code> or <code>True</code>, assuming the original array has a fill value of <code>0</code> or <code>False</code> respectively.</p> <p>If densification is needed, it must be explicit. In other words, you must call SparseArray.todense on the SparseArray object. If both operands are sparse.SparseArray, both must be densified.</p> <p>Operations with NumPy arrays</p> <p>In certain situations, operations with NumPy arrays are also supported. For example, the following will work if <code>x</code> is COO and <code>y</code> is a NumPy array:</p> <pre><code>   x * y\n</code></pre> <p>The following conditions must be met when performing element-wise operations with NumPy arrays:</p> <ul> <li>The operation must produce a consistent fill-values. In other words, the resulting   array must also be sparse.</li> <li>Operating on the NumPy arrays must not increase the size when broadcasting the arrays.</li> </ul>"},{"location":"operations/#operations-with-scipysparsespmatrix","title":"Operations with scipy.sparse.spmatrix","text":"<p>Certain operations with scipy.sparse.spmatrix are also supported. For example, the following are all allowed if <code>y</code> is a scipy.sparse.spmatrix:</p> <pre><code>   x + y\n   x - y\n   x * y\n   x &gt; y\n   x &lt; y\n</code></pre> <p>In general, operating on a scipy.sparse.spmatrix is the same as operating on COO or GCXS, as long as it is to the right of the operator.</p> <p>Note</p> <p>Results are not guaranteed if <code>x</code> is a scipy.sparse.spmatrix. For this reason, we recommend that all Scipy sparse matrices should be explicitly converted to COO or GCXS before any operations.</p>"},{"location":"operations/#broadcasting","title":"Broadcasting","text":"<p>All binary operators support broadcasting. This means that (under certain conditions) you can perform binary operations on arrays with unequal shape. Namely, when the shape is missing a dimension, or when a dimension is <code>1</code>. For example, performing a binary operation on two <code>COO</code> arrays with shapes <code>(4,)</code> and <code>(5, 1)</code> yields an object of shape <code>(5, 4)</code>. The same happens with arrays of shape <code>(1, 4)</code> and <code>(5, 1)</code>. However, <code>(4, 1)</code> and <code>(5, 1)</code> will raise a ValueError.If densification is needed,</p>"},{"location":"operations/#element-wise-operations","title":"Element-wise Operations","text":"<p>COO and GCXS arrays support a variety of element-wise operations. However, as with operators, operations that map zero to a nonzero value are not supported.</p> <p>To illustrate, the following are all possible, and will produce another SparseArray:</p> <pre><code>   np.abs(x)\n   np.sin(x)\n   np.sqrt(x)\n   np.conj(x)\n   np.expm1(x)\n   np.log1p(x)\n   np.exp(x)\n   np.cos(x)\n   np.log(x)\n</code></pre> <p>As above, in the last three cases, an array with a nonzero fill value will be produced.</p> <p>Notice that you can apply any unary or binary numpy.ufunc to COO arrays, and numpy.ndarray objects and scalars and it will work so long as the result is not dense. When applying to numpy.ndarray objects, we check that operating on the array with zero would always produce a zero.</p>"},{"location":"operations/#reductions","title":"Reductions","text":"<p>COO and GCXS objects support a number of reductions. However, not all important reductions are currently implemented (help welcome!). All of the following currently work:</p> <pre><code>   x.sum(axis=1)\n   np.max(x)\n   np.min(x, axis=(0, 2))\n   x.prod()\n</code></pre> <p>SparseArray.reduce</p> <p>This method can take an arbitrary numpy.ufunc and performs a reduction using that method. For example, the following will perform a sum:</p> <pre><code>   x.reduce(np.add, axis=1)\n</code></pre> <p>Note</p> <p>This library currently performs reductions by grouping together all coordinates along the supplied axes and reducing those. Then, if the number in a group is deficient, it reduces an extra time with zero. As a result, if reductions can change by adding multiple zeros to it, this method won't be accurate. However, it works in most cases.</p> <p>Partial List of Supported Reductions</p> <p>Although any binary numpy.ufunc should work for reductions, when calling in the form <code>x.reduction()</code>, the following reductions are supported:</p> <ul> <li>COO.sum</li> <li>COO.max</li> <li>COO.min</li> <li>COO.prod</li> </ul>"},{"location":"operations/#indexing","title":"Indexing","text":"<p>COO and GCXS arrays can be indexed just like regular numpy.ndarray objects. They support integer, slice and boolean indexing. However, currently, numpy advanced indexing is not properly supported. This means that all of the following work like in Numpy, except that they will produce SparseArray arrays rather than numpy.ndarray objects, and will produce scalars where expected. Assume that <code>z.shape</code> is <code>(5, 6, 7)</code></p> <pre><code>   z[0]\n   z[1, 3]\n   z[1, 4, 3]\n   z[:3, :2, 3]\n   z[::-1, 1, 3]\n   z[-1]\n</code></pre> <p>All of the following will raise an :obj:<code>IndexError</code>, like in Numpy 1.13 and later.</p> <pre><code>   z[6]\n   z[3, 6]\n   z[1, 4, 8]\n   z[-6]\n</code></pre> <p>Advanced Indexing</p> <p>Advanced indexing (indexing arrays with other arrays) is supported, but only for indexing with a single array. Indexing a single array with multiple arrays is not supported at this time. As above, if <code>z.shape</code> is <code>(5, 6, 7)</code>, all of the following will work like NumPy:</p> <pre><code>   z[[0, 1, 2]]\n   z[1, [3]]\n   z[1, 4, [3, 6]]\n   z[:3, :2, [1, 5]]\n</code></pre> <p>Package Configuration</p> <p>By default, when performing something like <code>np.array(COO)</code>, we allow the array to be converted into a dense one. To prevent this and raise a RuntimeError instead, set the environment variable <code>SPARSE_AUTO_DENSIFY</code> to <code>0</code>.</p> <p>If it is desired to raise a warning if creating a sparse array that takes no less memory than an equivalent desne array, set the environment variable <code>SPARSE_WARN_ON_TOO_DENSE</code> to <code>1</code>.</p>"},{"location":"operations/#other-operations","title":"Other Operations","text":"<p>COO and GCXS arrays support a number of other common operations. Among them are dot, tensordot einsum, concatenate and stack, transpose and reshape. You can view the full list on the API reference page.</p> <p>Note</p> <p>Some operations require zero fill-values (such as nonzero) and others (such as concatenate) require that all inputs have consistent fill-values. For details, check the API reference.</p>"},{"location":"quickstart/","title":"Getting Started","text":""},{"location":"quickstart/#install","title":"Install","text":"<p>If you haven't already, install the <code>sparse</code> library</p> <pre><code>   pip install sparse\n</code></pre>"},{"location":"quickstart/#create","title":"Create","text":"<p>To start, lets construct a sparse COO array from a numpy.ndarray:</p> <pre><code>   import numpy as np\n   import sparse\n\n   x = np.random.random((100, 100, 100))\n   x[x &lt; 0.9] = 0  # fill most of the array with zeros\n\n   s = sparse.COO(x)  # convert to sparse array\n</code></pre> <p>These store the same information and support many of the same operations, but the sparse version takes up less space in memory</p> <pre><code>   &gt;&gt;&gt; x.nbytes\n   8000000\n   &gt;&gt;&gt; s.nbytes\n   1102706\n   &gt;&gt;&gt; s\n   &lt;COO: shape=(100, 100, 100), dtype=float64, nnz=100246, fill_value=0.0&gt;\n</code></pre> <p>For more efficient ways to construct sparse arrays, see documentation on Construct sparse arrays.</p>"},{"location":"quickstart/#compute","title":"Compute","text":"<p>Many of the normal Numpy operations work on COO objects just like on numpy.ndarray objects. This includes arithmetic, numpy.ufunc operations, or functions like tensordot and transpose.</p> <pre><code>   &gt;&gt;&gt; np.sin(s) + s.T * 1\n   &lt;COO: shape=(100, 100, 100), dtype=float64, nnz=189601, fill_value=0.0&gt;\n</code></pre> <p>However, operations which map zero elements to nonzero will usually change the fill-value instead of raising an error.</p> <pre><code>   &gt;&gt;&gt; y = s + 5\n   &lt;COO: shape=(100, 100, 100), dtype=float64, nnz=100246, fill_value=5.0&gt;\n</code></pre> <p>However, if you're sure you want to convert a sparse array to a dense one, you can use the <code>todense</code> method (which will result in a numpy.ndarray):</p> <pre><code>   y = s.todense() + 5\n</code></pre> <p>For more operations see the operations or the API reference page.</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>For a brochure version of this roadmap, see this link.</p>"},{"location":"roadmap/#background","title":"Background","text":"<p>The aim of PyData/Sparse is to create sparse containers that implement the ndarray interface. Traditionally in the PyData ecosystem, sparse arrays have been provided by the <code>scipy.sparse</code> submodule. All containers there depend on and emulate the <code>numpy.matrix</code> interface. This means that they are limited to two dimensions and also don\u2019t work well in places where <code>numpy.ndarray</code> would work.</p> <p>PyData/Sparse is well on its way to replacing <code>scipy.sparse</code> as the de-facto sparse array implementation in the PyData ecosystem.</p>"},{"location":"roadmap/#topics","title":"Topics","text":"<ul> <li>More storage formats</li> <li>Better performance/algorithms</li> <li>Covering more of the NumPy API</li> <li>SciPy Integration</li> <li>Dask integration for high scalability</li> <li>CuPy integration for GPU-acceleration</li> <li>Maintenance and General Improvements</li> </ul>"},{"location":"roadmap/#more-storage-formats","title":"More Storage Formats","text":"<p>In the sparse domain, you have to make a choice of format when representing your array in memory, and different formats have different trade-offs. For example:</p> <ul> <li>CSR/CSC are usually expected by external libraries, and have good space characteristics   for most arrays</li> <li>DOK allows in-place modification and writes</li> <li>LIL has faster writes if written to in-order.</li> <li>BSR allows block-writes and reads</li> </ul> <p>The most important formats are, of course, CSR and CSC, because they allow zero-copy interaction with a number of libraries including MKL, LAPACK and others. This will allow PyData/Sparse to quickly reach the functionality of <code>scipy.sparse</code>, accelerating the path to its replacement.</p>"},{"location":"roadmap/#better-performancealgorithms","title":"Better Performance/Algorithms","text":"<p>There are a few places in scipy.sparse where algorithms are sub-optimal, sometimes due to reliance on NumPy which doesn\u2019t have these algorithms. We intend to both improve the algorithms in NumPy, giving the broader community a chance to use them; as well as in PyData/Sparse, to reach optimal efficiency in the broadest use-cases.</p>"},{"location":"roadmap/#covering-more-of-the-numpy-api","title":"Covering More of the NumPy API","text":"<p>Our eventual aim is to cover all areas of NumPy where algorithms exist that give sparse arrays an edge over dense arrays. Currently, PyData/Sparse supports reductions, element-wise functions and other common functions such as stacking, concatenating and tensor products. Common uses of sparse arrays include linear algebra and graph theoretic subroutines, so we plan on covering those first.</p>"},{"location":"roadmap/#scipy-integration","title":"SciPy Integration","text":"<p>PyData/Sparse aims to build containers and elementary operations on them, such as element-wise operations, reductions and so on. We plan on modifying the current graph theoretic subroutines in <code>scipy.sparse.csgraph</code> to support PyData/Sparse arrays. The same applies for linear algebra and <code>scipy.sparse.linalg</code>.</p>"},{"location":"roadmap/#cupy-integration-for-gpu-acceleration","title":"CuPy integration for GPU-acceleration","text":"<p>CuPy is a project that implements a large portion of NumPy\u2019s ndarray interface on GPUs. We plan to integrate with CuPy so that it\u2019s possible to accelerate sparse arrays on GPUs.</p> <p></p>"},{"location":"roadmap/#completed-tasks","title":"Completed Tasks","text":""},{"location":"roadmap/#dask-integration-for-high-scalability","title":"Dask Integration for High Scalability","text":"<p>Dask is a project that takes ndarray style containers and then allows them to scale across multiple cores or clusters. We plan on tighter integration and cooperation with the Dask team to ensure the highest amount of Dask functionality works with sparse arrays.</p> <p>Currently, integration with Dask is supported via array protocols.  When more of the NumPy API (e.g. array creation functions) becomes available through array protocols, it will be automatically be supported by Dask.</p>"},{"location":"roadmap/#partial-scipy-integration","title":"(Partial) SciPy Integration","text":"<p>Support for <code>scipy.sparse.linalg</code> has been completed. We hope to add support for <code>scipy.sparse.csgraph</code> in the future.</p>"},{"location":"roadmap/#more-storage-formats_1","title":"More Storage Formats","text":"<p>GCXS, a compressed n-dimensional array format based on the GCRS/GCCS formats of Shaikh and Hasan 2015, has been added. In conjunction with this work, the CSR/CSC matrix formats have been are now a part of pydata/sparse. We plan to add better-performing algorithms for many of the operations currently supported.</p>"},{"location":"api/BACKEND/","title":"BACKEND","text":""},{"location":"api/BackendType/","title":"BackendType","text":"<p>               Bases: <code>Enum</code></p> Source code in <code>sparse/__init__.py</code> <pre><code>class BackendType(Enum):\n    Numba = \"Numba\"\n    Finch = \"Finch\"\n</code></pre>"},{"location":"api/BackendType/#sparse.BackendType.Numba","title":"<code>Numba = 'Numba'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/BackendType/#sparse.BackendType.Finch","title":"<code>Finch = 'Finch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/COO/","title":"COO","text":"<p>               Bases: <code>SparseArray</code>, <code>NDArrayOperatorsMixin</code></p> <p>A sparse multidimensional array.</p> <p>This is stored in COO format.  It depends on NumPy and Scipy.sparse for computation, but supports arrays of arbitrary dimension.</p> <p>Parameters:</p> Name Type Description Default <code>coords</code> <code>ndarray(ndim, nnz)</code> <p>An array holding the index locations of every value Should have shape (number of dimensions, number of non-zeros).</p> required <code>data</code> <code>ndarray(nnz)</code> <p>An array of Values. A scalar can also be supplied if the data is the same across all coordinates. If not given, defers to as_coo.</p> <code>None</code> <code>shape</code> <code>tuple[int](ndim)</code> <p>The shape of the array.</p> <code>None</code> <code>has_duplicates</code> <code>bool_</code> <p>A value indicating whether the supplied value for coords has duplicates. Note that setting this to <code>False</code> when <code>coords</code> does have duplicates may result in undefined behaviour. See <code>COO.sum_duplicates</code>.</p> <code>True</code> <code>sorted</code> <code>bool_</code> <p>A value indicating whether the values in <code>coords</code> are sorted. Note that setting this to <code>True</code> when coords isn't sorted may result in undefined behaviour. See <code>COO.sort_indices</code>.</p> <code>False</code> <code>prune</code> <code>bool_</code> <p>A flag indicating whether or not we should prune any fill-values present in <code>data</code>.</p> <code>False</code> <code>cache</code> <code>bool_</code> <p>Whether to enable cacheing for various operations. See <code>COO.enable_caching</code>.</p> <code>False</code> <code>fill_value</code> <p>The fill value for this array.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>coords</code> <code>ndarray(ndim, nnz)</code> <p>An array holding the coordinates of every nonzero element.</p> <code>data</code> <code>ndarray(nnz)</code> <p>An array holding the values corresponding to COO.coords.</p> <code>shape</code> <code>tuple[int](ndim)</code> <p>The dimensions of this array.</p> See Also <pre><code>[DOK][sparse.DOK]: A mostly write-only sparse array.\n[as_coo][sparse.as_coo]: Convert any given format to [COO][sparse.COO].\n</code></pre> <p>Examples:</p> <p>You can create COO objects from Numpy arrays.</p> <pre><code>&gt;&gt;&gt; x = np.eye(4, dtype=np.uint8)\n&gt;&gt;&gt; x[2, 3] = 5\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s\n&lt;COO: shape=(4, 4), dtype=uint8, nnz=5, fill_value=0&gt;\n&gt;&gt;&gt; s.data\narray([1, 1, 1, 5, 1], dtype=uint8)\n&gt;&gt;&gt; s.coords\narray([[0, 1, 2, 2, 3],\n       [0, 1, 2, 3, 3]])\n</code></pre> <p>COO objects support basic arithmetic and binary operations.</p> <pre><code>&gt;&gt;&gt; x2 = np.eye(4, dtype=np.uint8)\n&gt;&gt;&gt; x2[3, 2] = 5\n&gt;&gt;&gt; s2 = COO.from_numpy(x2)\n&gt;&gt;&gt; (s + s2).todense()\narray([[2, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 2, 5],\n       [0, 0, 5, 2]], dtype=uint8)\n&gt;&gt;&gt; (s * s2).todense()\narray([[1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1]], dtype=uint8)\n</code></pre> <p>Binary operations support broadcasting.</p> <pre><code>&gt;&gt;&gt; x3 = np.zeros((4, 1), dtype=np.uint8)\n&gt;&gt;&gt; x3[2, 0] = 1\n&gt;&gt;&gt; s3 = COO.from_numpy(x3)\n&gt;&gt;&gt; (s * s3).todense()\narray([[0, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 0, 1, 5],\n       [0, 0, 0, 0]], dtype=uint8)\n</code></pre> <p>COO objects also support dot products and reductions.</p> <pre><code>&gt;&gt;&gt; s.dot(s.T).sum(axis=0).todense()\narray([ 1,  1, 31,  6], dtype=uint64)\n</code></pre> <p>You can use Numpy <code>ufunc</code> operations on COO arrays as well.</p> <pre><code>&gt;&gt;&gt; np.sum(s, axis=1).todense()\narray([1, 1, 6, 1], dtype=uint64)\n&gt;&gt;&gt; np.round(np.sqrt(s, dtype=np.float64), decimals=1).todense()\narray([[ 1. ,  0. ,  0. ,  0. ],\n       [ 0. ,  1. ,  0. ,  0. ],\n       [ 0. ,  0. ,  1. ,  2.2],\n       [ 0. ,  0. ,  0. ,  1. ]])\n</code></pre> <p>Operations that will result in a dense array will usually result in a different fill value, such as the following.</p> <pre><code>&gt;&gt;&gt; np.exp(s)\n&lt;COO: shape=(4, 4), dtype=float16, nnz=5, fill_value=1.0&gt;\n</code></pre> <p>You can also create COO arrays from coordinates and data.</p> <pre><code>&gt;&gt;&gt; coords = [[0, 0, 0, 1, 1], [0, 1, 2, 0, 3], [0, 3, 2, 0, 1]]\n&gt;&gt;&gt; data = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; s4 = COO(coords, data, shape=(3, 4, 5))\n&gt;&gt;&gt; s4\n&lt;COO: shape=(3, 4, 5), dtype=int64, nnz=5, fill_value=0&gt;\n</code></pre> <p>If the data is same across all coordinates, you can also specify a scalar.</p> <pre><code>&gt;&gt;&gt; coords = [[0, 0, 0, 1, 1], [0, 1, 2, 0, 3], [0, 3, 2, 0, 1]]\n&gt;&gt;&gt; data = 1\n&gt;&gt;&gt; s5 = COO(coords, data, shape=(3, 4, 5))\n&gt;&gt;&gt; s5\n&lt;COO: shape=(3, 4, 5), dtype=int64, nnz=5, fill_value=0&gt;\n</code></pre> <p>Following scipy.sparse conventions you can also pass these as a tuple with rows and columns</p> <pre><code>&gt;&gt;&gt; rows = [0, 1, 2, 3, 4]\n&gt;&gt;&gt; cols = [0, 0, 0, 1, 1]\n&gt;&gt;&gt; data = [10, 20, 30, 40, 50]\n&gt;&gt;&gt; z = COO((data, (rows, cols)))\n&gt;&gt;&gt; z.todense()\narray([[10,  0],\n       [20,  0],\n       [30,  0],\n       [ 0, 40],\n       [ 0, 50]])\n</code></pre> <p>You can also pass a dictionary or iterable of index/value pairs. Repeated indices imply summation:</p> <pre><code>&gt;&gt;&gt; d = {(0, 0, 0): 1, (1, 2, 3): 2, (1, 1, 0): 3}\n&gt;&gt;&gt; COO(d)\n&lt;COO: shape=(2, 3, 4), dtype=int64, nnz=3, fill_value=0&gt;\n&gt;&gt;&gt; L = [((0, 0), 1), ((1, 1), 2), ((0, 0), 3)]\n&gt;&gt;&gt; COO(L).todense()\narray([[4, 0],\n       [0, 2]])\n</code></pre> <p>You can convert DOK arrays to COO arrays.</p> <pre><code>&gt;&gt;&gt; from sparse import DOK\n&gt;&gt;&gt; s6 = DOK((5, 5), dtype=np.int64)\n&gt;&gt;&gt; s6[1:3, 1:3] = [[4, 5], [6, 7]]\n&gt;&gt;&gt; s6\n&lt;DOK: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n&gt;&gt;&gt; s7 = s6.asformat(\"coo\")\n&gt;&gt;&gt; s7\n&lt;COO: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n&gt;&gt;&gt; s7.todense()\narray([[0, 0, 0, 0, 0],\n       [0, 4, 5, 0, 0],\n       [0, 6, 7, 0, 0],\n       [0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0]])\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>class COO(SparseArray, NDArrayOperatorsMixin):  # lgtm [py/missing-equals]\n    \"\"\"\n    A sparse multidimensional array.\n\n    This is stored in COO format.  It depends on NumPy and Scipy.sparse for\n    computation, but supports arrays of arbitrary dimension.\n\n    Parameters\n    ----------\n    coords : numpy.ndarray (COO.ndim, COO.nnz)\n        An array holding the index locations of every value\n        Should have shape (number of dimensions, number of non-zeros).\n    data : numpy.ndarray (COO.nnz,)\n        An array of Values. A scalar can also be supplied if the data is the same across\n        all coordinates. If not given, defers to [as_coo][sparse.as_coo].\n    shape : tuple[int] (COO.ndim,)\n        The shape of the array.\n    has_duplicates : bool, optional\n        A value indicating whether the supplied value for [coords][sparse.COO.coords] has\n        duplicates. Note that setting this to `False` when `coords` does have\n        duplicates may result in undefined behaviour. See `COO.sum_duplicates`.\n    sorted : bool, optional\n        A value indicating whether the values in `coords` are sorted. Note\n        that setting this to `True` when [coords][sparse.COO.coords] isn't sorted may\n        result in undefined behaviour. See `COO.sort_indices`.\n    prune : bool, optional\n        A flag indicating whether or not we should prune any fill-values present in\n        `data`.\n    cache : bool, optional\n        Whether to enable cacheing for various operations. See\n        `COO.enable_caching`.\n    fill_value: scalar, optional\n        The fill value for this array.\n\n    Attributes\n    ----------\n    coords : numpy.ndarray (ndim, nnz)\n        An array holding the coordinates of every nonzero element.\n    data : numpy.ndarray (nnz,)\n        An array holding the values corresponding to [COO.coords][sparse.COO.coords].\n    shape : tuple[int] (ndim,)\n        The dimensions of this array.\n\n    See Also\n    --------\n        [DOK][sparse.DOK]: A mostly write-only sparse array.\n        [as_coo][sparse.as_coo]: Convert any given format to [COO][sparse.COO].\n\n    Examples\n    --------\n    You can create [COO][sparse.COO] objects from Numpy arrays.\n\n    &gt;&gt;&gt; x = np.eye(4, dtype=np.uint8)\n    &gt;&gt;&gt; x[2, 3] = 5\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s\n    &lt;COO: shape=(4, 4), dtype=uint8, nnz=5, fill_value=0&gt;\n    &gt;&gt;&gt; s.data  # doctest: +NORMALIZE_WHITESPACE\n    array([1, 1, 1, 5, 1], dtype=uint8)\n    &gt;&gt;&gt; s.coords  # doctest: +NORMALIZE_WHITESPACE\n    array([[0, 1, 2, 2, 3],\n           [0, 1, 2, 3, 3]])\n\n    [COO][sparse.COO] objects support basic arithmetic and binary operations.\n\n    &gt;&gt;&gt; x2 = np.eye(4, dtype=np.uint8)\n    &gt;&gt;&gt; x2[3, 2] = 5\n    &gt;&gt;&gt; s2 = COO.from_numpy(x2)\n    &gt;&gt;&gt; (s + s2).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[2, 0, 0, 0],\n           [0, 2, 0, 0],\n           [0, 0, 2, 5],\n           [0, 0, 5, 2]], dtype=uint8)\n    &gt;&gt;&gt; (s * s2).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[1, 0, 0, 0],\n           [0, 1, 0, 0],\n           [0, 0, 1, 0],\n           [0, 0, 0, 1]], dtype=uint8)\n\n    Binary operations support broadcasting.\n\n    &gt;&gt;&gt; x3 = np.zeros((4, 1), dtype=np.uint8)\n    &gt;&gt;&gt; x3[2, 0] = 1\n    &gt;&gt;&gt; s3 = COO.from_numpy(x3)\n    &gt;&gt;&gt; (s * s3).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[0, 0, 0, 0],\n           [0, 0, 0, 0],\n           [0, 0, 1, 5],\n           [0, 0, 0, 0]], dtype=uint8)\n\n    [COO][sparse.COO] objects also support dot products and reductions.\n\n    &gt;&gt;&gt; s.dot(s.T).sum(axis=0).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([ 1,  1, 31,  6], dtype=uint64)\n\n    You can use Numpy `ufunc` operations on [COO][sparse.COO] arrays as well.\n\n    &gt;&gt;&gt; np.sum(s, axis=1).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([1, 1, 6, 1], dtype=uint64)\n    &gt;&gt;&gt; np.round(np.sqrt(s, dtype=np.float64), decimals=1).todense()  # doctest: +SKIP\n    array([[ 1. ,  0. ,  0. ,  0. ],\n           [ 0. ,  1. ,  0. ,  0. ],\n           [ 0. ,  0. ,  1. ,  2.2],\n           [ 0. ,  0. ,  0. ,  1. ]])\n\n    Operations that will result in a dense array will usually result in a different\n    fill value, such as the following.\n\n    &gt;&gt;&gt; np.exp(s)\n    &lt;COO: shape=(4, 4), dtype=float16, nnz=5, fill_value=1.0&gt;\n\n    You can also create [COO][sparse.COO] arrays from coordinates and data.\n\n    &gt;&gt;&gt; coords = [[0, 0, 0, 1, 1], [0, 1, 2, 0, 3], [0, 3, 2, 0, 1]]\n    &gt;&gt;&gt; data = [1, 2, 3, 4, 5]\n    &gt;&gt;&gt; s4 = COO(coords, data, shape=(3, 4, 5))\n    &gt;&gt;&gt; s4\n    &lt;COO: shape=(3, 4, 5), dtype=int64, nnz=5, fill_value=0&gt;\n\n    If the data is same across all coordinates, you can also specify a scalar.\n\n    &gt;&gt;&gt; coords = [[0, 0, 0, 1, 1], [0, 1, 2, 0, 3], [0, 3, 2, 0, 1]]\n    &gt;&gt;&gt; data = 1\n    &gt;&gt;&gt; s5 = COO(coords, data, shape=(3, 4, 5))\n    &gt;&gt;&gt; s5\n    &lt;COO: shape=(3, 4, 5), dtype=int64, nnz=5, fill_value=0&gt;\n\n    Following scipy.sparse conventions you can also pass these as a tuple with\n    rows and columns\n\n    &gt;&gt;&gt; rows = [0, 1, 2, 3, 4]\n    &gt;&gt;&gt; cols = [0, 0, 0, 1, 1]\n    &gt;&gt;&gt; data = [10, 20, 30, 40, 50]\n    &gt;&gt;&gt; z = COO((data, (rows, cols)))\n    &gt;&gt;&gt; z.todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[10,  0],\n           [20,  0],\n           [30,  0],\n           [ 0, 40],\n           [ 0, 50]])\n\n    You can also pass a dictionary or iterable of index/value pairs. Repeated\n    indices imply summation:\n\n    &gt;&gt;&gt; d = {(0, 0, 0): 1, (1, 2, 3): 2, (1, 1, 0): 3}\n    &gt;&gt;&gt; COO(d)\n    &lt;COO: shape=(2, 3, 4), dtype=int64, nnz=3, fill_value=0&gt;\n    &gt;&gt;&gt; L = [((0, 0), 1), ((1, 1), 2), ((0, 0), 3)]\n    &gt;&gt;&gt; COO(L).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[4, 0],\n           [0, 2]])\n\n    You can convert [DOK][sparse.DOK] arrays to [COO][sparse.COO] arrays.\n\n    &gt;&gt;&gt; from sparse import DOK\n    &gt;&gt;&gt; s6 = DOK((5, 5), dtype=np.int64)\n    &gt;&gt;&gt; s6[1:3, 1:3] = [[4, 5], [6, 7]]\n    &gt;&gt;&gt; s6\n    &lt;DOK: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n    &gt;&gt;&gt; s7 = s6.asformat(\"coo\")\n    &gt;&gt;&gt; s7\n    &lt;COO: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n    &gt;&gt;&gt; s7.todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[0, 0, 0, 0, 0],\n           [0, 4, 5, 0, 0],\n           [0, 6, 7, 0, 0],\n           [0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0]])\n    \"\"\"\n\n    __array_priority__ = 12\n\n    def __init__(\n        self,\n        coords,\n        data=None,\n        shape=None,\n        has_duplicates=True,\n        sorted=False,\n        prune=False,\n        cache=False,\n        fill_value=None,\n        idx_dtype=None,\n    ):\n        self._cache = None\n        if cache:\n            self.enable_caching()\n\n        if not isinstance(coords, np.ndarray):\n            warnings.warn(\n                \"coords should be an ndarray. This will raise a ValueError in the future.\",\n                DeprecationWarning,\n                stacklevel=1,\n            )\n\n        if data is None:\n            arr = as_coo(coords, shape=shape, fill_value=fill_value, idx_dtype=idx_dtype)\n            self._make_shallow_copy_of(arr)\n            if cache:\n                self.enable_caching()\n            return\n\n        self.data = np.asarray(data)\n        self.coords = np.asarray(coords)\n\n        if self.coords.ndim == 1:\n            if self.coords.size == 0 and shape is not None:\n                self.coords = self.coords.reshape((len(shape), len(data)))\n            else:\n                self.coords = self.coords[None, :]\n\n        if self.data.ndim == 0:\n            self.data = np.broadcast_to(self.data, self.coords.shape[1])\n\n        if self.data.ndim != 1:\n            raise ValueError(\"data must be a scalar or 1-dimensional.\")\n\n        if shape is None:\n            warnings.warn(\n                \"shape should be provided. This will raise a ValueError in the future.\",\n                DeprecationWarning,\n                stacklevel=1,\n            )\n            shape = tuple(self.coords.max(axis=1) + 1) if self.coords.nbytes else ()\n\n        if not isinstance(shape, Iterable):\n            shape = (shape,)\n\n        if isinstance(shape, np.ndarray):\n            shape = tuple(shape)\n\n        if shape and not self.coords.size:\n            self.coords = np.zeros((len(shape) if isinstance(shape, Iterable) else 1, 0), dtype=np.intp)\n\n        super().__init__(shape, fill_value=fill_value)\n        if idx_dtype:\n            if not can_store(idx_dtype, max(shape)):\n                raise ValueError(f\"cannot cast array with shape {shape} to dtype {idx_dtype}.\")\n            self.coords = self.coords.astype(idx_dtype)\n\n        if self.shape:\n            if len(self.data) != self.coords.shape[1]:\n                msg = \"The data length does not match the coordinates given.\\nlen(data) = {}, but {} coords specified.\"\n                raise ValueError(msg.format(len(data), self.coords.shape[1]))\n            if len(self.shape) != self.coords.shape[0]:\n                msg = (\n                    \"Shape specified by `shape` doesn't match the \"\n                    \"shape of `coords`; len(shape)={} != coords.shape[0]={}\"\n                    \"(and coords.shape={})\"\n                )\n                raise ValueError(msg.format(len(shape), self.coords.shape[0], self.coords.shape))\n\n        from .._settings import WARN_ON_TOO_DENSE\n\n        if WARN_ON_TOO_DENSE and self.nbytes &gt;= self.size * self.data.itemsize:\n            warnings.warn(\n                \"Attempting to create a sparse array that takes no less \"\n                \"memory than than an equivalent dense array. You may want to \"\n                \"use a dense array here instead.\",\n                RuntimeWarning,\n                stacklevel=1,\n            )\n\n        if not sorted:\n            self._sort_indices()\n\n        if has_duplicates:\n            self._sum_duplicates()\n\n        if prune:\n            self._prune()\n\n    def __getstate__(self):\n        return (self.coords, self.data, self.shape, self.fill_value)\n\n    def __setstate__(self, state):\n        self.coords, self.data, self.shape, self.fill_value = state\n        self._cache = None\n\n    def __dask_tokenize__(self):\n        \"Produce a deterministic, content-based hash for dask.\"\n        from dask.base import normalize_token\n\n        return normalize_token((type(self), self.coords, self.data, self.shape, self.fill_value))\n\n    def copy(self, deep=True):\n        \"\"\"Return a copy of the array.\n\n        Parameters\n        ----------\n        deep : boolean, optional\n            If True (default), the internal coords and data arrays are also\n            copied. Set to ``False`` to only make a shallow copy.\n        \"\"\"\n        return _copy.deepcopy(self) if deep else _copy.copy(self)\n\n    def enable_caching(self):\n        \"\"\"Enable caching of reshape, transpose, and tocsr/csc operations\n\n        This enables efficient iterative workflows that make heavy use of\n        csr/csc operations, such as tensordot.  This maintains a cache of\n        recent results of reshape and transpose so that operations like\n        tensordot (which uses both internally) store efficiently stored\n        representations for repeated use.  This can significantly cut down on\n        computational costs in common numeric algorithms.\n\n        However, this also assumes that neither this object, nor the downstream\n        objects will have their data mutated.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s.enable_caching()  # doctest: +SKIP\n        &gt;&gt;&gt; csr1 = s.transpose((2, 0, 1)).reshape((100, 120)).tocsr()  # doctest: +SKIP\n        &gt;&gt;&gt; csr2 = s.transpose((2, 0, 1)).reshape((100, 120)).tocsr()  # doctest: +SKIP\n        &gt;&gt;&gt; csr1 is csr2  # doctest: +SKIP\n        True\n        \"\"\"\n        self._cache = defaultdict(lambda: deque(maxlen=3))\n\n    @classmethod\n    def from_numpy(cls, x, fill_value=None, idx_dtype=None):\n        \"\"\"\n        Convert the given :obj:`numpy.ndarray` to a :obj:`COO` object.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            The dense array to convert.\n        fill_value : scalar\n            The fill value of the constructed :obj:`COO` array. Zero if\n            unspecified.\n\n        Returns\n        -------\n        COO\n            The converted COO array.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = np.eye(5)\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s\n        &lt;COO: shape=(5, 5), dtype=float64, nnz=5, fill_value=0.0&gt;\n\n        &gt;&gt;&gt; x[x == 0] = np.nan\n        &gt;&gt;&gt; COO.from_numpy(x, fill_value=np.nan)\n        &lt;COO: shape=(5, 5), dtype=float64, nnz=5, fill_value=nan&gt;\n        \"\"\"\n        x = np.asanyarray(x).view(type=np.ndarray)\n\n        if fill_value is None:\n            fill_value = _zero_of_dtype(x.dtype) if x.shape else x\n\n        coords = np.atleast_2d(np.flatnonzero(~equivalent(x, fill_value)))\n        data = x.ravel()[tuple(coords)]\n        return cls(\n            coords,\n            data,\n            shape=x.size,\n            has_duplicates=False,\n            sorted=True,\n            fill_value=fill_value,\n            idx_dtype=idx_dtype,\n        ).reshape(x.shape)\n\n    def todense(self):\n        \"\"\"\n        Convert this :obj:`COO` array to a dense :obj:`numpy.ndarray`. Note that\n        this may take a large amount of memory if the :obj:`COO` object's :code:`shape`\n        is large.\n\n        Returns\n        -------\n        numpy.ndarray\n            The converted dense array.\n\n        See Also\n        --------\n        DOK.todense : Equivalent :obj:`DOK` array method.\n        scipy.sparse.coo_matrix.todense : Equivalent Scipy method.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = np.random.randint(100, size=(7, 3))\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; x2 = s.todense()\n        &gt;&gt;&gt; np.array_equal(x, x2)\n        True\n        \"\"\"\n        x = np.full(self.shape, self.fill_value, self.dtype)\n\n        coords = tuple([self.coords[i, :] for i in range(self.ndim)])\n        data = self.data\n\n        if coords != ():\n            x[coords] = data\n        else:\n            if len(data) != 0:\n                x[coords] = data\n\n        return x\n\n    @classmethod\n    def from_scipy_sparse(cls, x, /, *, fill_value=None):\n        \"\"\"\n        Construct a :obj:`COO` array from a :obj:`scipy.sparse.spmatrix`\n\n        Parameters\n        ----------\n        x : scipy.sparse.spmatrix\n            The sparse matrix to construct the array from.\n        fill_value : scalar\n            The fill-value to use when converting.\n\n        Returns\n        -------\n        COO\n            The converted :obj:`COO` object.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = scipy.sparse.rand(6, 3, density=0.2)\n        &gt;&gt;&gt; s = COO.from_scipy_sparse(x)\n        &gt;&gt;&gt; np.array_equal(x.todense(), s.todense())\n        True\n        \"\"\"\n        x = x.asformat(\"coo\")\n        coords = np.empty((2, x.nnz), dtype=x.row.dtype)\n        coords[0, :] = x.row\n        coords[1, :] = x.col\n        return COO(\n            coords,\n            x.data,\n            shape=x.shape,\n            has_duplicates=not x.has_canonical_format,\n            sorted=x.has_canonical_format,\n            fill_value=fill_value,\n        )\n\n    @classmethod\n    def from_iter(cls, x, shape=None, fill_value=None, dtype=None):\n        \"\"\"\n        Converts an iterable in certain formats to a :obj:`COO` array. See examples\n        for details.\n\n        Parameters\n        ----------\n        x : Iterable or Iterator\n            The iterable to convert to :obj:`COO`.\n        shape : tuple[int], optional\n            The shape of the array.\n        fill_value : scalar\n            The fill value for this array.\n        dtype : numpy.dtype\n            The dtype of the input array. Inferred from the input if not given.\n\n        Returns\n        -------\n        out : COO\n            The output :obj:`COO` array.\n\n        Examples\n        --------\n        You can convert items of the format ``[((i, j, k), value), ((i, j, k), value)]`` to :obj:`COO`.\n        Here, the first part represents the coordinate and the second part represents the value.\n\n        &gt;&gt;&gt; x = [((0, 0), 1), ((1, 1), 1)]\n        &gt;&gt;&gt; s = COO.from_iter(x)\n        &gt;&gt;&gt; s.todense()\n        array([[1, 0],\n               [0, 1]])\n\n        You can also have a similar format with a dictionary.\n\n        &gt;&gt;&gt; x = {(0, 0): 1, (1, 1): 1}\n        &gt;&gt;&gt; s = COO.from_iter(x)\n        &gt;&gt;&gt; s.todense()\n        array([[1, 0],\n               [0, 1]])\n\n        The third supported format is ``(data, (..., row, col))``.\n\n        &gt;&gt;&gt; x = ([1, 1], ([0, 1], [0, 1]))\n        &gt;&gt;&gt; s = COO.from_iter(x)\n        &gt;&gt;&gt; s.todense()\n        array([[1, 0],\n               [0, 1]])\n\n        You can also pass in a :obj:`collections.Iterator` object.\n\n        &gt;&gt;&gt; x = [((0, 0), 1), ((1, 1), 1)].__iter__()\n        &gt;&gt;&gt; s = COO.from_iter(x)\n        &gt;&gt;&gt; s.todense()\n        array([[1, 0],\n               [0, 1]])\n        \"\"\"\n        if isinstance(x, dict):\n            x = list(x.items())\n\n        if not isinstance(x, Sized):\n            x = list(x)\n\n        if len(x) != 2 and not all(len(item) == 2 for item in x):\n            raise ValueError(\"Invalid iterable to convert to COO.\")\n\n        if not x:\n            ndim = 0 if shape is None else len(shape)\n            coords = np.empty((ndim, 0), dtype=np.uint8)\n            data = np.empty((0,), dtype=dtype)\n            shape = () if shape is None else shape\n\n        elif not isinstance(x[0][0], Iterable):\n            coords = np.stack(x[1], axis=0)\n            data = np.asarray(x[0], dtype=dtype)\n        else:\n            coords = np.array([item[0] for item in x]).T\n            data = np.array([item[1] for item in x], dtype=dtype)\n\n        if not (\n            coords.ndim == 2 and data.ndim == 1 and np.issubdtype(coords.dtype, np.integer) and np.all(coords &gt;= 0)\n        ):\n            raise ValueError(\"Invalid iterable to convert to COO.\")\n\n        return COO(coords, data, shape=shape, fill_value=fill_value)\n\n    @property\n    def dtype(self):\n        \"\"\"\n        The datatype of this array.\n\n        Returns\n        -------\n        numpy.dtype\n            The datatype of this array.\n\n        See Also\n        --------\n        numpy.ndarray.dtype : Numpy equivalent property.\n        scipy.sparse.coo_matrix.dtype : Scipy equivalent property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = (200 * np.random.rand(5, 4)).astype(np.int32)\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.dtype\n        dtype('int32')\n        &gt;&gt;&gt; x.dtype == s.dtype\n        True\n        \"\"\"\n        return self.data.dtype\n\n    @property\n    def nnz(self):\n        \"\"\"\n        The number of nonzero elements in this array. Note that any duplicates in\n        :code:`coords` are counted multiple times. To avoid this, call :obj:`COO.sum_duplicates`.\n\n        Returns\n        -------\n        int\n            The number of nonzero elements in this array.\n\n        See Also\n        --------\n        DOK.nnz : Equivalent :obj:`DOK` array property.\n        numpy.count_nonzero : A similar Numpy function.\n        scipy.sparse.coo_matrix.nnz : The Scipy equivalent property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = np.array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0])\n        &gt;&gt;&gt; np.count_nonzero(x)\n        6\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.nnz\n        6\n        &gt;&gt;&gt; np.count_nonzero(x) == s.nnz\n        True\n        \"\"\"\n        return self.coords.shape[1]\n\n    @property\n    def format(self):\n        \"\"\"\n        The storage format of this array.\n        Returns\n        -------\n        str\n            The storage format of this array.\n        See Also\n        -------\n        scipy.sparse.dok_matrix.format : The Scipy equivalent property.\n        Examples\n        -------\n        &gt;&gt;&gt; import sparse\n        &gt;&gt;&gt; s = sparse.random((5, 5), density=0.2, format=\"dok\")\n        &gt;&gt;&gt; s.format\n        'dok'\n        &gt;&gt;&gt; t = sparse.random((5, 5), density=0.2, format=\"coo\")\n        &gt;&gt;&gt; t.format\n        'coo'\n        \"\"\"\n        return \"coo\"\n\n    @property\n    def nbytes(self):\n        \"\"\"\n        The number of bytes taken up by this object. Note that for small arrays,\n        this may undercount the number of bytes due to the large constant overhead.\n\n        Returns\n        -------\n        int\n            The approximate bytes of memory taken by this object.\n\n        See Also\n        --------\n        numpy.ndarray.nbytes : The equivalent Numpy property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; data = np.arange(6, dtype=np.uint8)\n        &gt;&gt;&gt; coords = np.random.randint(1000, size=(3, 6), dtype=np.uint16)\n        &gt;&gt;&gt; s = COO(coords, data, shape=(1000, 1000, 1000))\n        &gt;&gt;&gt; s.nbytes\n        42\n        \"\"\"\n        return self.data.nbytes + self.coords.nbytes\n\n    def __len__(self):\n        \"\"\"\n        Get \"length\" of array, which is by definition the size of the first\n        dimension.\n\n        Returns\n        -------\n        int\n            The size of the first dimension.\n\n        See Also\n        --------\n        numpy.ndarray.__len__ : Numpy equivalent property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = np.zeros((10, 10))\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; len(s)\n        10\n        \"\"\"\n        return self.shape[0]\n\n    def __sizeof__(self):\n        return self.nbytes\n\n    __getitem__ = getitem\n\n    def __str__(self):\n        summary = f\"&lt;COO: shape={self.shape!s}, dtype={self.dtype!s}, nnz={self.nnz:d}, fill_value={self.fill_value!s}&gt;\"\n        return self._str_impl(summary)\n\n    __repr__ = __str__\n\n    def _reduce_calc(self, method, axis, keepdims=False, **kwargs):\n        if axis == (None,):\n            axis = tuple(range(self.ndim))\n        axis = tuple(a if a &gt;= 0 else a + self.ndim for a in axis)\n        neg_axis = tuple(ax for ax in range(self.ndim) if ax not in set(axis))\n        a = self.transpose(neg_axis + axis)\n        a = a.reshape(\n            (\n                np.prod([self.shape[d] for d in neg_axis], dtype=np.intp),\n                np.prod([self.shape[d] for d in axis], dtype=np.intp),\n            )\n        )\n        data, inv_idx, counts = _grouped_reduce(a.data, a.coords[0], method, **kwargs)\n        n_cols = a.shape[1]\n        arr_attrs = (a, neg_axis, inv_idx)\n        return (data, counts, axis, n_cols, arr_attrs)\n\n    def _reduce_return(self, data, arr_attrs, result_fill_value):\n        a, neg_axis, inv_idx = arr_attrs\n        coords = a.coords[0:1, inv_idx]\n        out = COO(\n            coords,\n            data,\n            shape=(a.shape[0],),\n            has_duplicates=False,\n            sorted=True,\n            prune=True,\n            fill_value=result_fill_value,\n        )\n\n        return out.reshape(tuple(self.shape[d] for d in neg_axis))\n\n    def transpose(self, axes=None):\n        \"\"\"\n        Returns a new array which has the order of the axes switched.\n\n        Parameters\n        ----------\n        axes : Iterable[int], optional\n            The new order of the axes compared to the previous one. Reverses the axes\n            by default.\n\n        Returns\n        -------\n        COO\n            The new array with the axes in the desired order.\n\n        See Also\n        --------\n        :obj:`COO.T` : A quick property to reverse the order of the axes.\n        numpy.ndarray.transpose : Numpy equivalent function.\n\n        Examples\n        --------\n        We can change the order of the dimensions of any :obj:`COO` array with this\n        function.\n\n        &gt;&gt;&gt; x = np.add.outer(np.arange(5), np.arange(5)[::-1])\n        &gt;&gt;&gt; x  # doctest: +NORMALIZE_WHITESPACE\n        array([[4, 3, 2, 1, 0],\n               [5, 4, 3, 2, 1],\n               [6, 5, 4, 3, 2],\n               [7, 6, 5, 4, 3],\n               [8, 7, 6, 5, 4]])\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.transpose((1, 0)).todense()  # doctest: +NORMALIZE_WHITESPACE\n        array([[4, 5, 6, 7, 8],\n               [3, 4, 5, 6, 7],\n               [2, 3, 4, 5, 6],\n               [1, 2, 3, 4, 5],\n               [0, 1, 2, 3, 4]])\n\n        Note that by default, this reverses the order of the axes rather than switching\n        the last and second-to-last axes as required by some linear algebra operations.\n\n        &gt;&gt;&gt; x = np.random.rand(2, 3, 4)\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.transpose().shape\n        (4, 3, 2)\n        \"\"\"\n        if axes is None:\n            axes = list(reversed(range(self.ndim)))\n\n        # Normalize all axes indices to positive values\n        axes = normalize_axis(axes, self.ndim)\n\n        if len(np.unique(axes)) &lt; len(axes):\n            raise ValueError(\"repeated axis in transpose\")\n\n        if not len(axes) == self.ndim:\n            raise ValueError(\"axes don't match array\")\n\n        axes = tuple(axes)\n\n        if axes == tuple(range(self.ndim)):\n            return self\n\n        if self._cache is not None:\n            for ax, value in self._cache[\"transpose\"]:\n                if ax == axes:\n                    return value\n\n        shape = tuple(self.shape[ax] for ax in axes)\n        result = COO(\n            self.coords[axes, :],\n            self.data,\n            shape,\n            has_duplicates=False,\n            cache=self._cache is not None,\n            fill_value=self.fill_value,\n        )\n\n        if self._cache is not None:\n            self._cache[\"transpose\"].append((axes, result))\n        return result\n\n    @property\n    def T(self):\n        \"\"\"\n        Returns a new array which has the order of the axes reversed.\n\n        Returns\n        -------\n        COO\n            The new array with the axes in the desired order.\n\n        See Also\n        --------\n        :obj:`COO.transpose` :\n            A method where you can specify the order of the axes.\n        numpy.ndarray.T :\n            Numpy equivalent property.\n\n        Examples\n        --------\n        We can change the order of the dimensions of any :obj:`COO` array with this\n        function.\n\n        &gt;&gt;&gt; x = np.add.outer(np.arange(5), np.arange(5)[::-1])\n        &gt;&gt;&gt; x  # doctest: +NORMALIZE_WHITESPACE\n        array([[4, 3, 2, 1, 0],\n               [5, 4, 3, 2, 1],\n               [6, 5, 4, 3, 2],\n               [7, 6, 5, 4, 3],\n               [8, 7, 6, 5, 4]])\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.T.todense()  # doctest: +NORMALIZE_WHITESPACE\n        array([[4, 5, 6, 7, 8],\n               [3, 4, 5, 6, 7],\n               [2, 3, 4, 5, 6],\n               [1, 2, 3, 4, 5],\n               [0, 1, 2, 3, 4]])\n\n        Note that by default, this reverses the order of the axes rather than switching\n        the last and second-to-last axes as required by some linear algebra operations.\n\n        &gt;&gt;&gt; x = np.random.rand(2, 3, 4)\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.T.shape\n        (4, 3, 2)\n        \"\"\"\n        return self.transpose(tuple(range(self.ndim))[::-1])\n\n    @property\n    def mT(self):\n        if self.ndim &lt; 2:\n            raise ValueError(\"Cannot compute matrix transpose if `ndim &lt; 2`.\")\n\n        axis = list(range(self.ndim))\n        axis[-1], axis[-2] = axis[-2], axis[-1]\n\n        return self.transpose(axis)\n\n    def swapaxes(self, axis1, axis2):\n        \"\"\"Returns array that has axes axis1 and axis2 swapped.\n\n        Parameters\n        ----------\n        axis1 : int\n            first axis to swap\n        axis2 : int\n            second axis to swap\n\n        Returns\n        -------\n        COO\n            The new array with the axes axis1 and axis2 swapped.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = COO.from_numpy(np.ones((2, 3, 4)))\n        &gt;&gt;&gt; x.swapaxes(0, 2)\n        &lt;COO: shape=(4, 3, 2), dtype=float64, nnz=24, fill_value=0.0&gt;\n        \"\"\"\n        # Normalize all axis1, axis2 to positive values\n        axis1, axis2 = normalize_axis((axis1, axis2), self.ndim)  # checks if axis1,2 are in range + raises ValueError\n        axes = list(range(self.ndim))\n        axes[axis1], axes[axis2] = axes[axis2], axes[axis1]\n        return self.transpose(axes)\n\n    def dot(self, other):\n        \"\"\"\n        Performs the equivalent of :code:`x.dot(y)` for :obj:`COO`.\n\n        Parameters\n        ----------\n        other : Union[COO, numpy.ndarray, scipy.sparse.spmatrix]\n            The second operand of the dot product operation.\n\n        Returns\n        -------\n        {COO, numpy.ndarray}\n            The result of the dot product. If the result turns out to be dense,\n            then a dense array is returned, otherwise, a sparse array.\n\n        Raises\n        ------\n        ValueError\n            If all arguments don't have zero fill-values.\n\n        See Also\n        --------\n        dot : Equivalent function for two arguments.\n        :obj:`numpy.dot` : Numpy equivalent function.\n        scipy.sparse.coo_matrix.dot : Scipy equivalent function.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = np.arange(4).reshape((2, 2))\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.dot(s)  # doctest: +SKIP\n        array([[ 2,  3],\n               [ 6, 11]], dtype=int64)\n        \"\"\"\n        from .._common import dot\n\n        return dot(self, other)\n\n    def __matmul__(self, other):\n        from .._common import matmul\n\n        try:\n            return matmul(self, other)\n        except NotImplementedError:\n            return NotImplemented\n\n    def __rmatmul__(self, other):\n        from .._common import matmul\n\n        try:\n            return matmul(other, self)\n        except NotImplementedError:\n            return NotImplemented\n\n    def linear_loc(self):\n        \"\"\"\n        The nonzero coordinates of a flattened version of this array. Note that\n        the coordinates may be out of order.\n\n        Returns\n        -------\n        numpy.ndarray\n            The flattened coordinates.\n\n        See Also\n        --------\n        :obj:`numpy.flatnonzero` : Equivalent Numpy function.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = np.eye(5)\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.linear_loc()  # doctest: +NORMALIZE_WHITESPACE\n        array([ 0,  6, 12, 18, 24])\n        &gt;&gt;&gt; np.array_equal(np.flatnonzero(x), s.linear_loc())\n        True\n        \"\"\"\n        from .common import linear_loc\n\n        return linear_loc(self.coords, self.shape)\n\n    def flatten(self, order=\"C\"):\n        \"\"\"\n        Returns a new :obj:`COO` array that is a flattened version of this array.\n\n        Returns\n        -------\n        COO\n            The flattened output array.\n\n        Notes\n        -----\n        The :code:`order` parameter is provided just for compatibility with\n        Numpy and isn't actually supported.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = COO.from_numpy(np.arange(10))\n        &gt;&gt;&gt; s2 = s.reshape((2, 5)).flatten()\n        &gt;&gt;&gt; s2.todense()\n        array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n        \"\"\"\n        if order not in {\"C\", None}:\n            raise NotImplementedError(\"The `order` parameter is notsupported.\")\n\n        return self.reshape(-1)\n\n    def reshape(self, shape, order=\"C\"):\n        \"\"\"\n        Returns a new :obj:`COO` array that is a reshaped version of this array.\n\n        Parameters\n        ----------\n        shape : tuple[int]\n            The desired shape of the output array.\n\n        Returns\n        -------\n        COO\n            The reshaped output array.\n\n        See Also\n        --------\n        numpy.ndarray.reshape : The equivalent Numpy function.\n\n        Notes\n        -----\n        The :code:`order` parameter is provided just for compatibility with\n        Numpy and isn't actually supported.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = COO.from_numpy(np.arange(25))\n        &gt;&gt;&gt; s2 = s.reshape((5, 5))\n        &gt;&gt;&gt; s2.todense()  # doctest: +NORMALIZE_WHITESPACE\n        array([[ 0,  1,  2,  3,  4],\n               [ 5,  6,  7,  8,  9],\n               [10, 11, 12, 13, 14],\n               [15, 16, 17, 18, 19],\n               [20, 21, 22, 23, 24]])\n        \"\"\"\n        shape = tuple(shape) if isinstance(shape, Iterable) else (shape,)\n\n        if order not in {\"C\", None}:\n            raise NotImplementedError(\"The `order` parameter is not supported\")\n\n        if self.shape == shape:\n            return self\n        if any(d == -1 for d in shape):\n            extra = int(self.size / np.prod([d for d in shape if d != -1]))\n            shape = tuple([d if d != -1 else extra for d in shape])\n\n        if self.size != reduce(operator.mul, shape, 1):\n            raise ValueError(f\"cannot reshape array of size {self.size} into shape {shape}\")\n\n        if self._cache is not None:\n            for sh, value in self._cache[\"reshape\"]:\n                if sh == shape:\n                    return value\n\n        # TODO: this self.size enforces a 2**64 limit to array size\n        linear_loc = self.linear_loc()\n\n        idx_dtype = self.coords.dtype\n        if shape != () and not can_store(idx_dtype, max(shape)):\n            idx_dtype = np.min_scalar_type(max(shape))\n        coords = np.empty((len(shape), self.nnz), dtype=idx_dtype)\n        strides = 1\n        for i, d in enumerate(shape[::-1]):\n            coords[-(i + 1), :] = (linear_loc // strides) % d\n            strides *= d\n\n        result = COO(\n            coords,\n            self.data,\n            shape,\n            has_duplicates=False,\n            sorted=True,\n            cache=self._cache is not None,\n            fill_value=self.fill_value,\n        )\n\n        if self._cache is not None:\n            self._cache[\"reshape\"].append((shape, result))\n        return result\n\n    def squeeze(self, axis=None):\n        \"\"\"\n        Removes singleton dimensions (axes) from ``x``.\n        Parameters\n        ----------\n        axis : Union[None, int, Tuple[int, ...]]\n            The axis (or axes) to squeeze. If a specified axis has a size greater than one,\n            a `ValueError` is raised. ``axis=None`` removes all singleton dimensions.\n            Default: ``None``.\n        Returns\n        -------\n        COO\n            The output array without ``axis`` dimensions.\n        Examples\n        --------\n        &gt;&gt;&gt; s = COO.from_numpy(np.eye(2)).reshape((2, 1, 2, 1))\n        &gt;&gt;&gt; s.squeeze().shape\n        (2, 2)\n        &gt;&gt;&gt; s.squeeze(axis=1).shape\n        (2, 2, 1)\n        \"\"\"\n        squeezable_dims = tuple([d for d in range(self.ndim) if self.shape[d] == 1])\n\n        if axis is None:\n            axis = squeezable_dims\n        if isinstance(axis, int):\n            axis = (axis,)\n        elif isinstance(axis, Iterable):\n            axis = tuple(axis)\n        else:\n            raise ValueError(f\"Invalid axis parameter: `{axis}`.\")\n\n        for d in axis:\n            if d not in squeezable_dims:\n                raise ValueError(f\"Specified axis `{d}` has a size greater than one: {self.shape[d]}\")\n\n        retained_dims = [d for d in range(self.ndim) if d not in axis]\n\n        coords = self.coords[retained_dims, :]\n        shape = tuple([s for idx, s in enumerate(self.shape) if idx in retained_dims])\n\n        return COO(\n            coords,\n            self.data,\n            shape,\n            has_duplicates=False,\n            sorted=True,\n            cache=self._cache is not None,\n            fill_value=self.fill_value,\n        )\n\n    def resize(self, *args, refcheck=True, coords_dtype=np.intp):\n        \"\"\"\n        This method changes the shape and size of an array in-place.\n        Parameters\n        ----------\n        args : tuple, or series of integers\n            The desired shape of the output array.\n\n        See Also\n        --------\n        numpy.ndarray.resize : The equivalent Numpy function.\n\n        \"\"\"\n        warnings.warn(\"resize is deprecated on all SpraseArray objects.\", DeprecationWarning, stacklevel=1)\n        if len(args) == 1 and isinstance(args[0], tuple):\n            shape = args[0]\n        elif all(isinstance(arg, int) for arg in args):\n            shape = tuple(args)\n        else:\n            raise ValueError(\"Invalid input\")\n\n        if any(d &lt; 0 for d in shape):\n            raise ValueError(\"negative dimensions not allowed\")\n\n        new_size = reduce(operator.mul, shape, 1)\n\n        # TODO: this self.size enforces a 2**64 limit to array size\n        linear_loc = self.linear_loc()\n        end_idx = np.searchsorted(linear_loc, new_size, side=\"left\")\n        linear_loc = linear_loc[:end_idx]\n\n        idx_dtype = self.coords.dtype\n        if shape != () and not can_store(idx_dtype, max(shape)):\n            idx_dtype = np.min_scalar_type(max(shape))\n        coords = np.empty((len(shape), len(linear_loc)), dtype=idx_dtype)\n        strides = 1\n        for i, d in enumerate(shape[::-1]):\n            coords[-(i + 1), :] = (linear_loc // strides) % d\n            strides *= d\n\n        self.shape = shape\n        self.coords = coords\n\n        if len(self.data) != len(linear_loc):\n            self.data = self.data[:end_idx].copy()\n\n    def to_scipy_sparse(self, /, *, accept_fv=None):\n        \"\"\"\n        Converts this :obj:`COO` object into a :obj:`scipy.sparse.coo_matrix`.\n\n        Parameters\n        ----------\n        accept_fv : scalar or list of scalar, optional\n            The list of accepted fill-values. The default accepts only zero.\n\n        Returns\n        -------\n        :obj:`scipy.sparse.coo_matrix`\n            The converted Scipy sparse matrix.\n\n        Raises\n        ------\n        ValueError\n            If the array is not two-dimensional.\n        ValueError\n            If all the array doesn't zero fill-values.\n\n        See Also\n        --------\n        COO.tocsr : Convert to a :obj:`scipy.sparse.csr_matrix`.\n        COO.tocsc : Convert to a :obj:`scipy.sparse.csc_matrix`.\n        \"\"\"\n        import scipy.sparse\n\n        check_fill_value(self, accept_fv=accept_fv)\n\n        if self.ndim != 2:\n            raise ValueError(\"Can only convert a 2-dimensional array to a Scipy sparse matrix.\")\n\n        result = scipy.sparse.coo_matrix((self.data, (self.coords[0], self.coords[1])), shape=self.shape)\n        result.has_canonical_format = True\n        return result\n\n    def _tocsr(self):\n        import scipy.sparse\n\n        if self.ndim != 2:\n            raise ValueError(\"This array must be two-dimensional for this conversion to work.\")\n        row, col = self.coords\n\n        # Pass 3: count nonzeros in each row\n        indptr = np.zeros(self.shape[0] + 1, dtype=np.int64)\n        np.cumsum(np.bincount(row, minlength=self.shape[0]), out=indptr[1:])\n\n        return scipy.sparse.csr_matrix((self.data, col, indptr), shape=self.shape)\n\n    def tocsr(self):\n        \"\"\"\n        Converts this array to a :obj:`scipy.sparse.csr_matrix`.\n\n        Returns\n        -------\n        scipy.sparse.csr_matrix\n            The result of the conversion.\n\n        Raises\n        ------\n        ValueError\n            If the array is not two-dimensional.\n        ValueError\n            If all the array doesn't have zero fill-values.\n\n        See Also\n        --------\n        COO.tocsc : Convert to a :obj:`scipy.sparse.csc_matrix`.\n        COO.to_scipy_sparse : Convert to a :obj:`scipy.sparse.coo_matrix`.\n        scipy.sparse.coo_matrix.tocsr : Equivalent Scipy function.\n        \"\"\"\n        check_zero_fill_value(self)\n\n        if self._cache is not None:\n            try:\n                return self._csr\n            except AttributeError:\n                pass\n            try:\n                self._csr = self._csc.tocsr()\n                return self._csr\n            except AttributeError:\n                pass\n\n            self._csr = csr = self._tocsr()\n        else:\n            csr = self._tocsr()\n        return csr\n\n    def tocsc(self):\n        \"\"\"\n        Converts this array to a :obj:`scipy.sparse.csc_matrix`.\n\n        Returns\n        -------\n        scipy.sparse.csc_matrix\n            The result of the conversion.\n\n        Raises\n        ------\n        ValueError\n            If the array is not two-dimensional.\n        ValueError\n            If the array doesn't have zero fill-values.\n\n        See Also\n        --------\n        COO.tocsr : Convert to a :obj:`scipy.sparse.csr_matrix`.\n        COO.to_scipy_sparse : Convert to a :obj:`scipy.sparse.coo_matrix`.\n        scipy.sparse.coo_matrix.tocsc : Equivalent Scipy function.\n        \"\"\"\n        check_zero_fill_value(self)\n\n        if self._cache is not None:\n            try:\n                return self._csc\n            except AttributeError:\n                pass\n            try:\n                self._csc = self._csr.tocsc()\n                return self._csc\n            except AttributeError:\n                pass\n\n            self._csc = csc = self.tocsr().tocsc()\n        else:\n            csc = self.tocsr().tocsc()\n\n        return csc\n\n    def _sort_indices(self):\n        \"\"\"\n        Sorts the :obj:`COO.coords` attribute. Also sorts the data in\n        :obj:`COO.data` to match.\n\n        Examples\n        --------\n        &gt;&gt;&gt; coords = np.array([[1, 2, 0]], dtype=np.uint8)\n        &gt;&gt;&gt; data = np.array([4, 1, 3], dtype=np.uint8)\n        &gt;&gt;&gt; s = COO(coords, data)\n        &gt;&gt;&gt; s._sort_indices()\n        &gt;&gt;&gt; s.coords  # doctest: +NORMALIZE_WHITESPACE\n        array([[0, 1, 2]], dtype=uint8)\n        &gt;&gt;&gt; s.data  # doctest: +NORMALIZE_WHITESPACE\n        array([3, 4, 1], dtype=uint8)\n        \"\"\"\n        linear = self.linear_loc()\n\n        if (np.diff(linear) &gt;= 0).all():  # already sorted\n            return\n\n        order = np.argsort(linear, kind=\"mergesort\")\n        self.coords = self.coords[:, order]\n        self.data = self.data[order]\n\n    def _sum_duplicates(self):\n        \"\"\"\n        Sums data corresponding to duplicates in :obj:`COO.coords`.\n\n        See Also\n        --------\n        scipy.sparse.coo_matrix.sum_duplicates : Equivalent Scipy function.\n\n        Examples\n        --------\n        &gt;&gt;&gt; coords = np.array([[0, 1, 1, 2]], dtype=np.uint8)\n        &gt;&gt;&gt; data = np.array([6, 5, 2, 2], dtype=np.uint8)\n        &gt;&gt;&gt; s = COO(coords, data)\n        &gt;&gt;&gt; s._sum_duplicates()\n        &gt;&gt;&gt; s.coords  # doctest: +NORMALIZE_WHITESPACE\n        array([[0, 1, 2]], dtype=uint8)\n        &gt;&gt;&gt; s.data  # doctest: +NORMALIZE_WHITESPACE\n        array([6, 7, 2], dtype=uint8)\n        \"\"\"\n        # Inspired by scipy/sparse/coo.py::sum_duplicates\n        # See https://github.com/scipy/scipy/blob/main/LICENSE.txt\n        linear = self.linear_loc()\n        unique_mask = np.diff(linear) != 0\n\n        if unique_mask.sum() == len(unique_mask):  # already unique\n            return\n\n        unique_mask = np.append(True, unique_mask)\n\n        coords = self.coords[:, unique_mask]\n        (unique_inds,) = np.nonzero(unique_mask)\n        data = np.add.reduceat(self.data, unique_inds, dtype=self.data.dtype)\n\n        self.data = data\n        self.coords = coords\n\n    def _prune(self):\n        \"\"\"\n        Prunes data so that if any fill-values are present, they are removed\n        from both coordinates and data.\n\n        Examples\n        --------\n        &gt;&gt;&gt; coords = np.array([[0, 1, 2, 3]])\n        &gt;&gt;&gt; data = np.array([1, 0, 1, 2])\n        &gt;&gt;&gt; s = COO(coords, data)\n        &gt;&gt;&gt; s._prune()\n        &gt;&gt;&gt; s.nnz\n        3\n        \"\"\"\n        mask = ~equivalent(self.data, self.fill_value)\n        self.coords = self.coords[:, mask]\n        self.data = self.data[mask]\n\n    def broadcast_to(self, shape):\n        \"\"\"\n        Performs the equivalent of :obj:`numpy.broadcast_to` for :obj:`COO`. Note that\n        this function returns a new array instead of a view.\n\n        Parameters\n        ----------\n        shape : tuple[int]\n            The shape to broadcast the data to.\n\n        Returns\n        -------\n        COO\n            The broadcasted sparse array.\n\n        Raises\n        ------\n        ValueError\n            If the operand cannot be broadcast to the given shape.\n\n        See Also\n        --------\n        :obj:`numpy.broadcast_to` : NumPy equivalent function\n        \"\"\"\n        return broadcast_to(self, shape)\n\n    def maybe_densify(self, max_size=1000, min_density=0.25):\n        \"\"\"\n        Converts this :obj:`COO` array to a :obj:`numpy.ndarray` if not too\n        costly.\n\n        Parameters\n        ----------\n        max_size : int\n            Maximum number of elements in output\n        min_density : float\n            Minimum density of output\n\n        Returns\n        -------\n        numpy.ndarray\n            The dense array.\n\n        Raises\n        ------\n        ValueError\n            If the returned array would be too large.\n\n        Examples\n        --------\n        Convert a small sparse array to a dense array.\n\n        &gt;&gt;&gt; s = COO.from_numpy(np.random.rand(2, 3, 4))\n        &gt;&gt;&gt; x = s.maybe_densify()\n        &gt;&gt;&gt; np.allclose(x, s.todense())\n        True\n\n        You can also specify the minimum allowed density or the maximum number\n        of output elements. If both conditions are unmet, this method will throw\n        an error.\n\n        &gt;&gt;&gt; x = np.zeros((5, 5), dtype=np.uint8)\n        &gt;&gt;&gt; x[2, 2] = 1\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.maybe_densify(max_size=5, min_density=0.25)\n        Traceback (most recent call last):\n            ...\n        ValueError: Operation would require converting large sparse array to dense\n        \"\"\"\n        if self.size &gt; max_size and self.density &lt; min_density:\n            raise ValueError(\"Operation would require converting large sparse array to dense\")\n\n        return self.todense()\n\n    def nonzero(self):\n        \"\"\"\n        Get the indices where this array is nonzero.\n\n        Returns\n        -------\n        idx : tuple[numpy.ndarray]\n            The indices where this array is nonzero.\n\n        See Also\n        --------\n        [numpy.ndarray.nonzero][] : NumPy equivalent function\n\n        Raises\n        ------\n        ValueError\n            If the array doesn't have zero fill-values.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = COO.from_numpy(np.eye(5))\n        &gt;&gt;&gt; s.nonzero()\n        (array([0, 1, 2, 3, 4]), array([0, 1, 2, 3, 4]))\n        \"\"\"\n        check_zero_fill_value(self)\n        if self.ndim == 0:\n            raise ValueError(\"`nonzero` is undefined for `self.ndim == 0`.\")\n        return tuple(self.coords)\n\n    def asformat(self, format, **kwargs):\n        \"\"\"\n        Convert this sparse array to a given format.\n\n        Parameters\n        ----------\n        format : str\n            A format string.\n\n        Returns\n        -------\n        out : SparseArray\n            The converted array.\n\n        Raises\n        ------\n        NotImplementedError\n            If the format isn't supported.\n        \"\"\"\n        from .._utils import convert_format\n\n        format = convert_format(format)\n\n        if format == \"gcxs\":\n            from .._compressed import GCXS\n\n            return GCXS.from_coo(self, **kwargs)\n\n        if len(kwargs) != 0:\n            raise TypeError(f\"Invalid keyword arguments provided: {kwargs}\")\n\n        if format == \"coo\":\n            return self\n\n        if format == \"dok\":\n            from .._dok import DOK\n\n            return DOK.from_coo(self, **kwargs)\n\n        return self.asformat(\"gcxs\", **kwargs).asformat(format, **kwargs)\n\n    def isinf(self):\n        \"\"\"\n        Tests each element ``x_i`` of the array to determine if equal to positive or negative infinity.\n        \"\"\"\n        new_fill_value = bool(np.isinf(self.fill_value))\n        new_data = np.isinf(self.data)\n\n        return COO(\n            self.coords,\n            new_data,\n            shape=self.shape,\n            fill_value=new_fill_value,\n            prune=True,\n        )\n\n    def isnan(self):\n        \"\"\"\n        Tests each element ``x_i`` of the array to determine whether the element is ``NaN``.\n        \"\"\"\n        new_fill_value = bool(np.isnan(self.fill_value))\n        new_data = np.isnan(self.data)\n\n        return COO(\n            self.coords,\n            new_data,\n            shape=self.shape,\n            fill_value=new_fill_value,\n            prune=True,\n        )\n</code></pre>"},{"location":"api/COO/#sparse.COO.shape","title":"<code>shape = tuple(int(sh) for sh in shape)</code>  <code>instance-attribute</code>","text":""},{"location":"api/COO/#sparse.COO.fill_value","title":"<code>fill_value = self.dtype.type(fill_value)</code>  <code>instance-attribute</code>","text":""},{"location":"api/COO/#sparse.COO.device","title":"<code>device</code>  <code>property</code>","text":""},{"location":"api/COO/#sparse.COO.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>The number of dimensions of this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of dimensions of this array.</p> See Also <pre><code>[DOK.ndim][sparse.DOK.ndim] : Equivalent property for [DOK][sparse.DOK] arrays.\n[numpy.ndarray.ndim][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.random.rand(1, 2, 3, 1, 2)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.ndim\n5\n&gt;&gt;&gt; s.ndim == x.ndim\nTrue\n</code></pre>"},{"location":"api/COO/#sparse.COO.size","title":"<code>size</code>  <code>property</code>","text":"<p>The number of all elements (including zeros) in this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of elements.</p> See Also <pre><code>[numpy.ndarray.size][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.zeros((10, 10))\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.size\n100\n</code></pre>"},{"location":"api/COO/#sparse.COO.density","title":"<code>density</code>  <code>property</code>","text":"<p>The ratio of nonzero to all elements in this array.</p> <p>Returns:</p> Type Description <code>float</code> <p>The ratio of nonzero to all elements.</p> See Also <pre><code>COO.size : Number of elements.\nCOO.nnz : Number of nonzero elements.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.zeros((8, 8))\n&gt;&gt;&gt; x[0, :] = 1\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.density\n0.125\n</code></pre>"},{"location":"api/COO/#sparse.COO.amax","title":"<code>amax = max</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/COO/#sparse.COO.amin","title":"<code>amin = min</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/COO/#sparse.COO.round_","title":"<code>round_ = round</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/COO/#sparse.COO.real","title":"<code>real</code>  <code>property</code>","text":"<p>The real part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.real.todense()\narray([1., 0.])\n&gt;&gt;&gt; x.real.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The real component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.real : NumPy equivalent attribute. numpy.real : NumPy equivalent function.</p>"},{"location":"api/COO/#sparse.COO.imag","title":"<code>imag</code>  <code>property</code>","text":"<p>The imaginary part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.imag.todense()\narray([0., 1.])\n&gt;&gt;&gt; x.imag.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The imaginary component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.imag : NumPy equivalent attribute. numpy.imag : NumPy equivalent function.</p>"},{"location":"api/COO/#sparse.COO.data","title":"<code>data = np.asarray(data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/COO/#sparse.COO.coords","title":"<code>coords = np.asarray(coords)</code>  <code>instance-attribute</code>","text":""},{"location":"api/COO/#sparse.COO.dtype","title":"<code>dtype</code>  <code>property</code>","text":"<p>The datatype of this array.</p> <p>Returns:</p> Type Description <code>dtype</code> <p>The datatype of this array.</p> See Also <p>numpy.ndarray.dtype : Numpy equivalent property. scipy.sparse.coo_matrix.dtype : Scipy equivalent property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = (200 * np.random.rand(5, 4)).astype(np.int32)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.dtype\ndtype('int32')\n&gt;&gt;&gt; x.dtype == s.dtype\nTrue\n</code></pre>"},{"location":"api/COO/#sparse.COO.nnz","title":"<code>nnz</code>  <code>property</code>","text":"<p>The number of nonzero elements in this array. Note that any duplicates in :code:<code>coords</code> are counted multiple times. To avoid this, call :obj:<code>COO.sum_duplicates</code>.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of nonzero elements in this array.</p> See Also <p>DOK.nnz : Equivalent :obj:<code>DOK</code> array property. numpy.count_nonzero : A similar Numpy function. scipy.sparse.coo_matrix.nnz : The Scipy equivalent property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0])\n&gt;&gt;&gt; np.count_nonzero(x)\n6\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.nnz\n6\n&gt;&gt;&gt; np.count_nonzero(x) == s.nnz\nTrue\n</code></pre>"},{"location":"api/COO/#sparse.COO.format","title":"<code>format</code>  <code>property</code>","text":"<p>The storage format of this array.</p> <p>Returns:</p> Type Description <code>str</code> <p>The storage format of this array.</p> See Also <p>scipy.sparse.dok_matrix.format : The Scipy equivalent property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; s = sparse.random((5, 5), density=0.2, format=\"dok\")\n&gt;&gt;&gt; s.format\n'dok'\n&gt;&gt;&gt; t = sparse.random((5, 5), density=0.2, format=\"coo\")\n&gt;&gt;&gt; t.format\n'coo'\n</code></pre>"},{"location":"api/COO/#sparse.COO.nbytes","title":"<code>nbytes</code>  <code>property</code>","text":"<p>The number of bytes taken up by this object. Note that for small arrays, this may undercount the number of bytes due to the large constant overhead.</p> <p>Returns:</p> Type Description <code>int</code> <p>The approximate bytes of memory taken by this object.</p> See Also <p>numpy.ndarray.nbytes : The equivalent Numpy property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = np.arange(6, dtype=np.uint8)\n&gt;&gt;&gt; coords = np.random.randint(1000, size=(3, 6), dtype=np.uint16)\n&gt;&gt;&gt; s = COO(coords, data, shape=(1000, 1000, 1000))\n&gt;&gt;&gt; s.nbytes\n42\n</code></pre>"},{"location":"api/COO/#sparse.COO.T","title":"<code>T</code>  <code>property</code>","text":"<p>Returns a new array which has the order of the axes reversed.</p> <p>Returns:</p> Type Description <code>COO</code> <p>The new array with the axes in the desired order.</p> See Also <p>:obj:<code>COO.transpose</code> :     A method where you can specify the order of the axes. numpy.ndarray.T :     Numpy equivalent property.</p> <p>Examples:</p> <p>We can change the order of the dimensions of any :obj:<code>COO</code> array with this function.</p> <pre><code>&gt;&gt;&gt; x = np.add.outer(np.arange(5), np.arange(5)[::-1])\n&gt;&gt;&gt; x\narray([[4, 3, 2, 1, 0],\n       [5, 4, 3, 2, 1],\n       [6, 5, 4, 3, 2],\n       [7, 6, 5, 4, 3],\n       [8, 7, 6, 5, 4]])\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.T.todense()\narray([[4, 5, 6, 7, 8],\n       [3, 4, 5, 6, 7],\n       [2, 3, 4, 5, 6],\n       [1, 2, 3, 4, 5],\n       [0, 1, 2, 3, 4]])\n</code></pre> <p>Note that by default, this reverses the order of the axes rather than switching the last and second-to-last axes as required by some linear algebra operations.</p> <pre><code>&gt;&gt;&gt; x = np.random.rand(2, 3, 4)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.T.shape\n(4, 3, 2)\n</code></pre>"},{"location":"api/COO/#sparse.COO.mT","title":"<code>mT</code>  <code>property</code>","text":""},{"location":"api/COO/#sparse.COO.to_device","title":"<code>to_device(device, /, *, stream=None)</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def to_device(self, device, /, *, stream=None):\n    if device != \"cpu\":\n        raise ValueError(\"Only `device='cpu'` is supported.\")\n\n    return self\n</code></pre>"},{"location":"api/COO/#sparse.COO.reduce","title":"<code>reduce(method, axis=(0), keepdims=False, **kwargs)</code>","text":"<p>Performs a reduction operation on this array.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>ufunc</code> <p>The method to use for performing the reduction.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to perform the reduction. Uses all axes by default.</p> <code>(0)</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Any extra arguments to pass to the reduction operation.</p> <code>{}</code> See Also <p>numpy.ufunc.reduce : A similar Numpy method. COO.reduce : This method implemented on COO arrays. GCXS.reduce : This method implemented on GCXS arrays.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def reduce(self, method, axis=(0,), keepdims=False, **kwargs):\n    \"\"\"\n    Performs a reduction operation on this array.\n\n    Parameters\n    ----------\n    method : numpy.ufunc\n        The method to use for performing the reduction.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to perform the reduction. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    **kwargs : dict\n        Any extra arguments to pass to the reduction operation.\n\n    See Also\n    --------\n    numpy.ufunc.reduce : A similar Numpy method.\n    COO.reduce : This method implemented on COO arrays.\n    GCXS.reduce : This method implemented on GCXS arrays.\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n    zero_reduce_result = method.reduce([self.fill_value, self.fill_value], **kwargs)\n    reduce_super_ufunc = _reduce_super_ufunc.get(method)\n    if not equivalent(zero_reduce_result, self.fill_value) and reduce_super_ufunc is None:\n        raise ValueError(f\"Performing this reduction operation would produce a dense result: {method!s}\")\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n    out = self._reduce_calc(method, axis, keepdims, **kwargs)\n    if len(out) == 1:\n        return out[0]\n    data, counts, axis, n_cols, arr_attrs = out\n    result_fill_value = self.fill_value\n    if reduce_super_ufunc is None:\n        missing_counts = counts != n_cols\n        data[missing_counts] = method(data[missing_counts], self.fill_value, **kwargs)\n    else:\n        data = method(\n            data,\n            reduce_super_ufunc(self.fill_value, n_cols - counts),\n        ).astype(data.dtype)\n        result_fill_value = reduce_super_ufunc(self.fill_value, n_cols)\n\n    out = self._reduce_return(data, arr_attrs, result_fill_value)\n\n    if keepdims:\n        shape = list(self.shape)\n        for ax in axis:\n            shape[ax] = 1\n        out = out.reshape(shape)\n\n    if out.ndim == 0:\n        return out[()]\n\n    return out\n</code></pre>"},{"location":"api/COO/#sparse.COO.sum","title":"<code>sum(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a sum operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to sum. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.sum</code> : Equivalent numpy function. scipy.sparse.coo_matrix.sum : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def sum(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a sum operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to sum. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.sum` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.sum : Equivalent Scipy function.\n    \"\"\"\n    return np.add.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/COO/#sparse.COO.max","title":"<code>max(axis=None, keepdims=False, out=None)</code>","text":"<p>Maximize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to maximize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.max</code> : Equivalent numpy function. scipy.sparse.coo_matrix.max : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def max(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Maximize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to maximize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.max` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.max : Equivalent Scipy function.\n    \"\"\"\n    return np.maximum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/COO/#sparse.COO.any","title":"<code>any(axis=None, keepdims=False, out=None)</code>","text":"<p>See if any values along array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.any</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def any(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if any values along array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.any` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_or.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/COO/#sparse.COO.all","title":"<code>all(axis=None, keepdims=False, out=None)</code>","text":"<p>See if all values in an array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.all</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def all(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if all values in an array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.all` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_and.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/COO/#sparse.COO.min","title":"<code>min(axis=None, keepdims=False, out=None)</code>","text":"<p>Minimize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.min</code> : Equivalent numpy function. scipy.sparse.coo_matrix.min : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def min(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Minimize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.min` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.min : Equivalent Scipy function.\n    \"\"\"\n    return np.minimum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/COO/#sparse.COO.prod","title":"<code>prod(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a product operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to multiply. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.prod</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def prod(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a product operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to multiply. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.prod` : Equivalent numpy function.\n    \"\"\"\n    return np.multiply.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/COO/#sparse.COO.round","title":"<code>round(decimals=0, out=None)</code>","text":"<p>Evenly round to the given number of decimals.</p> See Also <p>:obj:<code>numpy.round</code> :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def round(self, decimals=0, out=None):\n    \"\"\"\n    Evenly round to the given number of decimals.\n\n    See Also\n    --------\n    :obj:`numpy.round` :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.round, \"__call__\", self, decimals=decimals, out=out)\n</code></pre>"},{"location":"api/COO/#sparse.COO.clip","title":"<code>clip(min=None, max=None, out=None)</code>","text":"<p>Clip (limit) the values in the array.</p> <p>Return an array whose values are limited to <code>[min, max]</code>. One of min or max must be given.</p> See Also <p>sparse.clip : For full documentation and more details. numpy.clip : Equivalent NumPy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def clip(self, min=None, max=None, out=None):\n    \"\"\"\n    Clip (limit) the values in the array.\n\n    Return an array whose values are limited to ``[min, max]``. One of min\n    or max must be given.\n\n    See Also\n    --------\n    sparse.clip : For full documentation and more details.\n    numpy.clip : Equivalent NumPy function.\n    \"\"\"\n    if min is None and max is None:\n        raise ValueError(\"One of max or min must be given.\")\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.clip, \"__call__\", self, a_min=min, a_max=max, out=out)\n</code></pre>"},{"location":"api/COO/#sparse.COO.astype","title":"<code>astype(dtype, casting='unsafe', copy=True)</code>","text":"<p>Copy of the array, cast to a specified type.</p> See Also <p>scipy.sparse.coo_matrix.astype :     SciPy sparse equivalent function numpy.ndarray.astype :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def astype(self, dtype, casting=\"unsafe\", copy=True):\n    \"\"\"\n    Copy of the array, cast to a specified type.\n\n    See Also\n    --------\n    scipy.sparse.coo_matrix.astype :\n        SciPy sparse equivalent function\n    numpy.ndarray.astype :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    # this matches numpy's behavior\n    if self.dtype == dtype and not copy:\n        return self\n    return self.__array_ufunc__(np.ndarray.astype, \"__call__\", self, dtype=dtype, copy=copy, casting=casting)\n</code></pre>"},{"location":"api/COO/#sparse.COO.mean","title":"<code>mean(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Compute the mean along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the mean. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.mean : Equivalent numpy method. scipy.sparse.coo_matrix.mean : Equivalent Scipy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> <li>The :code:<code>out</code> parameter is provided just for compatibility with   Numpy and isn't actually supported.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.mean</code> to compute the mean of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.mean(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.5, 1.5, 0., 0.])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the mean.</p> <pre><code>&gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the mean along all axes.</p> <pre><code>&gt;&gt;&gt; s.mean()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def mean(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Compute the mean along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the mean. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.mean : Equivalent numpy method.\n    scipy.sparse.coo_matrix.mean : Equivalent Scipy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n    * The :code:`out` parameter is provided just for compatibility with\n      Numpy and isn't actually supported.\n\n    Examples\n    --------\n    You can use :obj:`COO.mean` to compute the mean of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.mean(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.5, 1.5, 0., 0.])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the mean.\n\n    &gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    mean along all axes.\n\n    &gt;&gt;&gt; s.mean()\n    0.5\n    \"\"\"\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n    elif not isinstance(axis, tuple):\n        axis = (axis,)\n    den = reduce(operator.mul, (self.shape[i] for i in axis), 1)\n\n    if dtype is None:\n        if issubclass(self.dtype.type, np.integer | np.bool_):\n            dtype = inter_dtype = np.dtype(\"f8\")\n        else:\n            dtype = self.dtype\n            inter_dtype = np.dtype(\"f4\") if issubclass(dtype.type, np.float16) else dtype\n    else:\n        inter_dtype = dtype\n\n    num = self.sum(axis=axis, keepdims=keepdims, dtype=inter_dtype)\n\n    if num.ndim:\n        out = np.true_divide(num, den, casting=\"unsafe\")\n        return out.astype(dtype) if out.dtype != dtype else out\n    return np.divide(num, den, dtype=dtype, out=out)\n</code></pre>"},{"location":"api/COO/#sparse.COO.var","title":"<code>var(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the variance along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the variance. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.var : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.var</code> to compute the variance of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.var(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.6875, 0.1875])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the variance.</p> <pre><code>&gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the variance along all axes.</p> <pre><code>&gt;&gt;&gt; s.var()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the variance along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the variance. Uses all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.var : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.var` to compute the variance of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.var(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.6875, 0.1875])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the variance.\n\n    &gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    variance along all axes.\n\n    &gt;&gt;&gt; s.var()\n    0.5\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n\n    rcount = reduce(operator.mul, (self.shape[a] for a in axis), 1)\n    # Make this warning show up on top.\n    if ddof &gt;= rcount:\n        warnings.warn(\"Degrees of freedom &lt;= 0 for slice\", RuntimeWarning, stacklevel=1)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None and issubclass(self.dtype.type, np.integer | np.bool_):\n        dtype = np.dtype(\"f8\")\n\n    arrmean = self.sum(axis, dtype=dtype, keepdims=True)[...]\n    np.divide(arrmean, rcount, out=arrmean)\n    x = self - arrmean\n    if issubclass(self.dtype.type, np.complexfloating):\n        x = x.real * x.real + x.imag * x.imag\n    else:\n        x = np.multiply(x, x, out=x)\n\n    ret = x.sum(axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n    # Compute degrees of freedom and make sure it is not negative.\n    rcount = max([rcount - ddof, 0])\n\n    ret = ret[...]\n    np.divide(ret, rcount, out=ret, casting=\"unsafe\")\n    return ret[()]\n</code></pre>"},{"location":"api/COO/#sparse.COO.std","title":"<code>std(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the standard deviation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the standard deviation. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.std : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.std</code> to compute the standard deviation of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.std(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.8291562, 0.4330127])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the standard deviation.</p> <pre><code>&gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the standard deviation along all axes.</p> <pre><code>&gt;&gt;&gt; s.std()\n0.7071067811865476\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the standard deviation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the standard deviation. Uses\n        all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.std : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.std` to compute the standard deviation of an array\n    across any dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.std(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.8291562, 0.4330127])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the standard deviation.\n\n    &gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    standard deviation along all axes.\n\n    &gt;&gt;&gt; s.std()  # doctest: +SKIP\n    0.7071067811865476\n    \"\"\"\n    ret = self.var(axis=axis, dtype=dtype, out=out, ddof=ddof, keepdims=keepdims)\n\n    return np.sqrt(ret)\n</code></pre>"},{"location":"api/COO/#sparse.COO.conj","title":"<code>conj()</code>","text":"<p>Return the complex conjugate, element-wise.</p> <p>The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n&gt;&gt;&gt; res = x.conj()\n&gt;&gt;&gt; res.todense()\narray([1.-2.j, 2.+1.j])\n&gt;&gt;&gt; res.dtype\ndtype('complex128')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The complex conjugate, with same dtype as the input.</p> See Also <p>numpy.ndarray.conj : NumPy equivalent method. numpy.conj : NumPy equivalent function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def conj(self):\n    \"\"\"Return the complex conjugate, element-wise.\n\n    The complex conjugate of a complex number is obtained by changing the\n    sign of its imaginary part.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n    &gt;&gt;&gt; res = x.conj()\n    &gt;&gt;&gt; res.todense()  # doctest: +SKIP\n    array([1.-2.j, 2.+1.j])\n    &gt;&gt;&gt; res.dtype\n    dtype('complex128')\n\n    Returns\n    -------\n    out : SparseArray\n        The complex conjugate, with same dtype as the input.\n\n    See Also\n    --------\n    numpy.ndarray.conj : NumPy equivalent method.\n    numpy.conj : NumPy equivalent function.\n    \"\"\"\n    return np.conj(self)\n</code></pre>"},{"location":"api/COO/#sparse.COO.copy","title":"<code>copy(deep=True)</code>","text":"<p>Return a copy of the array.</p> <p>Parameters:</p> Name Type Description Default <code>deep</code> <code>boolean</code> <p>If True (default), the internal coords and data arrays are also copied. Set to <code>False</code> to only make a shallow copy.</p> <code>True</code> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def copy(self, deep=True):\n    \"\"\"Return a copy of the array.\n\n    Parameters\n    ----------\n    deep : boolean, optional\n        If True (default), the internal coords and data arrays are also\n        copied. Set to ``False`` to only make a shallow copy.\n    \"\"\"\n    return _copy.deepcopy(self) if deep else _copy.copy(self)\n</code></pre>"},{"location":"api/COO/#sparse.COO.enable_caching","title":"<code>enable_caching()</code>","text":"<p>Enable caching of reshape, transpose, and tocsr/csc operations</p> <p>This enables efficient iterative workflows that make heavy use of csr/csc operations, such as tensordot.  This maintains a cache of recent results of reshape and transpose so that operations like tensordot (which uses both internally) store efficiently stored representations for repeated use.  This can significantly cut down on computational costs in common numeric algorithms.</p> <p>However, this also assumes that neither this object, nor the downstream objects will have their data mutated.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s.enable_caching()\n&gt;&gt;&gt; csr1 = s.transpose((2, 0, 1)).reshape((100, 120)).tocsr()\n&gt;&gt;&gt; csr2 = s.transpose((2, 0, 1)).reshape((100, 120)).tocsr()\n&gt;&gt;&gt; csr1 is csr2\nTrue\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def enable_caching(self):\n    \"\"\"Enable caching of reshape, transpose, and tocsr/csc operations\n\n    This enables efficient iterative workflows that make heavy use of\n    csr/csc operations, such as tensordot.  This maintains a cache of\n    recent results of reshape and transpose so that operations like\n    tensordot (which uses both internally) store efficiently stored\n    representations for repeated use.  This can significantly cut down on\n    computational costs in common numeric algorithms.\n\n    However, this also assumes that neither this object, nor the downstream\n    objects will have their data mutated.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s.enable_caching()  # doctest: +SKIP\n    &gt;&gt;&gt; csr1 = s.transpose((2, 0, 1)).reshape((100, 120)).tocsr()  # doctest: +SKIP\n    &gt;&gt;&gt; csr2 = s.transpose((2, 0, 1)).reshape((100, 120)).tocsr()  # doctest: +SKIP\n    &gt;&gt;&gt; csr1 is csr2  # doctest: +SKIP\n    True\n    \"\"\"\n    self._cache = defaultdict(lambda: deque(maxlen=3))\n</code></pre>"},{"location":"api/COO/#sparse.COO.from_numpy","title":"<code>from_numpy(x, fill_value=None, idx_dtype=None)</code>  <code>classmethod</code>","text":"<p>Convert the given :obj:<code>numpy.ndarray</code> to a :obj:<code>COO</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The dense array to convert.</p> required <code>fill_value</code> <code>scalar</code> <p>The fill value of the constructed :obj:<code>COO</code> array. Zero if unspecified.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The converted COO array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.eye(5)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s\n&lt;COO: shape=(5, 5), dtype=float64, nnz=5, fill_value=0.0&gt;\n</code></pre> <pre><code>&gt;&gt;&gt; x[x == 0] = np.nan\n&gt;&gt;&gt; COO.from_numpy(x, fill_value=np.nan)\n&lt;COO: shape=(5, 5), dtype=float64, nnz=5, fill_value=nan&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>@classmethod\ndef from_numpy(cls, x, fill_value=None, idx_dtype=None):\n    \"\"\"\n    Convert the given :obj:`numpy.ndarray` to a :obj:`COO` object.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        The dense array to convert.\n    fill_value : scalar\n        The fill value of the constructed :obj:`COO` array. Zero if\n        unspecified.\n\n    Returns\n    -------\n    COO\n        The converted COO array.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.eye(5)\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s\n    &lt;COO: shape=(5, 5), dtype=float64, nnz=5, fill_value=0.0&gt;\n\n    &gt;&gt;&gt; x[x == 0] = np.nan\n    &gt;&gt;&gt; COO.from_numpy(x, fill_value=np.nan)\n    &lt;COO: shape=(5, 5), dtype=float64, nnz=5, fill_value=nan&gt;\n    \"\"\"\n    x = np.asanyarray(x).view(type=np.ndarray)\n\n    if fill_value is None:\n        fill_value = _zero_of_dtype(x.dtype) if x.shape else x\n\n    coords = np.atleast_2d(np.flatnonzero(~equivalent(x, fill_value)))\n    data = x.ravel()[tuple(coords)]\n    return cls(\n        coords,\n        data,\n        shape=x.size,\n        has_duplicates=False,\n        sorted=True,\n        fill_value=fill_value,\n        idx_dtype=idx_dtype,\n    ).reshape(x.shape)\n</code></pre>"},{"location":"api/COO/#sparse.COO.todense","title":"<code>todense()</code>","text":"<p>Convert this :obj:<code>COO</code> array to a dense :obj:<code>numpy.ndarray</code>. Note that this may take a large amount of memory if the :obj:<code>COO</code> object's :code:<code>shape</code> is large.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The converted dense array.</p> See Also <p>DOK.todense : Equivalent :obj:<code>DOK</code> array method. scipy.sparse.coo_matrix.todense : Equivalent Scipy method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.random.randint(100, size=(7, 3))\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; x2 = s.todense()\n&gt;&gt;&gt; np.array_equal(x, x2)\nTrue\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def todense(self):\n    \"\"\"\n    Convert this :obj:`COO` array to a dense :obj:`numpy.ndarray`. Note that\n    this may take a large amount of memory if the :obj:`COO` object's :code:`shape`\n    is large.\n\n    Returns\n    -------\n    numpy.ndarray\n        The converted dense array.\n\n    See Also\n    --------\n    DOK.todense : Equivalent :obj:`DOK` array method.\n    scipy.sparse.coo_matrix.todense : Equivalent Scipy method.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.random.randint(100, size=(7, 3))\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; x2 = s.todense()\n    &gt;&gt;&gt; np.array_equal(x, x2)\n    True\n    \"\"\"\n    x = np.full(self.shape, self.fill_value, self.dtype)\n\n    coords = tuple([self.coords[i, :] for i in range(self.ndim)])\n    data = self.data\n\n    if coords != ():\n        x[coords] = data\n    else:\n        if len(data) != 0:\n            x[coords] = data\n\n    return x\n</code></pre>"},{"location":"api/COO/#sparse.COO.from_scipy_sparse","title":"<code>from_scipy_sparse(x, /, *, fill_value=None)</code>  <code>classmethod</code>","text":"<p>Construct a :obj:<code>COO</code> array from a :obj:<code>scipy.sparse.spmatrix</code></p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>spmatrix</code> <p>The sparse matrix to construct the array from.</p> required <code>fill_value</code> <code>scalar</code> <p>The fill-value to use when converting.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The converted :obj:<code>COO</code> object.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = scipy.sparse.rand(6, 3, density=0.2)\n&gt;&gt;&gt; s = COO.from_scipy_sparse(x)\n&gt;&gt;&gt; np.array_equal(x.todense(), s.todense())\nTrue\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>@classmethod\ndef from_scipy_sparse(cls, x, /, *, fill_value=None):\n    \"\"\"\n    Construct a :obj:`COO` array from a :obj:`scipy.sparse.spmatrix`\n\n    Parameters\n    ----------\n    x : scipy.sparse.spmatrix\n        The sparse matrix to construct the array from.\n    fill_value : scalar\n        The fill-value to use when converting.\n\n    Returns\n    -------\n    COO\n        The converted :obj:`COO` object.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = scipy.sparse.rand(6, 3, density=0.2)\n    &gt;&gt;&gt; s = COO.from_scipy_sparse(x)\n    &gt;&gt;&gt; np.array_equal(x.todense(), s.todense())\n    True\n    \"\"\"\n    x = x.asformat(\"coo\")\n    coords = np.empty((2, x.nnz), dtype=x.row.dtype)\n    coords[0, :] = x.row\n    coords[1, :] = x.col\n    return COO(\n        coords,\n        x.data,\n        shape=x.shape,\n        has_duplicates=not x.has_canonical_format,\n        sorted=x.has_canonical_format,\n        fill_value=fill_value,\n    )\n</code></pre>"},{"location":"api/COO/#sparse.COO.from_iter","title":"<code>from_iter(x, shape=None, fill_value=None, dtype=None)</code>  <code>classmethod</code>","text":"<p>Converts an iterable in certain formats to a :obj:<code>COO</code> array. See examples for details.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Iterable or Iterator</code> <p>The iterable to convert to :obj:<code>COO</code>.</p> required <code>shape</code> <code>tuple[int]</code> <p>The shape of the array.</p> <code>None</code> <code>fill_value</code> <code>scalar</code> <p>The fill value for this array.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The dtype of the input array. Inferred from the input if not given.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>COO</code> <p>The output :obj:<code>COO</code> array.</p> <p>Examples:</p> <p>You can convert items of the format <code>[((i, j, k), value), ((i, j, k), value)]</code> to :obj:<code>COO</code>. Here, the first part represents the coordinate and the second part represents the value.</p> <pre><code>&gt;&gt;&gt; x = [((0, 0), 1), ((1, 1), 1)]\n&gt;&gt;&gt; s = COO.from_iter(x)\n&gt;&gt;&gt; s.todense()\narray([[1, 0],\n       [0, 1]])\n</code></pre> <p>You can also have a similar format with a dictionary.</p> <pre><code>&gt;&gt;&gt; x = {(0, 0): 1, (1, 1): 1}\n&gt;&gt;&gt; s = COO.from_iter(x)\n&gt;&gt;&gt; s.todense()\narray([[1, 0],\n       [0, 1]])\n</code></pre> <p>The third supported format is <code>(data, (..., row, col))</code>.</p> <pre><code>&gt;&gt;&gt; x = ([1, 1], ([0, 1], [0, 1]))\n&gt;&gt;&gt; s = COO.from_iter(x)\n&gt;&gt;&gt; s.todense()\narray([[1, 0],\n       [0, 1]])\n</code></pre> <p>You can also pass in a :obj:<code>collections.Iterator</code> object.</p> <pre><code>&gt;&gt;&gt; x = [((0, 0), 1), ((1, 1), 1)].__iter__()\n&gt;&gt;&gt; s = COO.from_iter(x)\n&gt;&gt;&gt; s.todense()\narray([[1, 0],\n       [0, 1]])\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>@classmethod\ndef from_iter(cls, x, shape=None, fill_value=None, dtype=None):\n    \"\"\"\n    Converts an iterable in certain formats to a :obj:`COO` array. See examples\n    for details.\n\n    Parameters\n    ----------\n    x : Iterable or Iterator\n        The iterable to convert to :obj:`COO`.\n    shape : tuple[int], optional\n        The shape of the array.\n    fill_value : scalar\n        The fill value for this array.\n    dtype : numpy.dtype\n        The dtype of the input array. Inferred from the input if not given.\n\n    Returns\n    -------\n    out : COO\n        The output :obj:`COO` array.\n\n    Examples\n    --------\n    You can convert items of the format ``[((i, j, k), value), ((i, j, k), value)]`` to :obj:`COO`.\n    Here, the first part represents the coordinate and the second part represents the value.\n\n    &gt;&gt;&gt; x = [((0, 0), 1), ((1, 1), 1)]\n    &gt;&gt;&gt; s = COO.from_iter(x)\n    &gt;&gt;&gt; s.todense()\n    array([[1, 0],\n           [0, 1]])\n\n    You can also have a similar format with a dictionary.\n\n    &gt;&gt;&gt; x = {(0, 0): 1, (1, 1): 1}\n    &gt;&gt;&gt; s = COO.from_iter(x)\n    &gt;&gt;&gt; s.todense()\n    array([[1, 0],\n           [0, 1]])\n\n    The third supported format is ``(data, (..., row, col))``.\n\n    &gt;&gt;&gt; x = ([1, 1], ([0, 1], [0, 1]))\n    &gt;&gt;&gt; s = COO.from_iter(x)\n    &gt;&gt;&gt; s.todense()\n    array([[1, 0],\n           [0, 1]])\n\n    You can also pass in a :obj:`collections.Iterator` object.\n\n    &gt;&gt;&gt; x = [((0, 0), 1), ((1, 1), 1)].__iter__()\n    &gt;&gt;&gt; s = COO.from_iter(x)\n    &gt;&gt;&gt; s.todense()\n    array([[1, 0],\n           [0, 1]])\n    \"\"\"\n    if isinstance(x, dict):\n        x = list(x.items())\n\n    if not isinstance(x, Sized):\n        x = list(x)\n\n    if len(x) != 2 and not all(len(item) == 2 for item in x):\n        raise ValueError(\"Invalid iterable to convert to COO.\")\n\n    if not x:\n        ndim = 0 if shape is None else len(shape)\n        coords = np.empty((ndim, 0), dtype=np.uint8)\n        data = np.empty((0,), dtype=dtype)\n        shape = () if shape is None else shape\n\n    elif not isinstance(x[0][0], Iterable):\n        coords = np.stack(x[1], axis=0)\n        data = np.asarray(x[0], dtype=dtype)\n    else:\n        coords = np.array([item[0] for item in x]).T\n        data = np.array([item[1] for item in x], dtype=dtype)\n\n    if not (\n        coords.ndim == 2 and data.ndim == 1 and np.issubdtype(coords.dtype, np.integer) and np.all(coords &gt;= 0)\n    ):\n        raise ValueError(\"Invalid iterable to convert to COO.\")\n\n    return COO(coords, data, shape=shape, fill_value=fill_value)\n</code></pre>"},{"location":"api/COO/#sparse.COO.transpose","title":"<code>transpose(axes=None)</code>","text":"<p>Returns a new array which has the order of the axes switched.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>Iterable[int]</code> <p>The new order of the axes compared to the previous one. Reverses the axes by default.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The new array with the axes in the desired order.</p> See Also <p>:obj:<code>COO.T</code> : A quick property to reverse the order of the axes. numpy.ndarray.transpose : Numpy equivalent function.</p> <p>Examples:</p> <p>We can change the order of the dimensions of any :obj:<code>COO</code> array with this function.</p> <pre><code>&gt;&gt;&gt; x = np.add.outer(np.arange(5), np.arange(5)[::-1])\n&gt;&gt;&gt; x\narray([[4, 3, 2, 1, 0],\n       [5, 4, 3, 2, 1],\n       [6, 5, 4, 3, 2],\n       [7, 6, 5, 4, 3],\n       [8, 7, 6, 5, 4]])\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.transpose((1, 0)).todense()\narray([[4, 5, 6, 7, 8],\n       [3, 4, 5, 6, 7],\n       [2, 3, 4, 5, 6],\n       [1, 2, 3, 4, 5],\n       [0, 1, 2, 3, 4]])\n</code></pre> <p>Note that by default, this reverses the order of the axes rather than switching the last and second-to-last axes as required by some linear algebra operations.</p> <pre><code>&gt;&gt;&gt; x = np.random.rand(2, 3, 4)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.transpose().shape\n(4, 3, 2)\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def transpose(self, axes=None):\n    \"\"\"\n    Returns a new array which has the order of the axes switched.\n\n    Parameters\n    ----------\n    axes : Iterable[int], optional\n        The new order of the axes compared to the previous one. Reverses the axes\n        by default.\n\n    Returns\n    -------\n    COO\n        The new array with the axes in the desired order.\n\n    See Also\n    --------\n    :obj:`COO.T` : A quick property to reverse the order of the axes.\n    numpy.ndarray.transpose : Numpy equivalent function.\n\n    Examples\n    --------\n    We can change the order of the dimensions of any :obj:`COO` array with this\n    function.\n\n    &gt;&gt;&gt; x = np.add.outer(np.arange(5), np.arange(5)[::-1])\n    &gt;&gt;&gt; x  # doctest: +NORMALIZE_WHITESPACE\n    array([[4, 3, 2, 1, 0],\n           [5, 4, 3, 2, 1],\n           [6, 5, 4, 3, 2],\n           [7, 6, 5, 4, 3],\n           [8, 7, 6, 5, 4]])\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s.transpose((1, 0)).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[4, 5, 6, 7, 8],\n           [3, 4, 5, 6, 7],\n           [2, 3, 4, 5, 6],\n           [1, 2, 3, 4, 5],\n           [0, 1, 2, 3, 4]])\n\n    Note that by default, this reverses the order of the axes rather than switching\n    the last and second-to-last axes as required by some linear algebra operations.\n\n    &gt;&gt;&gt; x = np.random.rand(2, 3, 4)\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s.transpose().shape\n    (4, 3, 2)\n    \"\"\"\n    if axes is None:\n        axes = list(reversed(range(self.ndim)))\n\n    # Normalize all axes indices to positive values\n    axes = normalize_axis(axes, self.ndim)\n\n    if len(np.unique(axes)) &lt; len(axes):\n        raise ValueError(\"repeated axis in transpose\")\n\n    if not len(axes) == self.ndim:\n        raise ValueError(\"axes don't match array\")\n\n    axes = tuple(axes)\n\n    if axes == tuple(range(self.ndim)):\n        return self\n\n    if self._cache is not None:\n        for ax, value in self._cache[\"transpose\"]:\n            if ax == axes:\n                return value\n\n    shape = tuple(self.shape[ax] for ax in axes)\n    result = COO(\n        self.coords[axes, :],\n        self.data,\n        shape,\n        has_duplicates=False,\n        cache=self._cache is not None,\n        fill_value=self.fill_value,\n    )\n\n    if self._cache is not None:\n        self._cache[\"transpose\"].append((axes, result))\n    return result\n</code></pre>"},{"location":"api/COO/#sparse.COO.swapaxes","title":"<code>swapaxes(axis1, axis2)</code>","text":"<p>Returns array that has axes axis1 and axis2 swapped.</p> <p>Parameters:</p> Name Type Description Default <code>axis1</code> <code>int</code> <p>first axis to swap</p> required <code>axis2</code> <code>int</code> <p>second axis to swap</p> required <p>Returns:</p> Type Description <code>COO</code> <p>The new array with the axes axis1 and axis2 swapped.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = COO.from_numpy(np.ones((2, 3, 4)))\n&gt;&gt;&gt; x.swapaxes(0, 2)\n&lt;COO: shape=(4, 3, 2), dtype=float64, nnz=24, fill_value=0.0&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def swapaxes(self, axis1, axis2):\n    \"\"\"Returns array that has axes axis1 and axis2 swapped.\n\n    Parameters\n    ----------\n    axis1 : int\n        first axis to swap\n    axis2 : int\n        second axis to swap\n\n    Returns\n    -------\n    COO\n        The new array with the axes axis1 and axis2 swapped.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = COO.from_numpy(np.ones((2, 3, 4)))\n    &gt;&gt;&gt; x.swapaxes(0, 2)\n    &lt;COO: shape=(4, 3, 2), dtype=float64, nnz=24, fill_value=0.0&gt;\n    \"\"\"\n    # Normalize all axis1, axis2 to positive values\n    axis1, axis2 = normalize_axis((axis1, axis2), self.ndim)  # checks if axis1,2 are in range + raises ValueError\n    axes = list(range(self.ndim))\n    axes[axis1], axes[axis2] = axes[axis2], axes[axis1]\n    return self.transpose(axes)\n</code></pre>"},{"location":"api/COO/#sparse.COO.dot","title":"<code>dot(other)</code>","text":"<p>Performs the equivalent of :code:<code>x.dot(y)</code> for :obj:<code>COO</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Union[COO, ndarray, spmatrix]</code> <p>The second operand of the dot product operation.</p> required <p>Returns:</p> Type Description <code>{COO, ndarray}</code> <p>The result of the dot product. If the result turns out to be dense, then a dense array is returned, otherwise, a sparse array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all arguments don't have zero fill-values.</p> See Also <p>dot : Equivalent function for two arguments. :obj:<code>numpy.dot</code> : Numpy equivalent function. scipy.sparse.coo_matrix.dot : Scipy equivalent function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.arange(4).reshape((2, 2))\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.dot(s)\narray([[ 2,  3],\n       [ 6, 11]], dtype=int64)\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def dot(self, other):\n    \"\"\"\n    Performs the equivalent of :code:`x.dot(y)` for :obj:`COO`.\n\n    Parameters\n    ----------\n    other : Union[COO, numpy.ndarray, scipy.sparse.spmatrix]\n        The second operand of the dot product operation.\n\n    Returns\n    -------\n    {COO, numpy.ndarray}\n        The result of the dot product. If the result turns out to be dense,\n        then a dense array is returned, otherwise, a sparse array.\n\n    Raises\n    ------\n    ValueError\n        If all arguments don't have zero fill-values.\n\n    See Also\n    --------\n    dot : Equivalent function for two arguments.\n    :obj:`numpy.dot` : Numpy equivalent function.\n    scipy.sparse.coo_matrix.dot : Scipy equivalent function.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.arange(4).reshape((2, 2))\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s.dot(s)  # doctest: +SKIP\n    array([[ 2,  3],\n           [ 6, 11]], dtype=int64)\n    \"\"\"\n    from .._common import dot\n\n    return dot(self, other)\n</code></pre>"},{"location":"api/COO/#sparse.COO.linear_loc","title":"<code>linear_loc()</code>","text":"<p>The nonzero coordinates of a flattened version of this array. Note that the coordinates may be out of order.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The flattened coordinates.</p> See Also <p>:obj:<code>numpy.flatnonzero</code> : Equivalent Numpy function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.eye(5)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.linear_loc()\narray([ 0,  6, 12, 18, 24])\n&gt;&gt;&gt; np.array_equal(np.flatnonzero(x), s.linear_loc())\nTrue\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def linear_loc(self):\n    \"\"\"\n    The nonzero coordinates of a flattened version of this array. Note that\n    the coordinates may be out of order.\n\n    Returns\n    -------\n    numpy.ndarray\n        The flattened coordinates.\n\n    See Also\n    --------\n    :obj:`numpy.flatnonzero` : Equivalent Numpy function.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.eye(5)\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s.linear_loc()  # doctest: +NORMALIZE_WHITESPACE\n    array([ 0,  6, 12, 18, 24])\n    &gt;&gt;&gt; np.array_equal(np.flatnonzero(x), s.linear_loc())\n    True\n    \"\"\"\n    from .common import linear_loc\n\n    return linear_loc(self.coords, self.shape)\n</code></pre>"},{"location":"api/COO/#sparse.COO.flatten","title":"<code>flatten(order='C')</code>","text":"<p>Returns a new :obj:<code>COO</code> array that is a flattened version of this array.</p> <p>Returns:</p> Type Description <code>COO</code> <p>The flattened output array.</p> Notes <p>The :code:<code>order</code> parameter is provided just for compatibility with Numpy and isn't actually supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = COO.from_numpy(np.arange(10))\n&gt;&gt;&gt; s2 = s.reshape((2, 5)).flatten()\n&gt;&gt;&gt; s2.todense()\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def flatten(self, order=\"C\"):\n    \"\"\"\n    Returns a new :obj:`COO` array that is a flattened version of this array.\n\n    Returns\n    -------\n    COO\n        The flattened output array.\n\n    Notes\n    -----\n    The :code:`order` parameter is provided just for compatibility with\n    Numpy and isn't actually supported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = COO.from_numpy(np.arange(10))\n    &gt;&gt;&gt; s2 = s.reshape((2, 5)).flatten()\n    &gt;&gt;&gt; s2.todense()\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    \"\"\"\n    if order not in {\"C\", None}:\n        raise NotImplementedError(\"The `order` parameter is notsupported.\")\n\n    return self.reshape(-1)\n</code></pre>"},{"location":"api/COO/#sparse.COO.reshape","title":"<code>reshape(shape, order='C')</code>","text":"<p>Returns a new :obj:<code>COO</code> array that is a reshaped version of this array.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>tuple[int]</code> <p>The desired shape of the output array.</p> required <p>Returns:</p> Type Description <code>COO</code> <p>The reshaped output array.</p> See Also <p>numpy.ndarray.reshape : The equivalent Numpy function.</p> Notes <p>The :code:<code>order</code> parameter is provided just for compatibility with Numpy and isn't actually supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = COO.from_numpy(np.arange(25))\n&gt;&gt;&gt; s2 = s.reshape((5, 5))\n&gt;&gt;&gt; s2.todense()\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24]])\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def reshape(self, shape, order=\"C\"):\n    \"\"\"\n    Returns a new :obj:`COO` array that is a reshaped version of this array.\n\n    Parameters\n    ----------\n    shape : tuple[int]\n        The desired shape of the output array.\n\n    Returns\n    -------\n    COO\n        The reshaped output array.\n\n    See Also\n    --------\n    numpy.ndarray.reshape : The equivalent Numpy function.\n\n    Notes\n    -----\n    The :code:`order` parameter is provided just for compatibility with\n    Numpy and isn't actually supported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = COO.from_numpy(np.arange(25))\n    &gt;&gt;&gt; s2 = s.reshape((5, 5))\n    &gt;&gt;&gt; s2.todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[ 0,  1,  2,  3,  4],\n           [ 5,  6,  7,  8,  9],\n           [10, 11, 12, 13, 14],\n           [15, 16, 17, 18, 19],\n           [20, 21, 22, 23, 24]])\n    \"\"\"\n    shape = tuple(shape) if isinstance(shape, Iterable) else (shape,)\n\n    if order not in {\"C\", None}:\n        raise NotImplementedError(\"The `order` parameter is not supported\")\n\n    if self.shape == shape:\n        return self\n    if any(d == -1 for d in shape):\n        extra = int(self.size / np.prod([d for d in shape if d != -1]))\n        shape = tuple([d if d != -1 else extra for d in shape])\n\n    if self.size != reduce(operator.mul, shape, 1):\n        raise ValueError(f\"cannot reshape array of size {self.size} into shape {shape}\")\n\n    if self._cache is not None:\n        for sh, value in self._cache[\"reshape\"]:\n            if sh == shape:\n                return value\n\n    # TODO: this self.size enforces a 2**64 limit to array size\n    linear_loc = self.linear_loc()\n\n    idx_dtype = self.coords.dtype\n    if shape != () and not can_store(idx_dtype, max(shape)):\n        idx_dtype = np.min_scalar_type(max(shape))\n    coords = np.empty((len(shape), self.nnz), dtype=idx_dtype)\n    strides = 1\n    for i, d in enumerate(shape[::-1]):\n        coords[-(i + 1), :] = (linear_loc // strides) % d\n        strides *= d\n\n    result = COO(\n        coords,\n        self.data,\n        shape,\n        has_duplicates=False,\n        sorted=True,\n        cache=self._cache is not None,\n        fill_value=self.fill_value,\n    )\n\n    if self._cache is not None:\n        self._cache[\"reshape\"].append((shape, result))\n    return result\n</code></pre>"},{"location":"api/COO/#sparse.COO.squeeze","title":"<code>squeeze(axis=None)</code>","text":"<p>Removes singleton dimensions (axes) from <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[None, int, Tuple[int, ...]]</code> <p>The axis (or axes) to squeeze. If a specified axis has a size greater than one, a <code>ValueError</code> is raised. <code>axis=None</code> removes all singleton dimensions. Default: <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The output array without <code>axis</code> dimensions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = COO.from_numpy(np.eye(2)).reshape((2, 1, 2, 1))\n&gt;&gt;&gt; s.squeeze().shape\n(2, 2)\n&gt;&gt;&gt; s.squeeze(axis=1).shape\n(2, 2, 1)\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def squeeze(self, axis=None):\n    \"\"\"\n    Removes singleton dimensions (axes) from ``x``.\n    Parameters\n    ----------\n    axis : Union[None, int, Tuple[int, ...]]\n        The axis (or axes) to squeeze. If a specified axis has a size greater than one,\n        a `ValueError` is raised. ``axis=None`` removes all singleton dimensions.\n        Default: ``None``.\n    Returns\n    -------\n    COO\n        The output array without ``axis`` dimensions.\n    Examples\n    --------\n    &gt;&gt;&gt; s = COO.from_numpy(np.eye(2)).reshape((2, 1, 2, 1))\n    &gt;&gt;&gt; s.squeeze().shape\n    (2, 2)\n    &gt;&gt;&gt; s.squeeze(axis=1).shape\n    (2, 2, 1)\n    \"\"\"\n    squeezable_dims = tuple([d for d in range(self.ndim) if self.shape[d] == 1])\n\n    if axis is None:\n        axis = squeezable_dims\n    if isinstance(axis, int):\n        axis = (axis,)\n    elif isinstance(axis, Iterable):\n        axis = tuple(axis)\n    else:\n        raise ValueError(f\"Invalid axis parameter: `{axis}`.\")\n\n    for d in axis:\n        if d not in squeezable_dims:\n            raise ValueError(f\"Specified axis `{d}` has a size greater than one: {self.shape[d]}\")\n\n    retained_dims = [d for d in range(self.ndim) if d not in axis]\n\n    coords = self.coords[retained_dims, :]\n    shape = tuple([s for idx, s in enumerate(self.shape) if idx in retained_dims])\n\n    return COO(\n        coords,\n        self.data,\n        shape,\n        has_duplicates=False,\n        sorted=True,\n        cache=self._cache is not None,\n        fill_value=self.fill_value,\n    )\n</code></pre>"},{"location":"api/COO/#sparse.COO.resize","title":"<code>resize(*args, refcheck=True, coords_dtype=np.intp)</code>","text":"<p>This method changes the shape and size of an array in-place.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>tuple, or series of integers</code> <p>The desired shape of the output array.</p> <code>()</code> See Also <p>numpy.ndarray.resize : The equivalent Numpy function.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def resize(self, *args, refcheck=True, coords_dtype=np.intp):\n    \"\"\"\n    This method changes the shape and size of an array in-place.\n    Parameters\n    ----------\n    args : tuple, or series of integers\n        The desired shape of the output array.\n\n    See Also\n    --------\n    numpy.ndarray.resize : The equivalent Numpy function.\n\n    \"\"\"\n    warnings.warn(\"resize is deprecated on all SpraseArray objects.\", DeprecationWarning, stacklevel=1)\n    if len(args) == 1 and isinstance(args[0], tuple):\n        shape = args[0]\n    elif all(isinstance(arg, int) for arg in args):\n        shape = tuple(args)\n    else:\n        raise ValueError(\"Invalid input\")\n\n    if any(d &lt; 0 for d in shape):\n        raise ValueError(\"negative dimensions not allowed\")\n\n    new_size = reduce(operator.mul, shape, 1)\n\n    # TODO: this self.size enforces a 2**64 limit to array size\n    linear_loc = self.linear_loc()\n    end_idx = np.searchsorted(linear_loc, new_size, side=\"left\")\n    linear_loc = linear_loc[:end_idx]\n\n    idx_dtype = self.coords.dtype\n    if shape != () and not can_store(idx_dtype, max(shape)):\n        idx_dtype = np.min_scalar_type(max(shape))\n    coords = np.empty((len(shape), len(linear_loc)), dtype=idx_dtype)\n    strides = 1\n    for i, d in enumerate(shape[::-1]):\n        coords[-(i + 1), :] = (linear_loc // strides) % d\n        strides *= d\n\n    self.shape = shape\n    self.coords = coords\n\n    if len(self.data) != len(linear_loc):\n        self.data = self.data[:end_idx].copy()\n</code></pre>"},{"location":"api/COO/#sparse.COO.to_scipy_sparse","title":"<code>to_scipy_sparse(*, accept_fv=None)</code>","text":"<p>Converts this :obj:<code>COO</code> object into a :obj:<code>scipy.sparse.coo_matrix</code>.</p> <p>Parameters:</p> Name Type Description Default <code>accept_fv</code> <code>scalar or list of scalar</code> <p>The list of accepted fill-values. The default accepts only zero.</p> <code>None</code> <p>Returns:</p> Type Description <code>obj:`scipy.sparse.coo_matrix`</code> <p>The converted Scipy sparse matrix.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array is not two-dimensional.</p> <code>ValueError</code> <p>If all the array doesn't zero fill-values.</p> See Also <p>COO.tocsr : Convert to a :obj:<code>scipy.sparse.csr_matrix</code>. COO.tocsc : Convert to a :obj:<code>scipy.sparse.csc_matrix</code>.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def to_scipy_sparse(self, /, *, accept_fv=None):\n    \"\"\"\n    Converts this :obj:`COO` object into a :obj:`scipy.sparse.coo_matrix`.\n\n    Parameters\n    ----------\n    accept_fv : scalar or list of scalar, optional\n        The list of accepted fill-values. The default accepts only zero.\n\n    Returns\n    -------\n    :obj:`scipy.sparse.coo_matrix`\n        The converted Scipy sparse matrix.\n\n    Raises\n    ------\n    ValueError\n        If the array is not two-dimensional.\n    ValueError\n        If all the array doesn't zero fill-values.\n\n    See Also\n    --------\n    COO.tocsr : Convert to a :obj:`scipy.sparse.csr_matrix`.\n    COO.tocsc : Convert to a :obj:`scipy.sparse.csc_matrix`.\n    \"\"\"\n    import scipy.sparse\n\n    check_fill_value(self, accept_fv=accept_fv)\n\n    if self.ndim != 2:\n        raise ValueError(\"Can only convert a 2-dimensional array to a Scipy sparse matrix.\")\n\n    result = scipy.sparse.coo_matrix((self.data, (self.coords[0], self.coords[1])), shape=self.shape)\n    result.has_canonical_format = True\n    return result\n</code></pre>"},{"location":"api/COO/#sparse.COO.tocsr","title":"<code>tocsr()</code>","text":"<p>Converts this array to a :obj:<code>scipy.sparse.csr_matrix</code>.</p> <p>Returns:</p> Type Description <code>csr_matrix</code> <p>The result of the conversion.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array is not two-dimensional.</p> <code>ValueError</code> <p>If all the array doesn't have zero fill-values.</p> See Also <p>COO.tocsc : Convert to a :obj:<code>scipy.sparse.csc_matrix</code>. COO.to_scipy_sparse : Convert to a :obj:<code>scipy.sparse.coo_matrix</code>. scipy.sparse.coo_matrix.tocsr : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def tocsr(self):\n    \"\"\"\n    Converts this array to a :obj:`scipy.sparse.csr_matrix`.\n\n    Returns\n    -------\n    scipy.sparse.csr_matrix\n        The result of the conversion.\n\n    Raises\n    ------\n    ValueError\n        If the array is not two-dimensional.\n    ValueError\n        If all the array doesn't have zero fill-values.\n\n    See Also\n    --------\n    COO.tocsc : Convert to a :obj:`scipy.sparse.csc_matrix`.\n    COO.to_scipy_sparse : Convert to a :obj:`scipy.sparse.coo_matrix`.\n    scipy.sparse.coo_matrix.tocsr : Equivalent Scipy function.\n    \"\"\"\n    check_zero_fill_value(self)\n\n    if self._cache is not None:\n        try:\n            return self._csr\n        except AttributeError:\n            pass\n        try:\n            self._csr = self._csc.tocsr()\n            return self._csr\n        except AttributeError:\n            pass\n\n        self._csr = csr = self._tocsr()\n    else:\n        csr = self._tocsr()\n    return csr\n</code></pre>"},{"location":"api/COO/#sparse.COO.tocsc","title":"<code>tocsc()</code>","text":"<p>Converts this array to a :obj:<code>scipy.sparse.csc_matrix</code>.</p> <p>Returns:</p> Type Description <code>csc_matrix</code> <p>The result of the conversion.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array is not two-dimensional.</p> <code>ValueError</code> <p>If the array doesn't have zero fill-values.</p> See Also <p>COO.tocsr : Convert to a :obj:<code>scipy.sparse.csr_matrix</code>. COO.to_scipy_sparse : Convert to a :obj:<code>scipy.sparse.coo_matrix</code>. scipy.sparse.coo_matrix.tocsc : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def tocsc(self):\n    \"\"\"\n    Converts this array to a :obj:`scipy.sparse.csc_matrix`.\n\n    Returns\n    -------\n    scipy.sparse.csc_matrix\n        The result of the conversion.\n\n    Raises\n    ------\n    ValueError\n        If the array is not two-dimensional.\n    ValueError\n        If the array doesn't have zero fill-values.\n\n    See Also\n    --------\n    COO.tocsr : Convert to a :obj:`scipy.sparse.csr_matrix`.\n    COO.to_scipy_sparse : Convert to a :obj:`scipy.sparse.coo_matrix`.\n    scipy.sparse.coo_matrix.tocsc : Equivalent Scipy function.\n    \"\"\"\n    check_zero_fill_value(self)\n\n    if self._cache is not None:\n        try:\n            return self._csc\n        except AttributeError:\n            pass\n        try:\n            self._csc = self._csr.tocsc()\n            return self._csc\n        except AttributeError:\n            pass\n\n        self._csc = csc = self.tocsr().tocsc()\n    else:\n        csc = self.tocsr().tocsc()\n\n    return csc\n</code></pre>"},{"location":"api/COO/#sparse.COO.broadcast_to","title":"<code>broadcast_to(shape)</code>","text":"<p>Performs the equivalent of :obj:<code>numpy.broadcast_to</code> for :obj:<code>COO</code>. Note that this function returns a new array instead of a view.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>tuple[int]</code> <p>The shape to broadcast the data to.</p> required <p>Returns:</p> Type Description <code>COO</code> <p>The broadcasted sparse array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the operand cannot be broadcast to the given shape.</p> See Also <p>:obj:<code>numpy.broadcast_to</code> : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def broadcast_to(self, shape):\n    \"\"\"\n    Performs the equivalent of :obj:`numpy.broadcast_to` for :obj:`COO`. Note that\n    this function returns a new array instead of a view.\n\n    Parameters\n    ----------\n    shape : tuple[int]\n        The shape to broadcast the data to.\n\n    Returns\n    -------\n    COO\n        The broadcasted sparse array.\n\n    Raises\n    ------\n    ValueError\n        If the operand cannot be broadcast to the given shape.\n\n    See Also\n    --------\n    :obj:`numpy.broadcast_to` : NumPy equivalent function\n    \"\"\"\n    return broadcast_to(self, shape)\n</code></pre>"},{"location":"api/COO/#sparse.COO.maybe_densify","title":"<code>maybe_densify(max_size=1000, min_density=0.25)</code>","text":"<p>Converts this :obj:<code>COO</code> array to a :obj:<code>numpy.ndarray</code> if not too costly.</p> <p>Parameters:</p> Name Type Description Default <code>max_size</code> <code>int</code> <p>Maximum number of elements in output</p> <code>1000</code> <code>min_density</code> <code>float</code> <p>Minimum density of output</p> <code>0.25</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The dense array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the returned array would be too large.</p> <p>Examples:</p> <p>Convert a small sparse array to a dense array.</p> <pre><code>&gt;&gt;&gt; s = COO.from_numpy(np.random.rand(2, 3, 4))\n&gt;&gt;&gt; x = s.maybe_densify()\n&gt;&gt;&gt; np.allclose(x, s.todense())\nTrue\n</code></pre> <p>You can also specify the minimum allowed density or the maximum number of output elements. If both conditions are unmet, this method will throw an error.</p> <pre><code>&gt;&gt;&gt; x = np.zeros((5, 5), dtype=np.uint8)\n&gt;&gt;&gt; x[2, 2] = 1\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.maybe_densify(max_size=5, min_density=0.25)\nTraceback (most recent call last):\n    ...\nValueError: Operation would require converting large sparse array to dense\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def maybe_densify(self, max_size=1000, min_density=0.25):\n    \"\"\"\n    Converts this :obj:`COO` array to a :obj:`numpy.ndarray` if not too\n    costly.\n\n    Parameters\n    ----------\n    max_size : int\n        Maximum number of elements in output\n    min_density : float\n        Minimum density of output\n\n    Returns\n    -------\n    numpy.ndarray\n        The dense array.\n\n    Raises\n    ------\n    ValueError\n        If the returned array would be too large.\n\n    Examples\n    --------\n    Convert a small sparse array to a dense array.\n\n    &gt;&gt;&gt; s = COO.from_numpy(np.random.rand(2, 3, 4))\n    &gt;&gt;&gt; x = s.maybe_densify()\n    &gt;&gt;&gt; np.allclose(x, s.todense())\n    True\n\n    You can also specify the minimum allowed density or the maximum number\n    of output elements. If both conditions are unmet, this method will throw\n    an error.\n\n    &gt;&gt;&gt; x = np.zeros((5, 5), dtype=np.uint8)\n    &gt;&gt;&gt; x[2, 2] = 1\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s.maybe_densify(max_size=5, min_density=0.25)\n    Traceback (most recent call last):\n        ...\n    ValueError: Operation would require converting large sparse array to dense\n    \"\"\"\n    if self.size &gt; max_size and self.density &lt; min_density:\n        raise ValueError(\"Operation would require converting large sparse array to dense\")\n\n    return self.todense()\n</code></pre>"},{"location":"api/COO/#sparse.COO.nonzero","title":"<code>nonzero()</code>","text":"<p>Get the indices where this array is nonzero.</p> <p>Returns:</p> Name Type Description <code>idx</code> <code>tuple[ndarray]</code> <p>The indices where this array is nonzero.</p> See Also <p>numpy.ndarray.nonzero : NumPy equivalent function</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array doesn't have zero fill-values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = COO.from_numpy(np.eye(5))\n&gt;&gt;&gt; s.nonzero()\n(array([0, 1, 2, 3, 4]), array([0, 1, 2, 3, 4]))\n</code></pre> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def nonzero(self):\n    \"\"\"\n    Get the indices where this array is nonzero.\n\n    Returns\n    -------\n    idx : tuple[numpy.ndarray]\n        The indices where this array is nonzero.\n\n    See Also\n    --------\n    [numpy.ndarray.nonzero][] : NumPy equivalent function\n\n    Raises\n    ------\n    ValueError\n        If the array doesn't have zero fill-values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = COO.from_numpy(np.eye(5))\n    &gt;&gt;&gt; s.nonzero()\n    (array([0, 1, 2, 3, 4]), array([0, 1, 2, 3, 4]))\n    \"\"\"\n    check_zero_fill_value(self)\n    if self.ndim == 0:\n        raise ValueError(\"`nonzero` is undefined for `self.ndim == 0`.\")\n    return tuple(self.coords)\n</code></pre>"},{"location":"api/COO/#sparse.COO.asformat","title":"<code>asformat(format, **kwargs)</code>","text":"<p>Convert this sparse array to a given format.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>A format string.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The converted array.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the format isn't supported.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def asformat(self, format, **kwargs):\n    \"\"\"\n    Convert this sparse array to a given format.\n\n    Parameters\n    ----------\n    format : str\n        A format string.\n\n    Returns\n    -------\n    out : SparseArray\n        The converted array.\n\n    Raises\n    ------\n    NotImplementedError\n        If the format isn't supported.\n    \"\"\"\n    from .._utils import convert_format\n\n    format = convert_format(format)\n\n    if format == \"gcxs\":\n        from .._compressed import GCXS\n\n        return GCXS.from_coo(self, **kwargs)\n\n    if len(kwargs) != 0:\n        raise TypeError(f\"Invalid keyword arguments provided: {kwargs}\")\n\n    if format == \"coo\":\n        return self\n\n    if format == \"dok\":\n        from .._dok import DOK\n\n        return DOK.from_coo(self, **kwargs)\n\n    return self.asformat(\"gcxs\", **kwargs).asformat(format, **kwargs)\n</code></pre>"},{"location":"api/COO/#sparse.COO.isinf","title":"<code>isinf()</code>","text":"<p>Tests each element <code>x_i</code> of the array to determine if equal to positive or negative infinity.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def isinf(self):\n    \"\"\"\n    Tests each element ``x_i`` of the array to determine if equal to positive or negative infinity.\n    \"\"\"\n    new_fill_value = bool(np.isinf(self.fill_value))\n    new_data = np.isinf(self.data)\n\n    return COO(\n        self.coords,\n        new_data,\n        shape=self.shape,\n        fill_value=new_fill_value,\n        prune=True,\n    )\n</code></pre>"},{"location":"api/COO/#sparse.COO.isnan","title":"<code>isnan()</code>","text":"<p>Tests each element <code>x_i</code> of the array to determine whether the element is <code>NaN</code>.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def isnan(self):\n    \"\"\"\n    Tests each element ``x_i`` of the array to determine whether the element is ``NaN``.\n    \"\"\"\n    new_fill_value = bool(np.isnan(self.fill_value))\n    new_data = np.isnan(self.data)\n\n    return COO(\n        self.coords,\n        new_data,\n        shape=self.shape,\n        fill_value=new_fill_value,\n        prune=True,\n    )\n</code></pre>"},{"location":"api/DOK/","title":"DOK","text":"<p>               Bases: <code>SparseArray</code>, <code>NDArrayOperatorsMixin</code></p> <p>A class for building sparse multidimensional arrays.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>tuple[int](ndim)</code> <p>The shape of the array.</p> required <code>data</code> <code>dict</code> <p>The key-value pairs for the data in this array.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type of this array. If left empty, it is inferred from the first element.</p> <code>None</code> <code>fill_value</code> <code>scalar</code> <p>The fill value of this array.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>dtype</code> <code>dtype</code> <p>The datatype of this array. Can be :code:<code>None</code> if no elements have been set yet.</p> <code>shape</code> <code>tuple[int]</code> <p>The shape of this array.</p> <code>data</code> <code>dict</code> <p>The keys of this dictionary contain all the indices and the values contain the nonzero entries.</p> See Also <p>COO : A read-only sparse array.</p> <p>Examples:</p> <p>You can create :obj:<code>DOK</code> objects from Numpy arrays.</p> <pre><code>&gt;&gt;&gt; x = np.eye(5, dtype=np.uint8)\n&gt;&gt;&gt; x[2, 3] = 5\n&gt;&gt;&gt; s = DOK.from_numpy(x)\n&gt;&gt;&gt; s\n&lt;DOK: shape=(5, 5), dtype=uint8, nnz=6, fill_value=0&gt;\n</code></pre> <p>You can also create them from just shapes, and use slicing assignment.</p> <pre><code>&gt;&gt;&gt; s2 = DOK((5, 5), dtype=np.int64)\n&gt;&gt;&gt; s2[1:3, 1:3] = [[4, 5], [6, 7]]\n&gt;&gt;&gt; s2\n&lt;DOK: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n</code></pre> <p>You can convert :obj:<code>DOK</code> arrays to :obj:<code>COO</code> arrays, or :obj:<code>numpy.ndarray</code> objects.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; s3 = COO(s2)\n&gt;&gt;&gt; s3\n&lt;COO: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n&gt;&gt;&gt; s2.todense()\narray([[0, 0, 0, 0, 0],\n       [0, 4, 5, 0, 0],\n       [0, 6, 7, 0, 0],\n       [0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0]])\n</code></pre> <pre><code>&gt;&gt;&gt; s4 = COO.from_numpy(np.eye(4, dtype=np.uint8))\n&gt;&gt;&gt; s4\n&lt;COO: shape=(4, 4), dtype=uint8, nnz=4, fill_value=0&gt;\n&gt;&gt;&gt; s5 = DOK.from_coo(s4)\n&gt;&gt;&gt; s5\n&lt;DOK: shape=(4, 4), dtype=uint8, nnz=4, fill_value=0&gt;\n</code></pre> <p>You can also create :obj:<code>DOK</code> arrays from a shape and a dict of values. Zeros are automatically ignored.</p> <pre><code>&gt;&gt;&gt; values = {\n...     (1, 2, 3): 4,\n...     (3, 2, 1): 0,\n... }\n&gt;&gt;&gt; s6 = DOK((5, 5, 5), values)\n&gt;&gt;&gt; s6\n&lt;DOK: shape=(5, 5, 5), dtype=int64, nnz=1, fill_value=0.0&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>class DOK(SparseArray, NDArrayOperatorsMixin):\n    \"\"\"\n    A class for building sparse multidimensional arrays.\n\n    Parameters\n    ----------\n    shape : tuple[int] (DOK.ndim,)\n        The shape of the array.\n    data : dict, optional\n        The key-value pairs for the data in this array.\n    dtype : np.dtype, optional\n        The data type of this array. If left empty, it is inferred from\n        the first element.\n    fill_value : scalar, optional\n        The fill value of this array.\n\n    Attributes\n    ----------\n    dtype : numpy.dtype\n        The datatype of this array. Can be :code:`None` if no elements\n        have been set yet.\n    shape : tuple[int]\n        The shape of this array.\n    data : dict\n        The keys of this dictionary contain all the indices and the values\n        contain the nonzero entries.\n\n    See Also\n    --------\n    COO : A read-only sparse array.\n\n    Examples\n    --------\n    You can create :obj:`DOK` objects from Numpy arrays.\n\n    &gt;&gt;&gt; x = np.eye(5, dtype=np.uint8)\n    &gt;&gt;&gt; x[2, 3] = 5\n    &gt;&gt;&gt; s = DOK.from_numpy(x)\n    &gt;&gt;&gt; s\n    &lt;DOK: shape=(5, 5), dtype=uint8, nnz=6, fill_value=0&gt;\n\n    You can also create them from just shapes, and use slicing assignment.\n\n    &gt;&gt;&gt; s2 = DOK((5, 5), dtype=np.int64)\n    &gt;&gt;&gt; s2[1:3, 1:3] = [[4, 5], [6, 7]]\n    &gt;&gt;&gt; s2\n    &lt;DOK: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n\n    You can convert :obj:`DOK` arrays to :obj:`COO` arrays, or :obj:`numpy.ndarray`\n    objects.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; s3 = COO(s2)\n    &gt;&gt;&gt; s3\n    &lt;COO: shape=(5, 5), dtype=int64, nnz=4, fill_value=0&gt;\n    &gt;&gt;&gt; s2.todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[0, 0, 0, 0, 0],\n           [0, 4, 5, 0, 0],\n           [0, 6, 7, 0, 0],\n           [0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0]])\n\n    &gt;&gt;&gt; s4 = COO.from_numpy(np.eye(4, dtype=np.uint8))\n    &gt;&gt;&gt; s4\n    &lt;COO: shape=(4, 4), dtype=uint8, nnz=4, fill_value=0&gt;\n    &gt;&gt;&gt; s5 = DOK.from_coo(s4)\n    &gt;&gt;&gt; s5\n    &lt;DOK: shape=(4, 4), dtype=uint8, nnz=4, fill_value=0&gt;\n\n    You can also create :obj:`DOK` arrays from a shape and a dict of\n    values. Zeros are automatically ignored.\n\n    &gt;&gt;&gt; values = {\n    ...     (1, 2, 3): 4,\n    ...     (3, 2, 1): 0,\n    ... }\n    &gt;&gt;&gt; s6 = DOK((5, 5, 5), values)\n    &gt;&gt;&gt; s6\n    &lt;DOK: shape=(5, 5, 5), dtype=int64, nnz=1, fill_value=0.0&gt;\n    \"\"\"\n\n    def __init__(self, shape, data=None, dtype=None, fill_value=None):\n        from ._common import _is_scipy_sparse_obj\n        from ._coo import COO\n\n        self.data = {}\n\n        if isinstance(shape, COO):\n            ar = DOK.from_coo(shape)\n            self._make_shallow_copy_of(ar)\n            return\n\n        if isinstance(shape, np.ndarray):\n            ar = DOK.from_numpy(shape)\n            self._make_shallow_copy_of(ar)\n            return\n\n        if _is_scipy_sparse_obj(shape):\n            ar = DOK.from_scipy_sparse(shape)\n            self._make_shallow_copy_of(ar)\n            return\n\n        self.dtype = np.dtype(dtype)\n\n        if not data:\n            data = {}\n\n        super().__init__(shape, fill_value=fill_value)\n\n        if isinstance(data, dict):\n            if not dtype:\n                if not len(data):\n                    self.dtype = np.dtype(\"float64\")\n                else:\n                    self.dtype = np.result_type(*(np.asarray(x).dtype for x in data.values()))\n\n            for c, d in data.items():\n                self[c] = d\n        else:\n            raise ValueError(\"data must be a dict.\")\n\n    @classmethod\n    def from_scipy_sparse(cls, x, /, *, fill_value=None):\n        \"\"\"\n        Create a :obj:`DOK` array from a :obj:`scipy.sparse.spmatrix`.\n\n        Parameters\n        ----------\n        x : scipy.sparse.spmatrix\n            The matrix to convert.\n        fill_value : scalar\n            The fill-value to use when converting.\n\n        Returns\n        -------\n        DOK\n            The equivalent :obj:`DOK` array.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = scipy.sparse.rand(6, 3, density=0.2)\n        &gt;&gt;&gt; s = DOK.from_scipy_sparse(x)\n        &gt;&gt;&gt; np.array_equal(x.todense(), s.todense())\n        True\n        \"\"\"\n        from sparse import COO\n\n        return COO.from_scipy_sparse(x, fill_value=fill_value).asformat(cls)\n\n    @classmethod\n    def from_coo(cls, x):\n        \"\"\"\n        Get a :obj:`DOK` array from a :obj:`COO` array.\n\n        Parameters\n        ----------\n        x : COO\n            The array to convert.\n\n        Returns\n        -------\n        DOK\n            The equivalent :obj:`DOK` array.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; s = COO.from_numpy(np.eye(4))\n        &gt;&gt;&gt; s2 = DOK.from_coo(s)\n        &gt;&gt;&gt; s2\n        &lt;DOK: shape=(4, 4), dtype=float64, nnz=4, fill_value=0.0&gt;\n        \"\"\"\n        ar = cls(x.shape, dtype=x.dtype, fill_value=x.fill_value)\n\n        for c, d in zip(x.coords.T, x.data, strict=True):\n            ar.data[tuple(c)] = d\n\n        return ar\n\n    def to_coo(self):\n        \"\"\"\n        Convert this :obj:`DOK` array to a :obj:`COO` array.\n\n        Returns\n        -------\n        COO\n            The equivalent :obj:`COO` array.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = DOK((5, 5))\n        &gt;&gt;&gt; s[1:3, 1:3] = [[4, 5], [6, 7]]\n        &gt;&gt;&gt; s\n        &lt;DOK: shape=(5, 5), dtype=float64, nnz=4, fill_value=0.0&gt;\n        &gt;&gt;&gt; s2 = s.to_coo()\n        &gt;&gt;&gt; s2\n        &lt;COO: shape=(5, 5), dtype=float64, nnz=4, fill_value=0.0&gt;\n        \"\"\"\n        from ._coo import COO\n\n        return COO(self)\n\n    @classmethod\n    def from_numpy(cls, x):\n        \"\"\"\n        Get a :obj:`DOK` array from a Numpy array.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            The array to convert.\n\n        Returns\n        -------\n        DOK\n            The equivalent :obj:`DOK` array.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = DOK.from_numpy(np.eye(4))\n        &gt;&gt;&gt; s\n        &lt;DOK: shape=(4, 4), dtype=float64, nnz=4, fill_value=0.0&gt;\n        \"\"\"\n        ar = cls(x.shape, dtype=x.dtype)\n\n        coords = np.nonzero(x)\n        data = x[coords]\n\n        for c in zip(data, *coords, strict=True):\n            d, c = c[0], c[1:]\n            ar.data[c] = d\n\n        return ar\n\n    @property\n    def nnz(self):\n        \"\"\"\n        The number of nonzero elements in this array.\n\n        Returns\n        -------\n        int\n            The number of nonzero elements.\n\n        See Also\n        --------\n        COO.nnz : Equivalent :obj:`COO` array property.\n        numpy.count_nonzero : A similar Numpy function.\n        scipy.sparse.dok_matrix.nnz : The Scipy equivalent property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; values = {\n        ...     (1, 2, 3): 4,\n        ...     (3, 2, 1): 0,\n        ... }\n        &gt;&gt;&gt; s = DOK((5, 5, 5), values)\n        &gt;&gt;&gt; s.nnz\n        1\n        \"\"\"\n        return len(self.data)\n\n    @property\n    def format(self):\n        \"\"\"\n        The storage format of this array.\n        Returns\n        -------\n        str\n            The storage format of this array.\n        See Also\n        -------\n        scipy.sparse.dok_matrix.format : The Scipy equivalent property.\n        Examples\n        -------\n        &gt;&gt;&gt; import sparse\n        &gt;&gt;&gt; s = sparse.random((5, 5), density=0.2, format=\"dok\")\n        &gt;&gt;&gt; s.format\n        'dok'\n        &gt;&gt;&gt; t = sparse.random((5, 5), density=0.2, format=\"coo\")\n        &gt;&gt;&gt; t.format\n        'coo'\n        \"\"\"\n        return \"dok\"\n\n    @property\n    def nbytes(self):\n        \"\"\"\n        The number of bytes taken up by this object. Note that for small arrays,\n        this may undercount the number of bytes due to the large constant overhead.\n\n        Returns\n        -------\n        int\n            The approximate bytes of memory taken by this object.\n\n        See Also\n        --------\n        numpy.ndarray.nbytes : The equivalent Numpy property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import sparse\n        &gt;&gt;&gt; x = sparse.random((100, 100), density=0.1, format=\"dok\")\n        &gt;&gt;&gt; x.nbytes\n        8000\n        \"\"\"\n        return self.nnz * self.dtype.itemsize\n\n    def __getitem__(self, key):\n        if not isinstance(key, tuple):\n            key = (key,)\n\n        if all(isinstance(k, Iterable) for k in key):\n            if len(key) != self.ndim:\n                raise NotImplementedError(f\"Index sequences for all {self.ndim} array dimensions needed!\")\n            if not all(len(key[0]) == len(k) for k in key):\n                raise IndexError(\"Unequal length of index sequences!\")\n            return self._fancy_getitem(key)\n\n        key = normalize_index(key, self.shape)\n\n        ret = self.asformat(\"coo\")[key]\n        if isinstance(ret, SparseArray):\n            ret = ret.asformat(\"dok\")\n\n        return ret\n\n    def _fancy_getitem(self, key):\n        \"\"\"Subset of fancy indexing, when all dimensions are accessed\"\"\"\n        new_data = {}\n        for i, k in enumerate(zip(*key, strict=True)):\n            if k in self.data:\n                new_data[i] = self.data[k]\n        return DOK(\n            shape=(len(key[0])),\n            data=new_data,\n            dtype=self.dtype,\n            fill_value=self.fill_value,\n        )\n\n    def __setitem__(self, key, value):\n        value = np.asarray(value, dtype=self.dtype)\n\n        # 1D fancy indexing\n        if self.ndim == 1 and isinstance(key, Iterable) and all(isinstance(i, int | np.integer) for i in key):\n            key = (key,)\n\n        if isinstance(key, tuple) and all(isinstance(k, Iterable) for k in key):\n            if len(key) != self.ndim:\n                raise NotImplementedError(f\"Index sequences for all {self.ndim} array dimensions needed!\")\n            if not all(len(key[0]) == len(k) for k in key):\n                raise IndexError(\"Unequal length of index sequences!\")\n            self._fancy_setitem(key, value)\n            return\n\n        key = normalize_index(key, self.shape)\n\n        key_list = [int(k) if isinstance(k, Integral) else k for k in key]\n\n        self._setitem(key_list, value)\n\n    def _fancy_setitem(self, idxs, values):\n        idxs = tuple(np.asanyarray(idxs) for idxs in idxs)\n        if not all(np.issubdtype(k.dtype, np.integer) for k in idxs):\n            raise IndexError(\"Indices must be sequences of integer types!\")\n        if idxs[0].ndim != 1:\n            raise IndexError(\"Indices are not 1d sequences!\")\n        if values.ndim == 0:\n            values = np.full(idxs[0].size, values, self.dtype)\n        elif values.ndim &gt; 1:\n            raise ValueError(f\"Dimension of values ({values.ndim}) must be 0 or 1!\")\n        if not idxs[0].shape == values.shape:\n            raise ValueError(f\"Shape mismatch of indices ({idxs[0].shape}) and values ({values.shape})!\")\n        fill_value = self.fill_value\n        data = self.data\n        for idx, value in zip(zip(*idxs, strict=True), values, strict=True):\n            if value != fill_value:\n                data[idx] = value\n            elif idx in data:\n                del data[idx]\n\n    def _setitem(self, key_list, value):\n        value_missing_dims = len([ind for ind in key_list if isinstance(ind, slice)]) - value.ndim\n\n        if value_missing_dims &lt; 0:\n            raise ValueError(\"setting an array element with a sequence.\")\n\n        for i, ind in enumerate(key_list):\n            if isinstance(ind, slice):\n                step = ind.step if ind.step is not None else 1\n                if step &gt; 0:\n                    start = ind.start if ind.start is not None else 0\n                    start = max(start, 0)\n                    stop = ind.stop if ind.stop is not None else self.shape[i]\n                    stop = min(stop, self.shape[i])\n                    if start &gt; stop:\n                        start = stop\n                else:\n                    start = ind.start or self.shape[i] - 1\n                    stop = ind.stop if ind.stop is not None else -1\n                    start = min(start, self.shape[i] - 1)\n                    stop = max(stop, -1)\n                    if start &lt; stop:\n                        start = stop\n\n                key_list_temp = key_list[:]\n                for v_idx, ki in enumerate(range(start, stop, step)):\n                    key_list_temp[i] = ki\n                    vi = value if value_missing_dims &gt; 0 else (value[0] if value.shape[0] == 1 else value[v_idx])\n                    self._setitem(key_list_temp, vi)\n\n                return\n            if not isinstance(ind, Integral):\n                raise IndexError(\"All indices must be slices or integers when setting an item.\")\n\n        key = tuple(key_list)\n        if not equivalent(value, self.fill_value):\n            self.data[key] = value[()]\n        elif key in self.data:\n            del self.data[key]\n\n    def __str__(self):\n        summary = f\"&lt;DOK: shape={self.shape!s}, dtype={self.dtype!s}, nnz={self.nnz:d}, fill_value={self.fill_value!s}&gt;\"\n        return self._str_impl(summary)\n\n    __repr__ = __str__\n\n    def todense(self):\n        \"\"\"\n        Convert this :obj:`DOK` array into a Numpy array.\n\n        Returns\n        -------\n        numpy.ndarray\n            The equivalent dense array.\n\n        See Also\n        --------\n        COO.todense : Equivalent :obj:`COO` array method.\n        scipy.sparse.dok_matrix.todense : Equivalent Scipy method.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = DOK((5, 5))\n        &gt;&gt;&gt; s[1:3, 1:3] = [[4, 5], [6, 7]]\n        &gt;&gt;&gt; s.todense()  # doctest: +SKIP\n        array([[0., 0., 0., 0., 0.],\n               [0., 4., 5., 0., 0.],\n               [0., 6., 7., 0., 0.],\n               [0., 0., 0., 0., 0.],\n               [0., 0., 0., 0., 0.]])\n        \"\"\"\n        result = np.full(self.shape, self.fill_value, self.dtype)\n\n        for c, d in self.data.items():\n            result[c] = d\n\n        return result\n\n    def asformat(self, format, **kwargs):\n        \"\"\"\n        Convert this sparse array to a given format.\n\n        Parameters\n        ----------\n        format : str\n            A format string.\n\n        Returns\n        -------\n        out : SparseArray\n            The converted array.\n\n        Raises\n        ------\n        NotImplementedError\n            If the format isn't supported.\n        \"\"\"\n        from ._utils import convert_format\n\n        format = convert_format(format)\n\n        if format == \"dok\":\n            return self\n\n        if format == \"coo\":\n            from ._coo import COO\n\n            if len(kwargs) != 0:\n                raise ValueError(f\"Extra kwargs found: {kwargs}\")\n            return COO.from_iter(\n                self.data,\n                shape=self.shape,\n                fill_value=self.fill_value,\n                dtype=self.dtype,\n            )\n\n        return self.asformat(\"coo\").asformat(format, **kwargs)\n\n    def reshape(self, shape, order=\"C\"):\n        \"\"\"\n        Returns a new :obj:`DOK` array that is a reshaped version of this array.\n\n        Parameters\n        ----------\n        shape : tuple[int]\n            The desired shape of the output array.\n\n        Returns\n        -------\n        DOK\n            The reshaped output array.\n\n        See Also\n        --------\n        numpy.ndarray.reshape : The equivalent Numpy function.\n\n        Notes\n        -----\n        The :code:`order` parameter is provided just for compatibility with\n        Numpy and isn't actually supported.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = DOK.from_numpy(np.arange(25))\n        &gt;&gt;&gt; s2 = s.reshape((5, 5))\n        &gt;&gt;&gt; s2.todense()  # doctest: +NORMALIZE_WHITESPACE\n        array([[ 0,  1,  2,  3,  4],\n               [ 5,  6,  7,  8,  9],\n               [10, 11, 12, 13, 14],\n               [15, 16, 17, 18, 19],\n               [20, 21, 22, 23, 24]])\n        \"\"\"\n        if order not in {\"C\", None}:\n            raise NotImplementedError(\"The 'order' parameter is not supported\")\n\n        return DOK.from_coo(self.to_coo().reshape(shape))\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.shape","title":"<code>shape = tuple(int(sh) for sh in shape)</code>  <code>instance-attribute</code>","text":""},{"location":"api/DOK/#sparse.DOK.fill_value","title":"<code>fill_value = self.dtype.type(fill_value)</code>  <code>instance-attribute</code>","text":""},{"location":"api/DOK/#sparse.DOK.device","title":"<code>device</code>  <code>property</code>","text":""},{"location":"api/DOK/#sparse.DOK.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>The number of dimensions of this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of dimensions of this array.</p> See Also <pre><code>[DOK.ndim][sparse.DOK.ndim] : Equivalent property for [DOK][sparse.DOK] arrays.\n[numpy.ndarray.ndim][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.random.rand(1, 2, 3, 1, 2)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.ndim\n5\n&gt;&gt;&gt; s.ndim == x.ndim\nTrue\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.size","title":"<code>size</code>  <code>property</code>","text":"<p>The number of all elements (including zeros) in this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of elements.</p> See Also <pre><code>[numpy.ndarray.size][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.zeros((10, 10))\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.size\n100\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.density","title":"<code>density</code>  <code>property</code>","text":"<p>The ratio of nonzero to all elements in this array.</p> <p>Returns:</p> Type Description <code>float</code> <p>The ratio of nonzero to all elements.</p> See Also <pre><code>COO.size : Number of elements.\nCOO.nnz : Number of nonzero elements.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.zeros((8, 8))\n&gt;&gt;&gt; x[0, :] = 1\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.density\n0.125\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.amax","title":"<code>amax = max</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/DOK/#sparse.DOK.amin","title":"<code>amin = min</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/DOK/#sparse.DOK.round_","title":"<code>round_ = round</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/DOK/#sparse.DOK.real","title":"<code>real</code>  <code>property</code>","text":"<p>The real part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.real.todense()\narray([1., 0.])\n&gt;&gt;&gt; x.real.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The real component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.real : NumPy equivalent attribute. numpy.real : NumPy equivalent function.</p>"},{"location":"api/DOK/#sparse.DOK.imag","title":"<code>imag</code>  <code>property</code>","text":"<p>The imaginary part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.imag.todense()\narray([0., 1.])\n&gt;&gt;&gt; x.imag.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The imaginary component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.imag : NumPy equivalent attribute. numpy.imag : NumPy equivalent function.</p>"},{"location":"api/DOK/#sparse.DOK.data","title":"<code>data = {}</code>  <code>instance-attribute</code>","text":""},{"location":"api/DOK/#sparse.DOK.dtype","title":"<code>dtype = np.dtype(dtype)</code>  <code>instance-attribute</code>","text":""},{"location":"api/DOK/#sparse.DOK.nnz","title":"<code>nnz</code>  <code>property</code>","text":"<p>The number of nonzero elements in this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of nonzero elements.</p> See Also <p>COO.nnz : Equivalent :obj:<code>COO</code> array property. numpy.count_nonzero : A similar Numpy function. scipy.sparse.dok_matrix.nnz : The Scipy equivalent property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; values = {\n...     (1, 2, 3): 4,\n...     (3, 2, 1): 0,\n... }\n&gt;&gt;&gt; s = DOK((5, 5, 5), values)\n&gt;&gt;&gt; s.nnz\n1\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.format","title":"<code>format</code>  <code>property</code>","text":"<p>The storage format of this array.</p> <p>Returns:</p> Type Description <code>str</code> <p>The storage format of this array.</p> See Also <p>scipy.sparse.dok_matrix.format : The Scipy equivalent property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; s = sparse.random((5, 5), density=0.2, format=\"dok\")\n&gt;&gt;&gt; s.format\n'dok'\n&gt;&gt;&gt; t = sparse.random((5, 5), density=0.2, format=\"coo\")\n&gt;&gt;&gt; t.format\n'coo'\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.nbytes","title":"<code>nbytes</code>  <code>property</code>","text":"<p>The number of bytes taken up by this object. Note that for small arrays, this may undercount the number of bytes due to the large constant overhead.</p> <p>Returns:</p> Type Description <code>int</code> <p>The approximate bytes of memory taken by this object.</p> See Also <p>numpy.ndarray.nbytes : The equivalent Numpy property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.random((100, 100), density=0.1, format=\"dok\")\n&gt;&gt;&gt; x.nbytes\n8000\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.to_device","title":"<code>to_device(device, /, *, stream=None)</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def to_device(self, device, /, *, stream=None):\n    if device != \"cpu\":\n        raise ValueError(\"Only `device='cpu'` is supported.\")\n\n    return self\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.reduce","title":"<code>reduce(method, axis=(0), keepdims=False, **kwargs)</code>","text":"<p>Performs a reduction operation on this array.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>ufunc</code> <p>The method to use for performing the reduction.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to perform the reduction. Uses all axes by default.</p> <code>(0)</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Any extra arguments to pass to the reduction operation.</p> <code>{}</code> See Also <p>numpy.ufunc.reduce : A similar Numpy method. COO.reduce : This method implemented on COO arrays. GCXS.reduce : This method implemented on GCXS arrays.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def reduce(self, method, axis=(0,), keepdims=False, **kwargs):\n    \"\"\"\n    Performs a reduction operation on this array.\n\n    Parameters\n    ----------\n    method : numpy.ufunc\n        The method to use for performing the reduction.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to perform the reduction. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    **kwargs : dict\n        Any extra arguments to pass to the reduction operation.\n\n    See Also\n    --------\n    numpy.ufunc.reduce : A similar Numpy method.\n    COO.reduce : This method implemented on COO arrays.\n    GCXS.reduce : This method implemented on GCXS arrays.\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n    zero_reduce_result = method.reduce([self.fill_value, self.fill_value], **kwargs)\n    reduce_super_ufunc = _reduce_super_ufunc.get(method)\n    if not equivalent(zero_reduce_result, self.fill_value) and reduce_super_ufunc is None:\n        raise ValueError(f\"Performing this reduction operation would produce a dense result: {method!s}\")\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n    out = self._reduce_calc(method, axis, keepdims, **kwargs)\n    if len(out) == 1:\n        return out[0]\n    data, counts, axis, n_cols, arr_attrs = out\n    result_fill_value = self.fill_value\n    if reduce_super_ufunc is None:\n        missing_counts = counts != n_cols\n        data[missing_counts] = method(data[missing_counts], self.fill_value, **kwargs)\n    else:\n        data = method(\n            data,\n            reduce_super_ufunc(self.fill_value, n_cols - counts),\n        ).astype(data.dtype)\n        result_fill_value = reduce_super_ufunc(self.fill_value, n_cols)\n\n    out = self._reduce_return(data, arr_attrs, result_fill_value)\n\n    if keepdims:\n        shape = list(self.shape)\n        for ax in axis:\n            shape[ax] = 1\n        out = out.reshape(shape)\n\n    if out.ndim == 0:\n        return out[()]\n\n    return out\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.sum","title":"<code>sum(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a sum operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to sum. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.sum</code> : Equivalent numpy function. scipy.sparse.coo_matrix.sum : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def sum(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a sum operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to sum. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.sum` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.sum : Equivalent Scipy function.\n    \"\"\"\n    return np.add.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.max","title":"<code>max(axis=None, keepdims=False, out=None)</code>","text":"<p>Maximize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to maximize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.max</code> : Equivalent numpy function. scipy.sparse.coo_matrix.max : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def max(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Maximize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to maximize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.max` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.max : Equivalent Scipy function.\n    \"\"\"\n    return np.maximum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.any","title":"<code>any(axis=None, keepdims=False, out=None)</code>","text":"<p>See if any values along array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.any</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def any(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if any values along array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.any` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_or.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.all","title":"<code>all(axis=None, keepdims=False, out=None)</code>","text":"<p>See if all values in an array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.all</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def all(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if all values in an array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.all` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_and.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.min","title":"<code>min(axis=None, keepdims=False, out=None)</code>","text":"<p>Minimize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.min</code> : Equivalent numpy function. scipy.sparse.coo_matrix.min : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def min(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Minimize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.min` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.min : Equivalent Scipy function.\n    \"\"\"\n    return np.minimum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.prod","title":"<code>prod(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a product operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to multiply. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.prod</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def prod(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a product operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to multiply. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.prod` : Equivalent numpy function.\n    \"\"\"\n    return np.multiply.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.round","title":"<code>round(decimals=0, out=None)</code>","text":"<p>Evenly round to the given number of decimals.</p> See Also <p>:obj:<code>numpy.round</code> :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def round(self, decimals=0, out=None):\n    \"\"\"\n    Evenly round to the given number of decimals.\n\n    See Also\n    --------\n    :obj:`numpy.round` :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.round, \"__call__\", self, decimals=decimals, out=out)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.clip","title":"<code>clip(min=None, max=None, out=None)</code>","text":"<p>Clip (limit) the values in the array.</p> <p>Return an array whose values are limited to <code>[min, max]</code>. One of min or max must be given.</p> See Also <p>sparse.clip : For full documentation and more details. numpy.clip : Equivalent NumPy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def clip(self, min=None, max=None, out=None):\n    \"\"\"\n    Clip (limit) the values in the array.\n\n    Return an array whose values are limited to ``[min, max]``. One of min\n    or max must be given.\n\n    See Also\n    --------\n    sparse.clip : For full documentation and more details.\n    numpy.clip : Equivalent NumPy function.\n    \"\"\"\n    if min is None and max is None:\n        raise ValueError(\"One of max or min must be given.\")\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.clip, \"__call__\", self, a_min=min, a_max=max, out=out)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.astype","title":"<code>astype(dtype, casting='unsafe', copy=True)</code>","text":"<p>Copy of the array, cast to a specified type.</p> See Also <p>scipy.sparse.coo_matrix.astype :     SciPy sparse equivalent function numpy.ndarray.astype :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def astype(self, dtype, casting=\"unsafe\", copy=True):\n    \"\"\"\n    Copy of the array, cast to a specified type.\n\n    See Also\n    --------\n    scipy.sparse.coo_matrix.astype :\n        SciPy sparse equivalent function\n    numpy.ndarray.astype :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    # this matches numpy's behavior\n    if self.dtype == dtype and not copy:\n        return self\n    return self.__array_ufunc__(np.ndarray.astype, \"__call__\", self, dtype=dtype, copy=copy, casting=casting)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.mean","title":"<code>mean(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Compute the mean along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the mean. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.mean : Equivalent numpy method. scipy.sparse.coo_matrix.mean : Equivalent Scipy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> <li>The :code:<code>out</code> parameter is provided just for compatibility with   Numpy and isn't actually supported.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.mean</code> to compute the mean of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.mean(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.5, 1.5, 0., 0.])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the mean.</p> <pre><code>&gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the mean along all axes.</p> <pre><code>&gt;&gt;&gt; s.mean()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def mean(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Compute the mean along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the mean. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.mean : Equivalent numpy method.\n    scipy.sparse.coo_matrix.mean : Equivalent Scipy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n    * The :code:`out` parameter is provided just for compatibility with\n      Numpy and isn't actually supported.\n\n    Examples\n    --------\n    You can use :obj:`COO.mean` to compute the mean of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.mean(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.5, 1.5, 0., 0.])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the mean.\n\n    &gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    mean along all axes.\n\n    &gt;&gt;&gt; s.mean()\n    0.5\n    \"\"\"\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n    elif not isinstance(axis, tuple):\n        axis = (axis,)\n    den = reduce(operator.mul, (self.shape[i] for i in axis), 1)\n\n    if dtype is None:\n        if issubclass(self.dtype.type, np.integer | np.bool_):\n            dtype = inter_dtype = np.dtype(\"f8\")\n        else:\n            dtype = self.dtype\n            inter_dtype = np.dtype(\"f4\") if issubclass(dtype.type, np.float16) else dtype\n    else:\n        inter_dtype = dtype\n\n    num = self.sum(axis=axis, keepdims=keepdims, dtype=inter_dtype)\n\n    if num.ndim:\n        out = np.true_divide(num, den, casting=\"unsafe\")\n        return out.astype(dtype) if out.dtype != dtype else out\n    return np.divide(num, den, dtype=dtype, out=out)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.var","title":"<code>var(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the variance along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the variance. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.var : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.var</code> to compute the variance of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.var(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.6875, 0.1875])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the variance.</p> <pre><code>&gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the variance along all axes.</p> <pre><code>&gt;&gt;&gt; s.var()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the variance along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the variance. Uses all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.var : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.var` to compute the variance of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.var(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.6875, 0.1875])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the variance.\n\n    &gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    variance along all axes.\n\n    &gt;&gt;&gt; s.var()\n    0.5\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n\n    rcount = reduce(operator.mul, (self.shape[a] for a in axis), 1)\n    # Make this warning show up on top.\n    if ddof &gt;= rcount:\n        warnings.warn(\"Degrees of freedom &lt;= 0 for slice\", RuntimeWarning, stacklevel=1)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None and issubclass(self.dtype.type, np.integer | np.bool_):\n        dtype = np.dtype(\"f8\")\n\n    arrmean = self.sum(axis, dtype=dtype, keepdims=True)[...]\n    np.divide(arrmean, rcount, out=arrmean)\n    x = self - arrmean\n    if issubclass(self.dtype.type, np.complexfloating):\n        x = x.real * x.real + x.imag * x.imag\n    else:\n        x = np.multiply(x, x, out=x)\n\n    ret = x.sum(axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n    # Compute degrees of freedom and make sure it is not negative.\n    rcount = max([rcount - ddof, 0])\n\n    ret = ret[...]\n    np.divide(ret, rcount, out=ret, casting=\"unsafe\")\n    return ret[()]\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.std","title":"<code>std(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the standard deviation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the standard deviation. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.std : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.std</code> to compute the standard deviation of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.std(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.8291562, 0.4330127])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the standard deviation.</p> <pre><code>&gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the standard deviation along all axes.</p> <pre><code>&gt;&gt;&gt; s.std()\n0.7071067811865476\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the standard deviation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the standard deviation. Uses\n        all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.std : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.std` to compute the standard deviation of an array\n    across any dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.std(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.8291562, 0.4330127])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the standard deviation.\n\n    &gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    standard deviation along all axes.\n\n    &gt;&gt;&gt; s.std()  # doctest: +SKIP\n    0.7071067811865476\n    \"\"\"\n    ret = self.var(axis=axis, dtype=dtype, out=out, ddof=ddof, keepdims=keepdims)\n\n    return np.sqrt(ret)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.conj","title":"<code>conj()</code>","text":"<p>Return the complex conjugate, element-wise.</p> <p>The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n&gt;&gt;&gt; res = x.conj()\n&gt;&gt;&gt; res.todense()\narray([1.-2.j, 2.+1.j])\n&gt;&gt;&gt; res.dtype\ndtype('complex128')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The complex conjugate, with same dtype as the input.</p> See Also <p>numpy.ndarray.conj : NumPy equivalent method. numpy.conj : NumPy equivalent function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def conj(self):\n    \"\"\"Return the complex conjugate, element-wise.\n\n    The complex conjugate of a complex number is obtained by changing the\n    sign of its imaginary part.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n    &gt;&gt;&gt; res = x.conj()\n    &gt;&gt;&gt; res.todense()  # doctest: +SKIP\n    array([1.-2.j, 2.+1.j])\n    &gt;&gt;&gt; res.dtype\n    dtype('complex128')\n\n    Returns\n    -------\n    out : SparseArray\n        The complex conjugate, with same dtype as the input.\n\n    See Also\n    --------\n    numpy.ndarray.conj : NumPy equivalent method.\n    numpy.conj : NumPy equivalent function.\n    \"\"\"\n    return np.conj(self)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.isinf","title":"<code>isinf()</code>  <code>abstractmethod</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>@abstractmethod\ndef isinf(self):\n    \"\"\" \"\"\"\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.isnan","title":"<code>isnan()</code>  <code>abstractmethod</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>@abstractmethod\ndef isnan(self):\n    \"\"\" \"\"\"\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.from_scipy_sparse","title":"<code>from_scipy_sparse(x, /, *, fill_value=None)</code>  <code>classmethod</code>","text":"<p>Create a :obj:<code>DOK</code> array from a :obj:<code>scipy.sparse.spmatrix</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>spmatrix</code> <p>The matrix to convert.</p> required <code>fill_value</code> <code>scalar</code> <p>The fill-value to use when converting.</p> <code>None</code> <p>Returns:</p> Type Description <code>DOK</code> <p>The equivalent :obj:<code>DOK</code> array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = scipy.sparse.rand(6, 3, density=0.2)\n&gt;&gt;&gt; s = DOK.from_scipy_sparse(x)\n&gt;&gt;&gt; np.array_equal(x.todense(), s.todense())\nTrue\n</code></pre> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>@classmethod\ndef from_scipy_sparse(cls, x, /, *, fill_value=None):\n    \"\"\"\n    Create a :obj:`DOK` array from a :obj:`scipy.sparse.spmatrix`.\n\n    Parameters\n    ----------\n    x : scipy.sparse.spmatrix\n        The matrix to convert.\n    fill_value : scalar\n        The fill-value to use when converting.\n\n    Returns\n    -------\n    DOK\n        The equivalent :obj:`DOK` array.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = scipy.sparse.rand(6, 3, density=0.2)\n    &gt;&gt;&gt; s = DOK.from_scipy_sparse(x)\n    &gt;&gt;&gt; np.array_equal(x.todense(), s.todense())\n    True\n    \"\"\"\n    from sparse import COO\n\n    return COO.from_scipy_sparse(x, fill_value=fill_value).asformat(cls)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.from_coo","title":"<code>from_coo(x)</code>  <code>classmethod</code>","text":"<p>Get a :obj:<code>DOK</code> array from a :obj:<code>COO</code> array.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>COO</code> <p>The array to convert.</p> required <p>Returns:</p> Type Description <code>DOK</code> <p>The equivalent :obj:<code>DOK</code> array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; s = COO.from_numpy(np.eye(4))\n&gt;&gt;&gt; s2 = DOK.from_coo(s)\n&gt;&gt;&gt; s2\n&lt;DOK: shape=(4, 4), dtype=float64, nnz=4, fill_value=0.0&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>@classmethod\ndef from_coo(cls, x):\n    \"\"\"\n    Get a :obj:`DOK` array from a :obj:`COO` array.\n\n    Parameters\n    ----------\n    x : COO\n        The array to convert.\n\n    Returns\n    -------\n    DOK\n        The equivalent :obj:`DOK` array.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; s = COO.from_numpy(np.eye(4))\n    &gt;&gt;&gt; s2 = DOK.from_coo(s)\n    &gt;&gt;&gt; s2\n    &lt;DOK: shape=(4, 4), dtype=float64, nnz=4, fill_value=0.0&gt;\n    \"\"\"\n    ar = cls(x.shape, dtype=x.dtype, fill_value=x.fill_value)\n\n    for c, d in zip(x.coords.T, x.data, strict=True):\n        ar.data[tuple(c)] = d\n\n    return ar\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.to_coo","title":"<code>to_coo()</code>","text":"<p>Convert this :obj:<code>DOK</code> array to a :obj:<code>COO</code> array.</p> <p>Returns:</p> Type Description <code>COO</code> <p>The equivalent :obj:<code>COO</code> array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = DOK((5, 5))\n&gt;&gt;&gt; s[1:3, 1:3] = [[4, 5], [6, 7]]\n&gt;&gt;&gt; s\n&lt;DOK: shape=(5, 5), dtype=float64, nnz=4, fill_value=0.0&gt;\n&gt;&gt;&gt; s2 = s.to_coo()\n&gt;&gt;&gt; s2\n&lt;COO: shape=(5, 5), dtype=float64, nnz=4, fill_value=0.0&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>def to_coo(self):\n    \"\"\"\n    Convert this :obj:`DOK` array to a :obj:`COO` array.\n\n    Returns\n    -------\n    COO\n        The equivalent :obj:`COO` array.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = DOK((5, 5))\n    &gt;&gt;&gt; s[1:3, 1:3] = [[4, 5], [6, 7]]\n    &gt;&gt;&gt; s\n    &lt;DOK: shape=(5, 5), dtype=float64, nnz=4, fill_value=0.0&gt;\n    &gt;&gt;&gt; s2 = s.to_coo()\n    &gt;&gt;&gt; s2\n    &lt;COO: shape=(5, 5), dtype=float64, nnz=4, fill_value=0.0&gt;\n    \"\"\"\n    from ._coo import COO\n\n    return COO(self)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.from_numpy","title":"<code>from_numpy(x)</code>  <code>classmethod</code>","text":"<p>Get a :obj:<code>DOK</code> array from a Numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to convert.</p> required <p>Returns:</p> Type Description <code>DOK</code> <p>The equivalent :obj:<code>DOK</code> array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = DOK.from_numpy(np.eye(4))\n&gt;&gt;&gt; s\n&lt;DOK: shape=(4, 4), dtype=float64, nnz=4, fill_value=0.0&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>@classmethod\ndef from_numpy(cls, x):\n    \"\"\"\n    Get a :obj:`DOK` array from a Numpy array.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        The array to convert.\n\n    Returns\n    -------\n    DOK\n        The equivalent :obj:`DOK` array.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = DOK.from_numpy(np.eye(4))\n    &gt;&gt;&gt; s\n    &lt;DOK: shape=(4, 4), dtype=float64, nnz=4, fill_value=0.0&gt;\n    \"\"\"\n    ar = cls(x.shape, dtype=x.dtype)\n\n    coords = np.nonzero(x)\n    data = x[coords]\n\n    for c in zip(data, *coords, strict=True):\n        d, c = c[0], c[1:]\n        ar.data[c] = d\n\n    return ar\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.todense","title":"<code>todense()</code>","text":"<p>Convert this :obj:<code>DOK</code> array into a Numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The equivalent dense array.</p> See Also <p>COO.todense : Equivalent :obj:<code>COO</code> array method. scipy.sparse.dok_matrix.todense : Equivalent Scipy method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = DOK((5, 5))\n&gt;&gt;&gt; s[1:3, 1:3] = [[4, 5], [6, 7]]\n&gt;&gt;&gt; s.todense()\narray([[0., 0., 0., 0., 0.],\n       [0., 4., 5., 0., 0.],\n       [0., 6., 7., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n</code></pre> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>def todense(self):\n    \"\"\"\n    Convert this :obj:`DOK` array into a Numpy array.\n\n    Returns\n    -------\n    numpy.ndarray\n        The equivalent dense array.\n\n    See Also\n    --------\n    COO.todense : Equivalent :obj:`COO` array method.\n    scipy.sparse.dok_matrix.todense : Equivalent Scipy method.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = DOK((5, 5))\n    &gt;&gt;&gt; s[1:3, 1:3] = [[4, 5], [6, 7]]\n    &gt;&gt;&gt; s.todense()  # doctest: +SKIP\n    array([[0., 0., 0., 0., 0.],\n           [0., 4., 5., 0., 0.],\n           [0., 6., 7., 0., 0.],\n           [0., 0., 0., 0., 0.],\n           [0., 0., 0., 0., 0.]])\n    \"\"\"\n    result = np.full(self.shape, self.fill_value, self.dtype)\n\n    for c, d in self.data.items():\n        result[c] = d\n\n    return result\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.asformat","title":"<code>asformat(format, **kwargs)</code>","text":"<p>Convert this sparse array to a given format.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>A format string.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The converted array.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the format isn't supported.</p> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>def asformat(self, format, **kwargs):\n    \"\"\"\n    Convert this sparse array to a given format.\n\n    Parameters\n    ----------\n    format : str\n        A format string.\n\n    Returns\n    -------\n    out : SparseArray\n        The converted array.\n\n    Raises\n    ------\n    NotImplementedError\n        If the format isn't supported.\n    \"\"\"\n    from ._utils import convert_format\n\n    format = convert_format(format)\n\n    if format == \"dok\":\n        return self\n\n    if format == \"coo\":\n        from ._coo import COO\n\n        if len(kwargs) != 0:\n            raise ValueError(f\"Extra kwargs found: {kwargs}\")\n        return COO.from_iter(\n            self.data,\n            shape=self.shape,\n            fill_value=self.fill_value,\n            dtype=self.dtype,\n        )\n\n    return self.asformat(\"coo\").asformat(format, **kwargs)\n</code></pre>"},{"location":"api/DOK/#sparse.DOK.reshape","title":"<code>reshape(shape, order='C')</code>","text":"<p>Returns a new :obj:<code>DOK</code> array that is a reshaped version of this array.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>tuple[int]</code> <p>The desired shape of the output array.</p> required <p>Returns:</p> Type Description <code>DOK</code> <p>The reshaped output array.</p> See Also <p>numpy.ndarray.reshape : The equivalent Numpy function.</p> Notes <p>The :code:<code>order</code> parameter is provided just for compatibility with Numpy and isn't actually supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = DOK.from_numpy(np.arange(25))\n&gt;&gt;&gt; s2 = s.reshape((5, 5))\n&gt;&gt;&gt; s2.todense()\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24]])\n</code></pre> Source code in <code>sparse/numba_backend/_dok.py</code> <pre><code>def reshape(self, shape, order=\"C\"):\n    \"\"\"\n    Returns a new :obj:`DOK` array that is a reshaped version of this array.\n\n    Parameters\n    ----------\n    shape : tuple[int]\n        The desired shape of the output array.\n\n    Returns\n    -------\n    DOK\n        The reshaped output array.\n\n    See Also\n    --------\n    numpy.ndarray.reshape : The equivalent Numpy function.\n\n    Notes\n    -----\n    The :code:`order` parameter is provided just for compatibility with\n    Numpy and isn't actually supported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = DOK.from_numpy(np.arange(25))\n    &gt;&gt;&gt; s2 = s.reshape((5, 5))\n    &gt;&gt;&gt; s2.todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[ 0,  1,  2,  3,  4],\n           [ 5,  6,  7,  8,  9],\n           [10, 11, 12, 13, 14],\n           [15, 16, 17, 18, 19],\n           [20, 21, 22, 23, 24]])\n    \"\"\"\n    if order not in {\"C\", None}:\n        raise NotImplementedError(\"The 'order' parameter is not supported\")\n\n    return DOK.from_coo(self.to_coo().reshape(shape))\n</code></pre>"},{"location":"api/GCXS/","title":"GCXS","text":"<p>               Bases: <code>SparseArray</code>, <code>NDArrayOperatorsMixin</code></p> <p>A sparse multidimensional array.</p> <p>This is stored in GCXS format, a generalization of the GCRS/GCCS formats from 'Efficient storage scheme for n-dimensional sparse array: GCRS/GCCS': https://ieeexplore.ieee.org/document/7237032. GCXS generalizes the CRS/CCS sparse matrix formats.</p> <p>For arrays with ndim == 2, GCXS is the same CSR/CSC. For arrays with ndim &gt;2, any combination of axes can be compressed, significantly reducing storage.</p> <p>GCXS consists of 3 arrays. Let the 3 arrays be RO, CO and VL. The first element of array RO is the integer 0 and later elements are the number of cumulative non-zero elements in each row for GCRS, column for GCCS. CO stores column indexes of non-zero elements at each row for GCRS, column for GCCS. VL stores the values of the non-zero array elements.</p> <p>The superiority of the GCRS/GCCS over traditional (CRS/CCS) is shown by both theoretical analysis and experimental results, outlined in the linked research paper.</p> <p>Parameters:</p> Name Type Description Default <code>arg</code> <code>tuple(data, indices, indptr)</code> <p>A tuple of arrays holding the data, indices, and index pointers for the nonzero values of the array.</p> required <code>shape</code> <code>tuple[int](ndim)</code> <p>The shape of the array.</p> <code>None</code> <code>compressed_axes</code> <code>Iterable[int]</code> <p>The axes to compress.</p> <code>None</code> <code>prune</code> <code>bool_</code> <p>A flag indicating whether or not we should prune any fill-values present in the data array.</p> <code>False</code> <code>fill_value</code> <p>The fill value for this array.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>ndarray(nnz)</code> <p>An array holding the nonzero values corresponding to :obj:<code>GCXS.indices</code>.</p> <code>indices</code> <code>ndarray(nnz)</code> <p>An array holding the coordinates of every nonzero element along uncompressed dimensions.</p> <code>indptr</code> <code>ndarray</code> <p>An array holding the cumulative sums of the nonzeros along the compressed dimensions.</p> <code>shape</code> <code>tuple[int](ndim)</code> <p>The dimensions of this array.</p> See Also <p>DOK : A mostly write-only sparse array.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>class GCXS(SparseArray, NDArrayOperatorsMixin):\n    \"\"\"\n    A sparse multidimensional array.\n\n    This is stored in GCXS format, a generalization of the GCRS/GCCS formats\n    from 'Efficient storage scheme for n-dimensional sparse array: GCRS/GCCS':\n    https://ieeexplore.ieee.org/document/7237032. GCXS generalizes the CRS/CCS\n    sparse matrix formats.\n\n    For arrays with ndim == 2, GCXS is the same CSR/CSC.\n    For arrays with ndim &gt;2, any combination of axes can be compressed,\n    significantly reducing storage.\n\n    GCXS consists of 3 arrays. Let the 3 arrays be RO, CO and VL. The first element\n    of array RO is the integer 0 and later elements are the number of\n    cumulative non-zero elements in each row for GCRS, column for\n    GCCS. CO stores column indexes of non-zero elements at each row for GCRS, column for GCCS.\n    VL stores the values of the non-zero array elements.\n\n    The superiority of the GCRS/GCCS over traditional (CRS/CCS) is shown by both\n    theoretical analysis and experimental results, outlined in the linked research paper.\n\n    Parameters\n    ----------\n    arg : tuple (data, indices, indptr)\n        A tuple of arrays holding the data, indices, and\n        index pointers for the nonzero values of the array.\n    shape : tuple[int] (COO.ndim,)\n        The shape of the array.\n    compressed_axes : Iterable[int]\n        The axes to compress.\n    prune : bool, optional\n        A flag indicating whether or not we should prune any fill-values present in\n        the data array.\n    fill_value: scalar, optional\n        The fill value for this array.\n\n    Attributes\n    ----------\n    data : numpy.ndarray (nnz,)\n        An array holding the nonzero values corresponding to :obj:`GCXS.indices`.\n    indices : numpy.ndarray (nnz,)\n        An array holding the coordinates of every nonzero element along uncompressed dimensions.\n    indptr : numpy.ndarray\n        An array holding the cumulative sums of the nonzeros along the compressed dimensions.\n    shape : tuple[int] (ndim,)\n        The dimensions of this array.\n\n    See Also\n    --------\n    DOK : A mostly write-only sparse array.\n    \"\"\"\n\n    __array_priority__ = 12\n\n    def __init__(\n        self,\n        arg,\n        shape=None,\n        compressed_axes=None,\n        prune=False,\n        fill_value=None,\n        idx_dtype=None,\n    ):\n        from .._common import _is_scipy_sparse_obj\n\n        if _is_scipy_sparse_obj(arg):\n            arg = self.from_scipy_sparse(arg)\n\n        if isinstance(arg, np.ndarray):\n            (arg, shape, compressed_axes, fill_value) = _from_coo(COO(arg), compressed_axes)\n\n        elif isinstance(arg, COO):\n            (arg, shape, compressed_axes, fill_value) = _from_coo(arg, compressed_axes, idx_dtype)\n\n        elif isinstance(arg, GCXS):\n            if compressed_axes is not None and arg.compressed_axes != compressed_axes:\n                arg = arg.change_compressed_axes(compressed_axes)\n            (arg, shape, compressed_axes, fill_value) = (\n                (arg.data, arg.indices, arg.indptr),\n                arg.shape,\n                arg.compressed_axes,\n                arg.fill_value,\n            )\n\n        if shape is None:\n            raise ValueError(\"missing `shape` argument\")\n\n        check_compressed_axes(len(shape), compressed_axes)\n\n        if len(shape) == 1:\n            compressed_axes = None\n\n        self.data, self.indices, self.indptr = arg\n\n        if self.data.ndim != 1:\n            raise ValueError(\"data must be a scalar or 1-dimensional.\")\n\n        self.shape = shape\n\n        if fill_value is None:\n            fill_value = _zero_of_dtype(self.data.dtype)\n\n        self._compressed_axes = tuple(compressed_axes) if isinstance(compressed_axes, Iterable) else None\n        self.fill_value = self.data.dtype.type(fill_value)\n\n        if prune:\n            self._prune()\n\n    def copy(self, deep=True):\n        \"\"\"Return a copy of the array.\n\n        Parameters\n        ----------\n        deep : boolean, optional\n            If True (default), the internal coords and data arrays are also\n            copied. Set to ``False`` to only make a shallow copy.\n        \"\"\"\n        return _copy.deepcopy(self) if deep else _copy.copy(self)\n\n    @classmethod\n    def from_numpy(cls, x, compressed_axes=None, fill_value=None, idx_dtype=None):\n        coo = COO.from_numpy(x, fill_value=fill_value, idx_dtype=idx_dtype)\n        return cls.from_coo(coo, compressed_axes, idx_dtype)\n\n    @classmethod\n    def from_coo(cls, x, compressed_axes=None, idx_dtype=None):\n        (arg, shape, compressed_axes, fill_value) = _from_coo(x, compressed_axes, idx_dtype)\n        return cls(arg, shape=shape, compressed_axes=compressed_axes, fill_value=fill_value)\n\n    @classmethod\n    def from_scipy_sparse(cls, x, /, *, fill_value=None):\n        if x.format == \"csc\":\n            return cls((x.data, x.indices, x.indptr), shape=x.shape, compressed_axes=(1,), fill_value=fill_value)\n\n        x = x.asformat(\"csr\")\n        return cls((x.data, x.indices, x.indptr), shape=x.shape, compressed_axes=(0,), fill_value=fill_value)\n\n    @classmethod\n    def from_iter(cls, x, shape=None, compressed_axes=None, fill_value=None, idx_dtype=None):\n        return cls.from_coo(\n            COO.from_iter(x, shape, fill_value),\n            compressed_axes,\n            idx_dtype,\n        )\n\n    @property\n    def dtype(self):\n        \"\"\"\n        The datatype of this array.\n\n        Returns\n        -------\n        numpy.dtype\n            The datatype of this array.\n\n        See Also\n        --------\n        numpy.ndarray.dtype : Numpy equivalent property.\n        scipy.sparse.csr_matrix.dtype : Scipy equivalent property.\n        \"\"\"\n        return self.data.dtype\n\n    @property\n    def nnz(self):\n        \"\"\"\n        The number of nonzero elements in this array.\n\n        Returns\n        -------\n        int\n            The number of nonzero elements in this array.\n\n        See Also\n        --------\n        COO.nnz : Equivalent :obj:`COO` array property.\n        DOK.nnz : Equivalent :obj:`DOK` array property.\n        numpy.count_nonzero : A similar Numpy function.\n        scipy.sparse.csr_matrix.nnz : The Scipy equivalent property.\n        \"\"\"\n        return self.data.shape[0]\n\n    @property\n    def format(self):\n        \"\"\"\n        The storage format of this array.\n        Returns\n        -------\n        str\n            The storage format of this array.\n        See Also\n        -------\n        scipy.sparse.dok_matrix.format : The Scipy equivalent property.\n        Examples\n        -------\n        &gt;&gt;&gt; import sparse\n        &gt;&gt;&gt; s = sparse.random((5, 5), density=0.2, format=\"dok\")\n        &gt;&gt;&gt; s.format\n        'dok'\n        &gt;&gt;&gt; t = sparse.random((5, 5), density=0.2, format=\"coo\")\n        &gt;&gt;&gt; t.format\n        'coo'\n        \"\"\"\n        return \"gcxs\"\n\n    @property\n    def nbytes(self):\n        \"\"\"\n        The number of bytes taken up by this object. Note that for small arrays,\n        this may undercount the number of bytes due to the large constant overhead.\n\n        Returns\n        -------\n        int\n            The approximate bytes of memory taken by this object.\n\n        See Also\n        --------\n        numpy.ndarray.nbytes : The equivalent Numpy property.\n        \"\"\"\n        return self.data.nbytes + self.indices.nbytes + self.indptr.nbytes\n\n    @property\n    def _axis_order(self):\n        axis_order = list(self.compressed_axes)\n        axis_order.extend(np.setdiff1d(np.arange(len(self.shape)), self.compressed_axes))\n        return axis_order\n\n    @property\n    def _axisptr(self):\n        # array location where the uncompressed dimensions start\n        return len(self.compressed_axes)\n\n    @property\n    def _compressed_shape(self):\n        row_size = np.prod(self._reordered_shape[: self._axisptr])\n        col_size = np.prod(self._reordered_shape[self._axisptr :])\n        return (row_size, col_size)\n\n    @property\n    def _reordered_shape(self):\n        return tuple(self.shape[i] for i in self._axis_order)\n\n    @property\n    def T(self):\n        return self.transpose()\n\n    @property\n    def mT(self):\n        if self.ndim &lt; 2:\n            raise ValueError(\"Cannot compute matrix transpose if `ndim &lt; 2`.\")\n\n        axis = list(range(self.ndim))\n        axis[-1], axis[-2] = axis[-2], axis[-1]\n\n        return self.transpose(axis)\n\n    def __str__(self):\n        summary = (\n            f\"&lt;GCXS: shape={self.shape}, dtype={self.dtype}, nnz={self.nnz}, fill_value={self.fill_value}, \"\n            f\"compressed_axes={self.compressed_axes}&gt;\"\n        )\n        return self._str_impl(summary)\n\n    __repr__ = __str__\n\n    __getitem__ = getitem\n\n    def _reduce_calc(self, method, axis, keepdims=False, **kwargs):\n        if axis[0] is None or np.array_equal(axis, np.arange(self.ndim, dtype=np.intp)):\n            x = self.flatten().tocoo()\n            out = x.reduce(method, axis=None, keepdims=keepdims, **kwargs)\n            if keepdims:\n                return (out.reshape(np.ones(self.ndim, dtype=np.intp)),)\n            return (out,)\n\n        r = np.arange(self.ndim, dtype=np.intp)\n        compressed_axes = [a for a in r if a not in set(axis)]\n        x = self.change_compressed_axes(compressed_axes)\n        idx = np.diff(x.indptr) != 0\n        indptr = x.indptr[:-1][idx]\n        indices = (np.arange(x._compressed_shape[0], dtype=self.indptr.dtype))[idx]\n        data = method.reduceat(x.data, indptr, **kwargs)\n        counts = x.indptr[1:][idx] - x.indptr[:-1][idx]\n        arr_attrs = (x, compressed_axes, indices)\n        n_cols = x._compressed_shape[1]\n        return (data, counts, axis, n_cols, arr_attrs)\n\n    def _reduce_return(self, data, arr_attrs, result_fill_value):\n        x, compressed_axes, indices = arr_attrs\n        # prune data\n        mask = ~equivalent(data, result_fill_value)\n        data = data[mask]\n        indices = indices[mask]\n        out = GCXS(\n            (data, indices, []),\n            shape=(x._compressed_shape[0],),\n            fill_value=result_fill_value,\n            compressed_axes=None,\n        )\n        return out.reshape(tuple(self.shape[d] for d in compressed_axes))\n\n    def change_compressed_axes(self, new_compressed_axes):\n        \"\"\"\n        Returns a new array with specified compressed axes. This operation is similar to converting\n        a scipy.sparse.csc_matrix to a scipy.sparse.csr_matrix.\n\n        Returns\n        -------\n        GCXS\n            A new instance of the input array with compression along the specified dimensions.\n        \"\"\"\n        if new_compressed_axes == self.compressed_axes:\n            return self\n\n        if self.ndim == 1:\n            raise NotImplementedError(\"no axes to compress for 1d array\")\n\n        new_compressed_axes = tuple(\n            normalize_axis(new_compressed_axes[i], self.ndim) for i in range(len(new_compressed_axes))\n        )\n\n        if new_compressed_axes == self.compressed_axes:\n            return self\n\n        if len(new_compressed_axes) &gt;= len(self.shape):\n            raise ValueError(\"cannot compress all axes\")\n        if len(set(new_compressed_axes)) != len(new_compressed_axes):\n            raise ValueError(\"repeated axis in compressed_axes\")\n\n        arg = _transpose(self, self.shape, np.arange(self.ndim), new_compressed_axes)\n\n        return GCXS(\n            arg,\n            shape=self.shape,\n            compressed_axes=new_compressed_axes,\n            fill_value=self.fill_value,\n        )\n\n    def tocoo(self):\n        \"\"\"\n        Convert this :obj:`GCXS` array to a :obj:`COO`.\n\n        Returns\n        -------\n        sparse.COO\n            The converted COO array.\n        \"\"\"\n        if self.ndim == 0:\n            return COO(\n                np.array([]),\n                self.data,\n                shape=self.shape,\n                fill_value=self.fill_value,\n            )\n        if self.ndim == 1:\n            return COO(\n                self.indices[None, :],\n                self.data,\n                shape=self.shape,\n                fill_value=self.fill_value,\n            )\n        uncompressed = uncompress_dimension(self.indptr)\n        coords = np.vstack((uncompressed, self.indices))\n        order = np.argsort(self._axis_order)\n        return (\n            COO(\n                coords,\n                self.data,\n                shape=self._compressed_shape,\n                fill_value=self.fill_value,\n            )\n            .reshape(self._reordered_shape)\n            .transpose(order)\n        )\n\n    def todense(self):\n        \"\"\"\n        Convert this :obj:`GCXS` array to a dense :obj:`numpy.ndarray`. Note that\n        this may take a large amount of memory if the :obj:`GCXS` object's :code:`shape`\n        is large.\n\n        Returns\n        -------\n        numpy.ndarray\n            The converted dense array.\n\n        See Also\n        --------\n        DOK.todense : Equivalent :obj:`DOK` array method.\n        COO.todense : Equivalent :obj:`COO` array method.\n        scipy.sparse.coo_matrix.todense : Equivalent Scipy method.\n        \"\"\"\n        if self.compressed_axes is None:\n            out = np.full(self.shape, self.fill_value, self.dtype)\n            if len(self.indices) != 0:\n                out[self.indices] = self.data\n            else:\n                if len(self.data) != 0:\n                    out[()] = self.data[0]\n            return out\n        return self.tocoo().todense()\n\n    def todok(self):\n        from .. import DOK\n\n        return DOK.from_coo(self.tocoo())  # probably a temporary solution\n\n    def to_scipy_sparse(self, accept_fv=None):\n        \"\"\"\n        Converts this :obj:`GCXS` object into a :obj:`scipy.sparse.csr_matrix` or `scipy.sparse.csc_matrix`.\n\n        Parameters\n        ----------\n        accept_fv : scalar or list of scalar, optional\n            The list of accepted fill-values. The default accepts only zero.\n\n        Returns\n        -------\n        :obj:`scipy.sparse.csr_matrix` or `scipy.sparse.csc_matrix`\n            The converted Scipy sparse matrix.\n\n        Raises\n        ------\n        ValueError\n            If the array is not two-dimensional.\n        ValueError\n            If all the array doesn't zero fill-values.\n        \"\"\"\n        import scipy.sparse\n\n        check_fill_value(self, accept_fv=accept_fv)\n        if self.ndim != 2:\n            raise ValueError(\"Can only convert a 2-dimensional array to a Scipy sparse matrix.\")\n\n        if 0 in self.compressed_axes:\n            return scipy.sparse.csr_matrix((self.data, self.indices, self.indptr), shape=self.shape)\n\n        return scipy.sparse.csc_matrix((self.data, self.indices, self.indptr), shape=self.shape)\n\n    def asformat(self, format, **kwargs):\n        \"\"\"\n        Convert this sparse array to a given format.\n        Parameters\n        ----------\n        format : str\n            A format string.\n\n        Returns\n        -------\n        out : SparseArray\n            The converted array.\n\n        Raises\n        ------\n        NotImplementedError\n            If the format isn't supported.\n        \"\"\"\n        from .._utils import convert_format\n\n        format = convert_format(format)\n        ret = None\n\n        if format == \"coo\":\n            ret = self.tocoo()\n        elif format == \"dok\":\n            ret = self.todok()\n        elif format == \"csr\":\n            ret = CSR(self)\n        elif format == \"csc\":\n            ret = CSC(self)\n        elif format == \"gcxs\":\n            compressed_axes = kwargs.pop(\"compressed_axes\", self.compressed_axes)\n            return self.change_compressed_axes(compressed_axes)\n\n        if len(kwargs) != 0:\n            raise TypeError(f\"Invalid keyword arguments provided: {kwargs}\")\n\n        if ret is None:\n            raise NotImplementedError(f\"The given format is not supported: {format}\")\n\n        return ret\n\n    def maybe_densify(self, max_size=1000, min_density=0.25):\n        \"\"\"\n        Converts this :obj:`GCXS` array to a :obj:`numpy.ndarray` if not too\n        costly.\n        Parameters\n        ----------\n        max_size : int\n            Maximum number of elements in output\n        min_density : float\n            Minimum density of output\n        Returns\n        -------\n        numpy.ndarray\n            The dense array.\n        See Also\n        --------\n        sparse.GCXS.todense: Converts to Numpy function without checking the cost.\n        sparse.COO.maybe_densify: The equivalent COO function.\n        Raises\n        -------\n        ValueError\n            If the returned array would be too large.\n        \"\"\"\n\n        if self.size &gt; max_size and self.density &lt; min_density:\n            raise ValueError(\"Operation would require converting large sparse array to dense\")\n\n        return self.todense()\n\n    def flatten(self, order=\"C\"):\n        \"\"\"\n        Returns a new :obj:`GCXS` array that is a flattened version of this array.\n\n        Returns\n        -------\n        GCXS\n            The flattened output array.\n\n        Notes\n        -----\n        The :code:`order` parameter is provided just for compatibility with\n        Numpy and isn't actually supported.\n        \"\"\"\n        if order not in {\"C\", None}:\n            raise NotImplementedError(\"The `order` parameter is not supported.\")\n\n        return self.reshape(-1)\n\n    def reshape(self, shape, order=\"C\", compressed_axes=None):\n        \"\"\"\n        Returns a new :obj:`GCXS` array that is a reshaped version of this array.\n\n        Parameters\n        ----------\n        shape : tuple[int]\n            The desired shape of the output array.\n        compressed_axes : Iterable[int], optional\n            The axes to compress to store the array. Finds the most efficient storage\n            by default.\n\n        Returns\n        -------\n        GCXS\n            The reshaped output array.\n\n        See Also\n        --------\n        numpy.ndarray.reshape : The equivalent Numpy function.\n        sparse.COO.reshape : The equivalent COO function.\n\n        Notes\n        -----\n        The :code:`order` parameter is provided just for compatibility with\n        Numpy and isn't actually supported.\n\n        \"\"\"\n        shape = tuple(shape) if isinstance(shape, Iterable) else (shape,)\n        if order not in {\"C\", None}:\n            raise NotImplementedError(\"The 'order' parameter is not supported\")\n        if any(d == -1 for d in shape):\n            extra = int(self.size / np.prod([d for d in shape if d != -1]))\n            shape = tuple([d if d != -1 else extra for d in shape])\n\n        if self.shape == shape:\n            return self\n\n        if self.size != reduce(operator.mul, shape, 1):\n            raise ValueError(f\"cannot reshape array of size {self.size} into shape {shape}\")\n        if len(shape) == 0:\n            return self.tocoo().reshape(shape).asformat(\"gcxs\")\n\n        if compressed_axes is None:\n            if len(shape) == self.ndim:\n                compressed_axes = self.compressed_axes\n            elif len(shape) == 1:\n                compressed_axes = None\n            else:\n                compressed_axes = (np.argmin(shape),)\n\n        if self.ndim == 1:\n            arg = _1d_reshape(self, shape, compressed_axes)\n        else:\n            arg = _transpose(self, shape, np.arange(self.ndim), compressed_axes)\n        return GCXS(\n            arg,\n            shape=tuple(shape),\n            compressed_axes=compressed_axes,\n            fill_value=self.fill_value,\n        )\n\n    @property\n    def compressed_axes(self):\n        return self._compressed_axes\n\n    def transpose(self, axes=None, compressed_axes=None):\n        \"\"\"\n        Returns a new array which has the order of the axes switched.\n\n        Parameters\n        ----------\n        axes : Iterable[int], optional\n            The new order of the axes compared to the previous one. Reverses the axes\n            by default.\n        compressed_axes : Iterable[int], optional\n            The axes to compress to store the array. Finds the most efficient storage\n            by default.\n\n        Returns\n        -------\n        GCXS\n            The new array with the axes in the desired order.\n\n        See Also\n        --------\n        :obj:`GCXS.T` : A quick property to reverse the order of the axes.\n        numpy.ndarray.transpose : Numpy equivalent function.\n        \"\"\"\n        if axes is None:\n            axes = list(reversed(range(self.ndim)))\n\n        # Normalize all axes indices to positive values\n        axes = normalize_axis(axes, self.ndim)\n\n        if len(np.unique(axes)) &lt; len(axes):\n            raise ValueError(\"repeated axis in transpose\")\n\n        if not len(axes) == self.ndim:\n            raise ValueError(\"axes don't match array\")\n\n        axes = tuple(axes)\n\n        if axes == tuple(range(self.ndim)):\n            return self\n\n        if self.ndim == 2:\n            return self._2d_transpose()\n\n        shape = tuple(self.shape[ax] for ax in axes)\n\n        if compressed_axes is None:\n            compressed_axes = (np.argmin(shape),)\n        arg = _transpose(self, shape, axes, compressed_axes, transpose=True)\n        return GCXS(\n            arg,\n            shape=shape,\n            compressed_axes=compressed_axes,\n            fill_value=self.fill_value,\n        )\n\n    def _2d_transpose(self):\n        \"\"\"\n        A function for performing constant-time transposes on 2d GCXS arrays.\n\n        Returns\n        -------\n        GCXS\n            The new transposed array with the opposite compressed axes as the input.\n\n        See Also\n        --------\n        scipy.sparse.csr_matrix.transpose : Scipy equivalent function.\n        scipy.sparse.csc_matrix.transpose : Scipy equivalent function.\n        numpy.ndarray.transpose : Numpy equivalent function.\n        \"\"\"\n        if self.ndim != 2:\n            raise ValueError(f\"cannot perform 2d transpose on array with dimension {self.ndim}\")\n\n        compressed_axes = [(self.compressed_axes[0] + 1) % 2]\n        shape = self.shape[::-1]\n        return GCXS(\n            (self.data, self.indices, self.indptr),\n            shape=shape,\n            compressed_axes=compressed_axes,\n            fill_value=self.fill_value,\n        )\n\n    def dot(self, other):\n        \"\"\"\n        Performs the equivalent of :code:`x.dot(y)` for :obj:`GCXS`.\n\n        Parameters\n        ----------\n        other : Union[GCXS, COO, numpy.ndarray, scipy.sparse.spmatrix]\n            The second operand of the dot product operation.\n\n        Returns\n        -------\n        {GCXS, numpy.ndarray}\n            The result of the dot product. If the result turns out to be dense,\n            then a dense array is returned, otherwise, a sparse array.\n\n        Raises\n        ------\n        ValueError\n            If all arguments don't have zero fill-values.\n\n        See Also\n        --------\n        dot : Equivalent function for two arguments.\n        :obj:`numpy.dot` : Numpy equivalent function.\n        scipy.sparse.csr_matrix.dot : Scipy equivalent function.\n        \"\"\"\n        from .._common import dot\n\n        return dot(self, other)\n\n    def __matmul__(self, other):\n        from .._common import matmul\n\n        try:\n            return matmul(self, other)\n        except NotImplementedError:\n            return NotImplemented\n\n    def __rmatmul__(self, other):\n        from .._common import matmul\n\n        try:\n            return matmul(other, self)\n        except NotImplementedError:\n            return NotImplemented\n\n    def _prune(self):\n        \"\"\"\n        Prunes data so that if any fill-values are present, they are removed\n        from both indices and data.\n\n        Examples\n        --------\n        &gt;&gt;&gt; coords = np.array([[0, 1, 2, 3]])\n        &gt;&gt;&gt; data = np.array([1, 0, 1, 2])\n        &gt;&gt;&gt; s = COO(coords, data).asformat(\"gcxs\")\n        &gt;&gt;&gt; s._prune()\n        &gt;&gt;&gt; s.nnz\n        3\n        \"\"\"\n        mask = ~equivalent(self.data, self.fill_value)\n        self.data = self.data[mask]\n        if len(self.indptr):\n            coords = np.stack((uncompress_dimension(self.indptr), self.indices))\n            coords = coords[:, mask]\n            self.indices = coords[1]\n            row_size = self._compressed_shape[0]\n            indptr = np.empty(row_size + 1, dtype=self.indptr.dtype)\n            indptr[0] = 0\n            np.cumsum(np.bincount(coords[0], minlength=row_size), out=indptr[1:])\n            self.indptr = indptr\n        else:\n            self.indices = self.indices[mask]\n\n    def isinf(self):\n        return self.tocoo().isinf().asformat(\"gcxs\", compressed_axes=self.compressed_axes)\n\n    def isnan(self):\n        return self.tocoo().isnan().asformat(\"gcxs\", compressed_axes=self.compressed_axes)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.device","title":"<code>device</code>  <code>property</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>The number of dimensions of this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of dimensions of this array.</p> See Also <pre><code>[DOK.ndim][sparse.DOK.ndim] : Equivalent property for [DOK][sparse.DOK] arrays.\n[numpy.ndarray.ndim][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.random.rand(1, 2, 3, 1, 2)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.ndim\n5\n&gt;&gt;&gt; s.ndim == x.ndim\nTrue\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.size","title":"<code>size</code>  <code>property</code>","text":"<p>The number of all elements (including zeros) in this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of elements.</p> See Also <pre><code>[numpy.ndarray.size][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.zeros((10, 10))\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.size\n100\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.density","title":"<code>density</code>  <code>property</code>","text":"<p>The ratio of nonzero to all elements in this array.</p> <p>Returns:</p> Type Description <code>float</code> <p>The ratio of nonzero to all elements.</p> See Also <pre><code>COO.size : Number of elements.\nCOO.nnz : Number of nonzero elements.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.zeros((8, 8))\n&gt;&gt;&gt; x[0, :] = 1\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.density\n0.125\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.amax","title":"<code>amax = max</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.amin","title":"<code>amin = min</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.round_","title":"<code>round_ = round</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.real","title":"<code>real</code>  <code>property</code>","text":"<p>The real part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.real.todense()\narray([1., 0.])\n&gt;&gt;&gt; x.real.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The real component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.real : NumPy equivalent attribute. numpy.real : NumPy equivalent function.</p>"},{"location":"api/GCXS/#sparse.GCXS.imag","title":"<code>imag</code>  <code>property</code>","text":"<p>The imaginary part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.imag.todense()\narray([0., 1.])\n&gt;&gt;&gt; x.imag.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The imaginary component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.imag : NumPy equivalent attribute. numpy.imag : NumPy equivalent function.</p>"},{"location":"api/GCXS/#sparse.GCXS.shape","title":"<code>shape = shape</code>  <code>instance-attribute</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.fill_value","title":"<code>fill_value = self.data.dtype.type(fill_value)</code>  <code>instance-attribute</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.dtype","title":"<code>dtype</code>  <code>property</code>","text":"<p>The datatype of this array.</p> <p>Returns:</p> Type Description <code>dtype</code> <p>The datatype of this array.</p> See Also <p>numpy.ndarray.dtype : Numpy equivalent property. scipy.sparse.csr_matrix.dtype : Scipy equivalent property.</p>"},{"location":"api/GCXS/#sparse.GCXS.nnz","title":"<code>nnz</code>  <code>property</code>","text":"<p>The number of nonzero elements in this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of nonzero elements in this array.</p> See Also <p>COO.nnz : Equivalent :obj:<code>COO</code> array property. DOK.nnz : Equivalent :obj:<code>DOK</code> array property. numpy.count_nonzero : A similar Numpy function. scipy.sparse.csr_matrix.nnz : The Scipy equivalent property.</p>"},{"location":"api/GCXS/#sparse.GCXS.format","title":"<code>format</code>  <code>property</code>","text":"<p>The storage format of this array.</p> <p>Returns:</p> Type Description <code>str</code> <p>The storage format of this array.</p> See Also <p>scipy.sparse.dok_matrix.format : The Scipy equivalent property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; s = sparse.random((5, 5), density=0.2, format=\"dok\")\n&gt;&gt;&gt; s.format\n'dok'\n&gt;&gt;&gt; t = sparse.random((5, 5), density=0.2, format=\"coo\")\n&gt;&gt;&gt; t.format\n'coo'\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.nbytes","title":"<code>nbytes</code>  <code>property</code>","text":"<p>The number of bytes taken up by this object. Note that for small arrays, this may undercount the number of bytes due to the large constant overhead.</p> <p>Returns:</p> Type Description <code>int</code> <p>The approximate bytes of memory taken by this object.</p> See Also <p>numpy.ndarray.nbytes : The equivalent Numpy property.</p>"},{"location":"api/GCXS/#sparse.GCXS.T","title":"<code>T</code>  <code>property</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.mT","title":"<code>mT</code>  <code>property</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.compressed_axes","title":"<code>compressed_axes</code>  <code>property</code>","text":""},{"location":"api/GCXS/#sparse.GCXS.to_device","title":"<code>to_device(device, /, *, stream=None)</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def to_device(self, device, /, *, stream=None):\n    if device != \"cpu\":\n        raise ValueError(\"Only `device='cpu'` is supported.\")\n\n    return self\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.reduce","title":"<code>reduce(method, axis=(0), keepdims=False, **kwargs)</code>","text":"<p>Performs a reduction operation on this array.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>ufunc</code> <p>The method to use for performing the reduction.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to perform the reduction. Uses all axes by default.</p> <code>(0)</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Any extra arguments to pass to the reduction operation.</p> <code>{}</code> See Also <p>numpy.ufunc.reduce : A similar Numpy method. COO.reduce : This method implemented on COO arrays. GCXS.reduce : This method implemented on GCXS arrays.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def reduce(self, method, axis=(0,), keepdims=False, **kwargs):\n    \"\"\"\n    Performs a reduction operation on this array.\n\n    Parameters\n    ----------\n    method : numpy.ufunc\n        The method to use for performing the reduction.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to perform the reduction. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    **kwargs : dict\n        Any extra arguments to pass to the reduction operation.\n\n    See Also\n    --------\n    numpy.ufunc.reduce : A similar Numpy method.\n    COO.reduce : This method implemented on COO arrays.\n    GCXS.reduce : This method implemented on GCXS arrays.\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n    zero_reduce_result = method.reduce([self.fill_value, self.fill_value], **kwargs)\n    reduce_super_ufunc = _reduce_super_ufunc.get(method)\n    if not equivalent(zero_reduce_result, self.fill_value) and reduce_super_ufunc is None:\n        raise ValueError(f\"Performing this reduction operation would produce a dense result: {method!s}\")\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n    out = self._reduce_calc(method, axis, keepdims, **kwargs)\n    if len(out) == 1:\n        return out[0]\n    data, counts, axis, n_cols, arr_attrs = out\n    result_fill_value = self.fill_value\n    if reduce_super_ufunc is None:\n        missing_counts = counts != n_cols\n        data[missing_counts] = method(data[missing_counts], self.fill_value, **kwargs)\n    else:\n        data = method(\n            data,\n            reduce_super_ufunc(self.fill_value, n_cols - counts),\n        ).astype(data.dtype)\n        result_fill_value = reduce_super_ufunc(self.fill_value, n_cols)\n\n    out = self._reduce_return(data, arr_attrs, result_fill_value)\n\n    if keepdims:\n        shape = list(self.shape)\n        for ax in axis:\n            shape[ax] = 1\n        out = out.reshape(shape)\n\n    if out.ndim == 0:\n        return out[()]\n\n    return out\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.sum","title":"<code>sum(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a sum operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to sum. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.sum</code> : Equivalent numpy function. scipy.sparse.coo_matrix.sum : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def sum(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a sum operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to sum. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.sum` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.sum : Equivalent Scipy function.\n    \"\"\"\n    return np.add.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.max","title":"<code>max(axis=None, keepdims=False, out=None)</code>","text":"<p>Maximize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to maximize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.max</code> : Equivalent numpy function. scipy.sparse.coo_matrix.max : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def max(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Maximize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to maximize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.max` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.max : Equivalent Scipy function.\n    \"\"\"\n    return np.maximum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.any","title":"<code>any(axis=None, keepdims=False, out=None)</code>","text":"<p>See if any values along array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.any</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def any(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if any values along array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.any` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_or.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.all","title":"<code>all(axis=None, keepdims=False, out=None)</code>","text":"<p>See if all values in an array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.all</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def all(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if all values in an array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.all` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_and.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.min","title":"<code>min(axis=None, keepdims=False, out=None)</code>","text":"<p>Minimize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.min</code> : Equivalent numpy function. scipy.sparse.coo_matrix.min : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def min(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Minimize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.min` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.min : Equivalent Scipy function.\n    \"\"\"\n    return np.minimum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.prod","title":"<code>prod(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a product operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to multiply. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.prod</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def prod(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a product operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to multiply. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.prod` : Equivalent numpy function.\n    \"\"\"\n    return np.multiply.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.round","title":"<code>round(decimals=0, out=None)</code>","text":"<p>Evenly round to the given number of decimals.</p> See Also <p>:obj:<code>numpy.round</code> :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def round(self, decimals=0, out=None):\n    \"\"\"\n    Evenly round to the given number of decimals.\n\n    See Also\n    --------\n    :obj:`numpy.round` :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.round, \"__call__\", self, decimals=decimals, out=out)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.clip","title":"<code>clip(min=None, max=None, out=None)</code>","text":"<p>Clip (limit) the values in the array.</p> <p>Return an array whose values are limited to <code>[min, max]</code>. One of min or max must be given.</p> See Also <p>sparse.clip : For full documentation and more details. numpy.clip : Equivalent NumPy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def clip(self, min=None, max=None, out=None):\n    \"\"\"\n    Clip (limit) the values in the array.\n\n    Return an array whose values are limited to ``[min, max]``. One of min\n    or max must be given.\n\n    See Also\n    --------\n    sparse.clip : For full documentation and more details.\n    numpy.clip : Equivalent NumPy function.\n    \"\"\"\n    if min is None and max is None:\n        raise ValueError(\"One of max or min must be given.\")\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.clip, \"__call__\", self, a_min=min, a_max=max, out=out)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.astype","title":"<code>astype(dtype, casting='unsafe', copy=True)</code>","text":"<p>Copy of the array, cast to a specified type.</p> See Also <p>scipy.sparse.coo_matrix.astype :     SciPy sparse equivalent function numpy.ndarray.astype :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def astype(self, dtype, casting=\"unsafe\", copy=True):\n    \"\"\"\n    Copy of the array, cast to a specified type.\n\n    See Also\n    --------\n    scipy.sparse.coo_matrix.astype :\n        SciPy sparse equivalent function\n    numpy.ndarray.astype :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    # this matches numpy's behavior\n    if self.dtype == dtype and not copy:\n        return self\n    return self.__array_ufunc__(np.ndarray.astype, \"__call__\", self, dtype=dtype, copy=copy, casting=casting)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.mean","title":"<code>mean(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Compute the mean along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the mean. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.mean : Equivalent numpy method. scipy.sparse.coo_matrix.mean : Equivalent Scipy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> <li>The :code:<code>out</code> parameter is provided just for compatibility with   Numpy and isn't actually supported.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.mean</code> to compute the mean of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.mean(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.5, 1.5, 0., 0.])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the mean.</p> <pre><code>&gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the mean along all axes.</p> <pre><code>&gt;&gt;&gt; s.mean()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def mean(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Compute the mean along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the mean. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.mean : Equivalent numpy method.\n    scipy.sparse.coo_matrix.mean : Equivalent Scipy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n    * The :code:`out` parameter is provided just for compatibility with\n      Numpy and isn't actually supported.\n\n    Examples\n    --------\n    You can use :obj:`COO.mean` to compute the mean of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.mean(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.5, 1.5, 0., 0.])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the mean.\n\n    &gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    mean along all axes.\n\n    &gt;&gt;&gt; s.mean()\n    0.5\n    \"\"\"\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n    elif not isinstance(axis, tuple):\n        axis = (axis,)\n    den = reduce(operator.mul, (self.shape[i] for i in axis), 1)\n\n    if dtype is None:\n        if issubclass(self.dtype.type, np.integer | np.bool_):\n            dtype = inter_dtype = np.dtype(\"f8\")\n        else:\n            dtype = self.dtype\n            inter_dtype = np.dtype(\"f4\") if issubclass(dtype.type, np.float16) else dtype\n    else:\n        inter_dtype = dtype\n\n    num = self.sum(axis=axis, keepdims=keepdims, dtype=inter_dtype)\n\n    if num.ndim:\n        out = np.true_divide(num, den, casting=\"unsafe\")\n        return out.astype(dtype) if out.dtype != dtype else out\n    return np.divide(num, den, dtype=dtype, out=out)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.var","title":"<code>var(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the variance along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the variance. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.var : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.var</code> to compute the variance of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.var(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.6875, 0.1875])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the variance.</p> <pre><code>&gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the variance along all axes.</p> <pre><code>&gt;&gt;&gt; s.var()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the variance along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the variance. Uses all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.var : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.var` to compute the variance of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.var(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.6875, 0.1875])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the variance.\n\n    &gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    variance along all axes.\n\n    &gt;&gt;&gt; s.var()\n    0.5\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n\n    rcount = reduce(operator.mul, (self.shape[a] for a in axis), 1)\n    # Make this warning show up on top.\n    if ddof &gt;= rcount:\n        warnings.warn(\"Degrees of freedom &lt;= 0 for slice\", RuntimeWarning, stacklevel=1)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None and issubclass(self.dtype.type, np.integer | np.bool_):\n        dtype = np.dtype(\"f8\")\n\n    arrmean = self.sum(axis, dtype=dtype, keepdims=True)[...]\n    np.divide(arrmean, rcount, out=arrmean)\n    x = self - arrmean\n    if issubclass(self.dtype.type, np.complexfloating):\n        x = x.real * x.real + x.imag * x.imag\n    else:\n        x = np.multiply(x, x, out=x)\n\n    ret = x.sum(axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n    # Compute degrees of freedom and make sure it is not negative.\n    rcount = max([rcount - ddof, 0])\n\n    ret = ret[...]\n    np.divide(ret, rcount, out=ret, casting=\"unsafe\")\n    return ret[()]\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.std","title":"<code>std(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the standard deviation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the standard deviation. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.std : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.std</code> to compute the standard deviation of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.std(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.8291562, 0.4330127])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the standard deviation.</p> <pre><code>&gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the standard deviation along all axes.</p> <pre><code>&gt;&gt;&gt; s.std()\n0.7071067811865476\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the standard deviation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the standard deviation. Uses\n        all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.std : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.std` to compute the standard deviation of an array\n    across any dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.std(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.8291562, 0.4330127])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the standard deviation.\n\n    &gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    standard deviation along all axes.\n\n    &gt;&gt;&gt; s.std()  # doctest: +SKIP\n    0.7071067811865476\n    \"\"\"\n    ret = self.var(axis=axis, dtype=dtype, out=out, ddof=ddof, keepdims=keepdims)\n\n    return np.sqrt(ret)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.conj","title":"<code>conj()</code>","text":"<p>Return the complex conjugate, element-wise.</p> <p>The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n&gt;&gt;&gt; res = x.conj()\n&gt;&gt;&gt; res.todense()\narray([1.-2.j, 2.+1.j])\n&gt;&gt;&gt; res.dtype\ndtype('complex128')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The complex conjugate, with same dtype as the input.</p> See Also <p>numpy.ndarray.conj : NumPy equivalent method. numpy.conj : NumPy equivalent function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def conj(self):\n    \"\"\"Return the complex conjugate, element-wise.\n\n    The complex conjugate of a complex number is obtained by changing the\n    sign of its imaginary part.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n    &gt;&gt;&gt; res = x.conj()\n    &gt;&gt;&gt; res.todense()  # doctest: +SKIP\n    array([1.-2.j, 2.+1.j])\n    &gt;&gt;&gt; res.dtype\n    dtype('complex128')\n\n    Returns\n    -------\n    out : SparseArray\n        The complex conjugate, with same dtype as the input.\n\n    See Also\n    --------\n    numpy.ndarray.conj : NumPy equivalent method.\n    numpy.conj : NumPy equivalent function.\n    \"\"\"\n    return np.conj(self)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.copy","title":"<code>copy(deep=True)</code>","text":"<p>Return a copy of the array.</p> <p>Parameters:</p> Name Type Description Default <code>deep</code> <code>boolean</code> <p>If True (default), the internal coords and data arrays are also copied. Set to <code>False</code> to only make a shallow copy.</p> <code>True</code> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def copy(self, deep=True):\n    \"\"\"Return a copy of the array.\n\n    Parameters\n    ----------\n    deep : boolean, optional\n        If True (default), the internal coords and data arrays are also\n        copied. Set to ``False`` to only make a shallow copy.\n    \"\"\"\n    return _copy.deepcopy(self) if deep else _copy.copy(self)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.from_numpy","title":"<code>from_numpy(x, compressed_axes=None, fill_value=None, idx_dtype=None)</code>  <code>classmethod</code>","text":"Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>@classmethod\ndef from_numpy(cls, x, compressed_axes=None, fill_value=None, idx_dtype=None):\n    coo = COO.from_numpy(x, fill_value=fill_value, idx_dtype=idx_dtype)\n    return cls.from_coo(coo, compressed_axes, idx_dtype)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.from_coo","title":"<code>from_coo(x, compressed_axes=None, idx_dtype=None)</code>  <code>classmethod</code>","text":"Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>@classmethod\ndef from_coo(cls, x, compressed_axes=None, idx_dtype=None):\n    (arg, shape, compressed_axes, fill_value) = _from_coo(x, compressed_axes, idx_dtype)\n    return cls(arg, shape=shape, compressed_axes=compressed_axes, fill_value=fill_value)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.from_scipy_sparse","title":"<code>from_scipy_sparse(x, /, *, fill_value=None)</code>  <code>classmethod</code>","text":"Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>@classmethod\ndef from_scipy_sparse(cls, x, /, *, fill_value=None):\n    if x.format == \"csc\":\n        return cls((x.data, x.indices, x.indptr), shape=x.shape, compressed_axes=(1,), fill_value=fill_value)\n\n    x = x.asformat(\"csr\")\n    return cls((x.data, x.indices, x.indptr), shape=x.shape, compressed_axes=(0,), fill_value=fill_value)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.from_iter","title":"<code>from_iter(x, shape=None, compressed_axes=None, fill_value=None, idx_dtype=None)</code>  <code>classmethod</code>","text":"Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>@classmethod\ndef from_iter(cls, x, shape=None, compressed_axes=None, fill_value=None, idx_dtype=None):\n    return cls.from_coo(\n        COO.from_iter(x, shape, fill_value),\n        compressed_axes,\n        idx_dtype,\n    )\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.change_compressed_axes","title":"<code>change_compressed_axes(new_compressed_axes)</code>","text":"<p>Returns a new array with specified compressed axes. This operation is similar to converting a scipy.sparse.csc_matrix to a scipy.sparse.csr_matrix.</p> <p>Returns:</p> Type Description <code>GCXS</code> <p>A new instance of the input array with compression along the specified dimensions.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def change_compressed_axes(self, new_compressed_axes):\n    \"\"\"\n    Returns a new array with specified compressed axes. This operation is similar to converting\n    a scipy.sparse.csc_matrix to a scipy.sparse.csr_matrix.\n\n    Returns\n    -------\n    GCXS\n        A new instance of the input array with compression along the specified dimensions.\n    \"\"\"\n    if new_compressed_axes == self.compressed_axes:\n        return self\n\n    if self.ndim == 1:\n        raise NotImplementedError(\"no axes to compress for 1d array\")\n\n    new_compressed_axes = tuple(\n        normalize_axis(new_compressed_axes[i], self.ndim) for i in range(len(new_compressed_axes))\n    )\n\n    if new_compressed_axes == self.compressed_axes:\n        return self\n\n    if len(new_compressed_axes) &gt;= len(self.shape):\n        raise ValueError(\"cannot compress all axes\")\n    if len(set(new_compressed_axes)) != len(new_compressed_axes):\n        raise ValueError(\"repeated axis in compressed_axes\")\n\n    arg = _transpose(self, self.shape, np.arange(self.ndim), new_compressed_axes)\n\n    return GCXS(\n        arg,\n        shape=self.shape,\n        compressed_axes=new_compressed_axes,\n        fill_value=self.fill_value,\n    )\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.tocoo","title":"<code>tocoo()</code>","text":"<p>Convert this :obj:<code>GCXS</code> array to a :obj:<code>COO</code>.</p> <p>Returns:</p> Type Description <code>COO</code> <p>The converted COO array.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def tocoo(self):\n    \"\"\"\n    Convert this :obj:`GCXS` array to a :obj:`COO`.\n\n    Returns\n    -------\n    sparse.COO\n        The converted COO array.\n    \"\"\"\n    if self.ndim == 0:\n        return COO(\n            np.array([]),\n            self.data,\n            shape=self.shape,\n            fill_value=self.fill_value,\n        )\n    if self.ndim == 1:\n        return COO(\n            self.indices[None, :],\n            self.data,\n            shape=self.shape,\n            fill_value=self.fill_value,\n        )\n    uncompressed = uncompress_dimension(self.indptr)\n    coords = np.vstack((uncompressed, self.indices))\n    order = np.argsort(self._axis_order)\n    return (\n        COO(\n            coords,\n            self.data,\n            shape=self._compressed_shape,\n            fill_value=self.fill_value,\n        )\n        .reshape(self._reordered_shape)\n        .transpose(order)\n    )\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.todense","title":"<code>todense()</code>","text":"<p>Convert this :obj:<code>GCXS</code> array to a dense :obj:<code>numpy.ndarray</code>. Note that this may take a large amount of memory if the :obj:<code>GCXS</code> object's :code:<code>shape</code> is large.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The converted dense array.</p> See Also <p>DOK.todense : Equivalent :obj:<code>DOK</code> array method. COO.todense : Equivalent :obj:<code>COO</code> array method. scipy.sparse.coo_matrix.todense : Equivalent Scipy method.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def todense(self):\n    \"\"\"\n    Convert this :obj:`GCXS` array to a dense :obj:`numpy.ndarray`. Note that\n    this may take a large amount of memory if the :obj:`GCXS` object's :code:`shape`\n    is large.\n\n    Returns\n    -------\n    numpy.ndarray\n        The converted dense array.\n\n    See Also\n    --------\n    DOK.todense : Equivalent :obj:`DOK` array method.\n    COO.todense : Equivalent :obj:`COO` array method.\n    scipy.sparse.coo_matrix.todense : Equivalent Scipy method.\n    \"\"\"\n    if self.compressed_axes is None:\n        out = np.full(self.shape, self.fill_value, self.dtype)\n        if len(self.indices) != 0:\n            out[self.indices] = self.data\n        else:\n            if len(self.data) != 0:\n                out[()] = self.data[0]\n        return out\n    return self.tocoo().todense()\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.todok","title":"<code>todok()</code>","text":"Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def todok(self):\n    from .. import DOK\n\n    return DOK.from_coo(self.tocoo())  # probably a temporary solution\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.to_scipy_sparse","title":"<code>to_scipy_sparse(accept_fv=None)</code>","text":"<p>Converts this :obj:<code>GCXS</code> object into a :obj:<code>scipy.sparse.csr_matrix</code> or <code>scipy.sparse.csc_matrix</code>.</p> <p>Parameters:</p> Name Type Description Default <code>accept_fv</code> <code>scalar or list of scalar</code> <p>The list of accepted fill-values. The default accepts only zero.</p> <code>None</code> <p>Returns:</p> Type Description <code>obj:`scipy.sparse.csr_matrix` or `scipy.sparse.csc_matrix`</code> <p>The converted Scipy sparse matrix.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array is not two-dimensional.</p> <code>ValueError</code> <p>If all the array doesn't zero fill-values.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def to_scipy_sparse(self, accept_fv=None):\n    \"\"\"\n    Converts this :obj:`GCXS` object into a :obj:`scipy.sparse.csr_matrix` or `scipy.sparse.csc_matrix`.\n\n    Parameters\n    ----------\n    accept_fv : scalar or list of scalar, optional\n        The list of accepted fill-values. The default accepts only zero.\n\n    Returns\n    -------\n    :obj:`scipy.sparse.csr_matrix` or `scipy.sparse.csc_matrix`\n        The converted Scipy sparse matrix.\n\n    Raises\n    ------\n    ValueError\n        If the array is not two-dimensional.\n    ValueError\n        If all the array doesn't zero fill-values.\n    \"\"\"\n    import scipy.sparse\n\n    check_fill_value(self, accept_fv=accept_fv)\n    if self.ndim != 2:\n        raise ValueError(\"Can only convert a 2-dimensional array to a Scipy sparse matrix.\")\n\n    if 0 in self.compressed_axes:\n        return scipy.sparse.csr_matrix((self.data, self.indices, self.indptr), shape=self.shape)\n\n    return scipy.sparse.csc_matrix((self.data, self.indices, self.indptr), shape=self.shape)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.asformat","title":"<code>asformat(format, **kwargs)</code>","text":"<p>Convert this sparse array to a given format.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>A format string.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The converted array.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the format isn't supported.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def asformat(self, format, **kwargs):\n    \"\"\"\n    Convert this sparse array to a given format.\n    Parameters\n    ----------\n    format : str\n        A format string.\n\n    Returns\n    -------\n    out : SparseArray\n        The converted array.\n\n    Raises\n    ------\n    NotImplementedError\n        If the format isn't supported.\n    \"\"\"\n    from .._utils import convert_format\n\n    format = convert_format(format)\n    ret = None\n\n    if format == \"coo\":\n        ret = self.tocoo()\n    elif format == \"dok\":\n        ret = self.todok()\n    elif format == \"csr\":\n        ret = CSR(self)\n    elif format == \"csc\":\n        ret = CSC(self)\n    elif format == \"gcxs\":\n        compressed_axes = kwargs.pop(\"compressed_axes\", self.compressed_axes)\n        return self.change_compressed_axes(compressed_axes)\n\n    if len(kwargs) != 0:\n        raise TypeError(f\"Invalid keyword arguments provided: {kwargs}\")\n\n    if ret is None:\n        raise NotImplementedError(f\"The given format is not supported: {format}\")\n\n    return ret\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.maybe_densify","title":"<code>maybe_densify(max_size=1000, min_density=0.25)</code>","text":"<p>Converts this :obj:<code>GCXS</code> array to a :obj:<code>numpy.ndarray</code> if not too costly.</p> <p>Parameters:</p> Name Type Description Default <code>max_size</code> <code>int</code> <p>Maximum number of elements in output</p> <code>1000</code> <code>min_density</code> <code>float</code> <p>Minimum density of output</p> <code>0.25</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The dense array.</p> See Also <p>sparse.GCXS.todense: Converts to Numpy function without checking the cost. sparse.COO.maybe_densify: The equivalent COO function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the returned array would be too large.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def maybe_densify(self, max_size=1000, min_density=0.25):\n    \"\"\"\n    Converts this :obj:`GCXS` array to a :obj:`numpy.ndarray` if not too\n    costly.\n    Parameters\n    ----------\n    max_size : int\n        Maximum number of elements in output\n    min_density : float\n        Minimum density of output\n    Returns\n    -------\n    numpy.ndarray\n        The dense array.\n    See Also\n    --------\n    sparse.GCXS.todense: Converts to Numpy function without checking the cost.\n    sparse.COO.maybe_densify: The equivalent COO function.\n    Raises\n    -------\n    ValueError\n        If the returned array would be too large.\n    \"\"\"\n\n    if self.size &gt; max_size and self.density &lt; min_density:\n        raise ValueError(\"Operation would require converting large sparse array to dense\")\n\n    return self.todense()\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.flatten","title":"<code>flatten(order='C')</code>","text":"<p>Returns a new :obj:<code>GCXS</code> array that is a flattened version of this array.</p> <p>Returns:</p> Type Description <code>GCXS</code> <p>The flattened output array.</p> Notes <p>The :code:<code>order</code> parameter is provided just for compatibility with Numpy and isn't actually supported.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def flatten(self, order=\"C\"):\n    \"\"\"\n    Returns a new :obj:`GCXS` array that is a flattened version of this array.\n\n    Returns\n    -------\n    GCXS\n        The flattened output array.\n\n    Notes\n    -----\n    The :code:`order` parameter is provided just for compatibility with\n    Numpy and isn't actually supported.\n    \"\"\"\n    if order not in {\"C\", None}:\n        raise NotImplementedError(\"The `order` parameter is not supported.\")\n\n    return self.reshape(-1)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.reshape","title":"<code>reshape(shape, order='C', compressed_axes=None)</code>","text":"<p>Returns a new :obj:<code>GCXS</code> array that is a reshaped version of this array.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>tuple[int]</code> <p>The desired shape of the output array.</p> required <code>compressed_axes</code> <code>Iterable[int]</code> <p>The axes to compress to store the array. Finds the most efficient storage by default.</p> <code>None</code> <p>Returns:</p> Type Description <code>GCXS</code> <p>The reshaped output array.</p> See Also <p>numpy.ndarray.reshape : The equivalent Numpy function. sparse.COO.reshape : The equivalent COO function.</p> Notes <p>The :code:<code>order</code> parameter is provided just for compatibility with Numpy and isn't actually supported.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def reshape(self, shape, order=\"C\", compressed_axes=None):\n    \"\"\"\n    Returns a new :obj:`GCXS` array that is a reshaped version of this array.\n\n    Parameters\n    ----------\n    shape : tuple[int]\n        The desired shape of the output array.\n    compressed_axes : Iterable[int], optional\n        The axes to compress to store the array. Finds the most efficient storage\n        by default.\n\n    Returns\n    -------\n    GCXS\n        The reshaped output array.\n\n    See Also\n    --------\n    numpy.ndarray.reshape : The equivalent Numpy function.\n    sparse.COO.reshape : The equivalent COO function.\n\n    Notes\n    -----\n    The :code:`order` parameter is provided just for compatibility with\n    Numpy and isn't actually supported.\n\n    \"\"\"\n    shape = tuple(shape) if isinstance(shape, Iterable) else (shape,)\n    if order not in {\"C\", None}:\n        raise NotImplementedError(\"The 'order' parameter is not supported\")\n    if any(d == -1 for d in shape):\n        extra = int(self.size / np.prod([d for d in shape if d != -1]))\n        shape = tuple([d if d != -1 else extra for d in shape])\n\n    if self.shape == shape:\n        return self\n\n    if self.size != reduce(operator.mul, shape, 1):\n        raise ValueError(f\"cannot reshape array of size {self.size} into shape {shape}\")\n    if len(shape) == 0:\n        return self.tocoo().reshape(shape).asformat(\"gcxs\")\n\n    if compressed_axes is None:\n        if len(shape) == self.ndim:\n            compressed_axes = self.compressed_axes\n        elif len(shape) == 1:\n            compressed_axes = None\n        else:\n            compressed_axes = (np.argmin(shape),)\n\n    if self.ndim == 1:\n        arg = _1d_reshape(self, shape, compressed_axes)\n    else:\n        arg = _transpose(self, shape, np.arange(self.ndim), compressed_axes)\n    return GCXS(\n        arg,\n        shape=tuple(shape),\n        compressed_axes=compressed_axes,\n        fill_value=self.fill_value,\n    )\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.transpose","title":"<code>transpose(axes=None, compressed_axes=None)</code>","text":"<p>Returns a new array which has the order of the axes switched.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>Iterable[int]</code> <p>The new order of the axes compared to the previous one. Reverses the axes by default.</p> <code>None</code> <code>compressed_axes</code> <code>Iterable[int]</code> <p>The axes to compress to store the array. Finds the most efficient storage by default.</p> <code>None</code> <p>Returns:</p> Type Description <code>GCXS</code> <p>The new array with the axes in the desired order.</p> See Also <p>:obj:<code>GCXS.T</code> : A quick property to reverse the order of the axes. numpy.ndarray.transpose : Numpy equivalent function.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def transpose(self, axes=None, compressed_axes=None):\n    \"\"\"\n    Returns a new array which has the order of the axes switched.\n\n    Parameters\n    ----------\n    axes : Iterable[int], optional\n        The new order of the axes compared to the previous one. Reverses the axes\n        by default.\n    compressed_axes : Iterable[int], optional\n        The axes to compress to store the array. Finds the most efficient storage\n        by default.\n\n    Returns\n    -------\n    GCXS\n        The new array with the axes in the desired order.\n\n    See Also\n    --------\n    :obj:`GCXS.T` : A quick property to reverse the order of the axes.\n    numpy.ndarray.transpose : Numpy equivalent function.\n    \"\"\"\n    if axes is None:\n        axes = list(reversed(range(self.ndim)))\n\n    # Normalize all axes indices to positive values\n    axes = normalize_axis(axes, self.ndim)\n\n    if len(np.unique(axes)) &lt; len(axes):\n        raise ValueError(\"repeated axis in transpose\")\n\n    if not len(axes) == self.ndim:\n        raise ValueError(\"axes don't match array\")\n\n    axes = tuple(axes)\n\n    if axes == tuple(range(self.ndim)):\n        return self\n\n    if self.ndim == 2:\n        return self._2d_transpose()\n\n    shape = tuple(self.shape[ax] for ax in axes)\n\n    if compressed_axes is None:\n        compressed_axes = (np.argmin(shape),)\n    arg = _transpose(self, shape, axes, compressed_axes, transpose=True)\n    return GCXS(\n        arg,\n        shape=shape,\n        compressed_axes=compressed_axes,\n        fill_value=self.fill_value,\n    )\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.dot","title":"<code>dot(other)</code>","text":"<p>Performs the equivalent of :code:<code>x.dot(y)</code> for :obj:<code>GCXS</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Union[GCXS, COO, ndarray, spmatrix]</code> <p>The second operand of the dot product operation.</p> required <p>Returns:</p> Type Description <code>{GCXS, ndarray}</code> <p>The result of the dot product. If the result turns out to be dense, then a dense array is returned, otherwise, a sparse array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all arguments don't have zero fill-values.</p> See Also <p>dot : Equivalent function for two arguments. :obj:<code>numpy.dot</code> : Numpy equivalent function. scipy.sparse.csr_matrix.dot : Scipy equivalent function.</p> Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def dot(self, other):\n    \"\"\"\n    Performs the equivalent of :code:`x.dot(y)` for :obj:`GCXS`.\n\n    Parameters\n    ----------\n    other : Union[GCXS, COO, numpy.ndarray, scipy.sparse.spmatrix]\n        The second operand of the dot product operation.\n\n    Returns\n    -------\n    {GCXS, numpy.ndarray}\n        The result of the dot product. If the result turns out to be dense,\n        then a dense array is returned, otherwise, a sparse array.\n\n    Raises\n    ------\n    ValueError\n        If all arguments don't have zero fill-values.\n\n    See Also\n    --------\n    dot : Equivalent function for two arguments.\n    :obj:`numpy.dot` : Numpy equivalent function.\n    scipy.sparse.csr_matrix.dot : Scipy equivalent function.\n    \"\"\"\n    from .._common import dot\n\n    return dot(self, other)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.isinf","title":"<code>isinf()</code>","text":"Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def isinf(self):\n    return self.tocoo().isinf().asformat(\"gcxs\", compressed_axes=self.compressed_axes)\n</code></pre>"},{"location":"api/GCXS/#sparse.GCXS.isnan","title":"<code>isnan()</code>","text":"Source code in <code>sparse/numba_backend/_compressed/compressed.py</code> <pre><code>def isnan(self):\n    return self.tocoo().isnan().asformat(\"gcxs\", compressed_axes=self.compressed_axes)\n</code></pre>"},{"location":"api/SparseArray/","title":"SparseArray","text":"<p>An abstract base class for all the sparse array classes.</p> <p>Attributes:</p> Name Type Description <code>dtype</code> <code>dtype</code> <p>The data type of this array.</p> <code>fill_value</code> <code>scalar</code> <p>The fill value of this array.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>class SparseArray:\n    \"\"\"\n    An abstract base class for all the sparse array classes.\n\n    Attributes\n    ----------\n    dtype : numpy.dtype\n        The data type of this array.\n    fill_value : scalar\n        The fill value of this array.\n    \"\"\"\n\n    __metaclass__ = ABCMeta\n\n    def __init__(self, shape, fill_value=None):\n        if not isinstance(shape, Iterable):\n            shape = (shape,)\n\n        if not all(isinstance(sh, Integral) and int(sh) &gt;= 0 for sh in shape):\n            raise ValueError(\"shape must be an non-negative integer or a tuple of non-negative integers.\")\n\n        self.shape = tuple(int(sh) for sh in shape)\n\n        if fill_value is not None:\n            if not hasattr(fill_value, \"dtype\") or fill_value.dtype != self.dtype:\n                self.fill_value = self.dtype.type(fill_value)\n            else:\n                self.fill_value = fill_value\n        else:\n            self.fill_value = _zero_of_dtype(self.dtype)\n\n    dtype = None\n\n    @property\n    def device(self):\n        data = getattr(self, \"data\", None)\n        return getattr(data, \"device\", \"cpu\")\n\n    def to_device(self, device, /, *, stream=None):\n        if device != \"cpu\":\n            raise ValueError(\"Only `device='cpu'` is supported.\")\n\n        return self\n\n    @property\n    @abstractmethod\n    def nnz(self):\n        \"\"\"\n        The number of nonzero elements in this array. Note that any duplicates in\n        :code:`coords` are counted multiple times. To avoid this, call :obj:`COO.sum_duplicates`.\n\n        Returns\n        -------\n        int\n            The number of nonzero elements in this array.\n\n        See Also\n        --------\n        DOK.nnz : Equivalent :obj:`DOK` array property.\n        numpy.count_nonzero : A similar Numpy function.\n        scipy.sparse.coo_matrix.nnz : The Scipy equivalent property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = np.array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0])\n        &gt;&gt;&gt; np.count_nonzero(x)\n        6\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.nnz\n        6\n        &gt;&gt;&gt; np.count_nonzero(x) == s.nnz\n        True\n        \"\"\"\n\n    @property\n    def ndim(self):\n        \"\"\"\n        The number of dimensions of this array.\n\n        Returns\n        -------\n        int\n            The number of dimensions of this array.\n\n        See Also\n        --------\n            [DOK.ndim][sparse.DOK.ndim] : Equivalent property for [DOK][sparse.DOK] arrays.\n            [numpy.ndarray.ndim][] : Numpy equivalent property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; x = np.random.rand(1, 2, 3, 1, 2)\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.ndim\n        5\n        &gt;&gt;&gt; s.ndim == x.ndim\n        True\n        \"\"\"\n        return len(self.shape)\n\n    @property\n    def size(self):\n        \"\"\"\n        The number of all elements (including zeros) in this array.\n\n        Returns\n        -------\n        int\n            The number of elements.\n\n        See Also\n        --------\n            [numpy.ndarray.size][] : Numpy equivalent property.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; x = np.zeros((10, 10))\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.size\n        100\n        \"\"\"\n        # We use this instead of np.prod because np.prod\n        # returns a float64 for an empty shape.\n        return reduce(operator.mul, self.shape, 1)\n\n    @property\n    def density(self):\n        \"\"\"\n        The ratio of nonzero to all elements in this array.\n\n        Returns\n        -------\n        float\n            The ratio of nonzero to all elements.\n\n        See Also\n        --------\n            COO.size : Number of elements.\n            COO.nnz : Number of nonzero elements.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = np.zeros((8, 8))\n        &gt;&gt;&gt; x[0, :] = 1\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s.density\n        0.125\n        \"\"\"\n        return self.nnz / self.size\n\n    def _repr_html_(self):\n        \"\"\"\n        Diagnostic report about this array.\n        Renders in Jupyter.\n        \"\"\"\n        try:\n            from matrepr import to_html\n            from matrepr.adapters.sparse_driver import PyDataSparseDriver\n\n            return to_html(PyDataSparseDriver.adapt(self), notebook=True)\n        except (ImportError, ValueError):\n            return html_table(self)\n\n    def _str_impl(self, summary):\n        \"\"\"\n        A human-readable representation of this array, including a metadata summary\n        and a tabular view of the array values.\n\n        Values view only included if `matrepr` is available.\n\n        Parameters\n        ----------\n        summary\n            A type-specific summary of this array, used as the first line of return value.\n\n        Returns\n        -------\n        str\n            A human-readable representation of this array.\n        \"\"\"\n        try:\n            from matrepr import to_str\n            from matrepr.adapters.sparse_driver import PyDataSparseDriver\n\n            values = to_str(\n                PyDataSparseDriver.adapt(self),\n                title=False,  # disable matrepr description\n                width_str=0,  # autodetect terminal width\n                max_cols=9999,\n            )\n            return f\"{summary}\\n{values}\"\n        except (ImportError, ValueError):\n            return summary\n\n    @abstractmethod\n    def asformat(self, format):\n        \"\"\"\n        Convert this sparse array to a given format.\n\n        Parameters\n        ----------\n        format : str\n            A format string.\n\n        Returns\n        -------\n        out : SparseArray\n            The converted array.\n\n        Raises\n        ------\n        NotImplementedError\n            If the format isn't supported.\n        \"\"\"\n\n    @abstractmethod\n    def todense(self):\n        \"\"\"\n        Convert this :obj:`SparseArray` array to a dense :obj:`numpy.ndarray`. Note that\n        this may take a large amount of memory and time.\n\n        Returns\n        -------\n        numpy.ndarray\n            The converted dense array.\n\n        See Also\n        --------\n        DOK.todense : Equivalent :obj:`DOK` array method.\n        COO.todense : Equivalent :obj:`COO` array method.\n        scipy.sparse.coo_matrix.todense : Equivalent Scipy method.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import sparse\n        &gt;&gt;&gt; x = np.random.randint(100, size=(7, 3))\n        &gt;&gt;&gt; s = sparse.COO.from_numpy(x)\n        &gt;&gt;&gt; x2 = s.todense()\n        &gt;&gt;&gt; np.array_equal(x, x2)\n        True\n        \"\"\"\n\n    def _make_shallow_copy_of(self, other):\n        self.__dict__ = other.__dict__.copy()\n\n    def __array__(self, *args, **kwargs):\n        from ._settings import AUTO_DENSIFY\n\n        if not AUTO_DENSIFY:\n            raise RuntimeError(\n                \"Cannot convert a sparse array to dense automatically. To manually densify, use the todense method.\"\n            )\n\n        return np.asarray(self.todense(), *args, **kwargs)\n\n    def __array_function__(self, func, types, args, kwargs):\n        import sparse as module\n\n        sparse_func = None\n        try:\n            submodules = getattr(func, \"__module__\", \"numpy\").split(\".\")[1:]\n            for submodule in submodules:\n                module = getattr(module, submodule)\n            sparse_func = getattr(module, func.__name__)\n        except AttributeError:\n            pass\n        else:\n            return sparse_func(*args, **kwargs)\n\n        with contextlib.suppress(AttributeError):\n            sparse_func = getattr(type(self), func.__name__)\n\n        if not isinstance(sparse_func, Callable) and len(args) == 1 and len(kwargs) == 0:\n            try:\n                return getattr(self, func.__name__)\n            except AttributeError:\n                pass\n\n        if sparse_func is None:\n            return NotImplemented\n\n        return sparse_func(*args, **kwargs)\n\n    @staticmethod\n    def _reduce(method, *args, **kwargs):\n        from ._common import _is_scipy_sparse_obj\n\n        assert len(args) == 1\n\n        self = args[0]\n        if _is_scipy_sparse_obj(self):\n            self = type(self).from_scipy_sparse(self)\n\n        return self.reduce(method, **kwargs)\n\n    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):\n        out = kwargs.pop(\"out\", None)\n        if out is not None and not all(isinstance(x, type(self)) for x in out):\n            return NotImplemented\n\n        if getattr(ufunc, \"signature\", None) is not None:\n            return self.__array_function__(ufunc, (np.ndarray, type(self)), inputs, kwargs)\n\n        if out is not None:\n            test_args = [np.empty((1,), dtype=a.dtype) if hasattr(a, \"dtype\") else a for a in inputs]\n            test_kwargs = kwargs.copy()\n            if method == \"reduce\":\n                test_kwargs[\"axis\"] = None\n            test_out = tuple(np.empty((1,), dtype=a.dtype) for a in out)\n            if len(test_out) == 1:\n                test_out = test_out[0]\n            getattr(ufunc, method)(*test_args, out=test_out, **test_kwargs)\n            kwargs[\"dtype\"] = out[0].dtype\n\n        if method == \"outer\":\n            method = \"__call__\"\n\n            cum_ndim = 0\n            inputs_transformed = []\n            for inp in reversed(inputs):\n                inputs_transformed.append(inp[(Ellipsis,) + (None,) * cum_ndim])\n                cum_ndim += inp.ndim\n\n            inputs = tuple(reversed(inputs_transformed))\n\n        if method == \"__call__\":\n            result = elemwise(ufunc, *inputs, **kwargs)\n        elif method == \"reduce\":\n            result = SparseArray._reduce(ufunc, *inputs, **kwargs)\n        else:\n            return NotImplemented\n\n        if out is not None:\n            (out,) = out\n            if out.shape != result.shape:\n                raise ValueError(\n                    f\"non-broadcastable output operand with shape {out.shape} \"\n                    f\"doesn't match the broadcast shape {result.shape}\"\n                )\n\n            out._make_shallow_copy_of(result)\n            return out\n\n        return result\n\n    def reduce(self, method, axis=(0,), keepdims=False, **kwargs):\n        \"\"\"\n        Performs a reduction operation on this array.\n\n        Parameters\n        ----------\n        method : numpy.ufunc\n            The method to use for performing the reduction.\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to perform the reduction. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n        **kwargs : dict\n            Any extra arguments to pass to the reduction operation.\n\n        See Also\n        --------\n        numpy.ufunc.reduce : A similar Numpy method.\n        COO.reduce : This method implemented on COO arrays.\n        GCXS.reduce : This method implemented on GCXS arrays.\n        \"\"\"\n        axis = normalize_axis(axis, self.ndim)\n        zero_reduce_result = method.reduce([self.fill_value, self.fill_value], **kwargs)\n        reduce_super_ufunc = _reduce_super_ufunc.get(method)\n        if not equivalent(zero_reduce_result, self.fill_value) and reduce_super_ufunc is None:\n            raise ValueError(f\"Performing this reduction operation would produce a dense result: {method!s}\")\n\n        if not isinstance(axis, tuple):\n            axis = (axis,)\n        out = self._reduce_calc(method, axis, keepdims, **kwargs)\n        if len(out) == 1:\n            return out[0]\n        data, counts, axis, n_cols, arr_attrs = out\n        result_fill_value = self.fill_value\n        if reduce_super_ufunc is None:\n            missing_counts = counts != n_cols\n            data[missing_counts] = method(data[missing_counts], self.fill_value, **kwargs)\n        else:\n            data = method(\n                data,\n                reduce_super_ufunc(self.fill_value, n_cols - counts),\n            ).astype(data.dtype)\n            result_fill_value = reduce_super_ufunc(self.fill_value, n_cols)\n\n        out = self._reduce_return(data, arr_attrs, result_fill_value)\n\n        if keepdims:\n            shape = list(self.shape)\n            for ax in axis:\n                shape[ax] = 1\n            out = out.reshape(shape)\n\n        if out.ndim == 0:\n            return out[()]\n\n        return out\n\n    def _reduce_calc(self, method, axis, keepdims, **kwargs):\n        raise NotImplementedError\n\n    def _reduce_return(self, data, arr_attrs, result_fill_value):\n        raise NotImplementedError\n\n    def sum(self, axis=None, keepdims=False, dtype=None, out=None):\n        \"\"\"\n        Performs a sum operation along the given axes. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to sum. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n        dtype : numpy.dtype\n            The data type of the output array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        :obj:`numpy.sum` : Equivalent numpy function.\n        scipy.sparse.coo_matrix.sum : Equivalent Scipy function.\n        \"\"\"\n        return np.add.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n\n    def max(self, axis=None, keepdims=False, out=None):\n        \"\"\"\n        Maximize along the given axes. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to maximize. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n        out : numpy.dtype\n            The data type of the output array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        :obj:`numpy.max` : Equivalent numpy function.\n        scipy.sparse.coo_matrix.max : Equivalent Scipy function.\n        \"\"\"\n        return np.maximum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n\n    amax = max\n\n    def any(self, axis=None, keepdims=False, out=None):\n        \"\"\"\n        See if any values along array are ``True``. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to minimize. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        :obj:`numpy.any` : Equivalent numpy function.\n        \"\"\"\n        return np.logical_or.reduce(self, out=out, axis=axis, keepdims=keepdims)\n\n    def all(self, axis=None, keepdims=False, out=None):\n        \"\"\"\n        See if all values in an array are ``True``. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to minimize. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        :obj:`numpy.all` : Equivalent numpy function.\n        \"\"\"\n        return np.logical_and.reduce(self, out=out, axis=axis, keepdims=keepdims)\n\n    def min(self, axis=None, keepdims=False, out=None):\n        \"\"\"\n        Minimize along the given axes. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to minimize. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n        out : numpy.dtype\n            The data type of the output array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        :obj:`numpy.min` : Equivalent numpy function.\n        scipy.sparse.coo_matrix.min : Equivalent Scipy function.\n        \"\"\"\n        return np.minimum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n\n    amin = min\n\n    def prod(self, axis=None, keepdims=False, dtype=None, out=None):\n        \"\"\"\n        Performs a product operation along the given axes. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to multiply. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n        dtype : numpy.dtype\n            The data type of the output array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        :obj:`numpy.prod` : Equivalent numpy function.\n        \"\"\"\n        return np.multiply.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n\n    def round(self, decimals=0, out=None):\n        \"\"\"\n        Evenly round to the given number of decimals.\n\n        See Also\n        --------\n        :obj:`numpy.round` :\n            NumPy equivalent ufunc.\n        :obj:`COO.elemwise` :\n            Apply an arbitrary element-wise function to one or two\n            arguments.\n        \"\"\"\n        if out is not None and not isinstance(out, tuple):\n            out = (out,)\n        return self.__array_ufunc__(np.round, \"__call__\", self, decimals=decimals, out=out)\n\n    round_ = round\n\n    def clip(self, min=None, max=None, out=None):\n        \"\"\"\n        Clip (limit) the values in the array.\n\n        Return an array whose values are limited to ``[min, max]``. One of min\n        or max must be given.\n\n        See Also\n        --------\n        sparse.clip : For full documentation and more details.\n        numpy.clip : Equivalent NumPy function.\n        \"\"\"\n        if min is None and max is None:\n            raise ValueError(\"One of max or min must be given.\")\n        if out is not None and not isinstance(out, tuple):\n            out = (out,)\n        return self.__array_ufunc__(np.clip, \"__call__\", self, a_min=min, a_max=max, out=out)\n\n    def astype(self, dtype, casting=\"unsafe\", copy=True):\n        \"\"\"\n        Copy of the array, cast to a specified type.\n\n        See Also\n        --------\n        scipy.sparse.coo_matrix.astype :\n            SciPy sparse equivalent function\n        numpy.ndarray.astype :\n            NumPy equivalent ufunc.\n        :obj:`COO.elemwise` :\n            Apply an arbitrary element-wise function to one or two\n            arguments.\n        \"\"\"\n        # this matches numpy's behavior\n        if self.dtype == dtype and not copy:\n            return self\n        return self.__array_ufunc__(np.ndarray.astype, \"__call__\", self, dtype=dtype, copy=copy, casting=casting)\n\n    def mean(self, axis=None, keepdims=False, dtype=None, out=None):\n        \"\"\"\n        Compute the mean along the given axes. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to compute the mean. Uses all axes by default.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n        dtype : numpy.dtype\n            The data type of the output array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        numpy.ndarray.mean : Equivalent numpy method.\n        scipy.sparse.coo_matrix.mean : Equivalent Scipy method.\n\n        Notes\n        -----\n        * This function internally calls :obj:`COO.sum_duplicates` to bring the\n          array into canonical form.\n        * The :code:`out` parameter is provided just for compatibility with\n          Numpy and isn't actually supported.\n\n        Examples\n        --------\n        You can use :obj:`COO.mean` to compute the mean of an array across any\n        dimension.\n\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s2 = s.mean(axis=1)\n        &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n        array([0.5, 1.5, 0., 0.])\n\n        You can also use the :code:`keepdims` argument to keep the dimensions\n        after the mean.\n\n        &gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n        &gt;&gt;&gt; s3.shape\n        (1, 4)\n\n        You can pass in an output datatype, if needed.\n\n        &gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n        &gt;&gt;&gt; s4.dtype\n        dtype('float16')\n\n        By default, this reduces the array down to one number, computing the\n        mean along all axes.\n\n        &gt;&gt;&gt; s.mean()\n        0.5\n        \"\"\"\n\n        if axis is None:\n            axis = tuple(range(self.ndim))\n        elif not isinstance(axis, tuple):\n            axis = (axis,)\n        den = reduce(operator.mul, (self.shape[i] for i in axis), 1)\n\n        if dtype is None:\n            if issubclass(self.dtype.type, np.integer | np.bool_):\n                dtype = inter_dtype = np.dtype(\"f8\")\n            else:\n                dtype = self.dtype\n                inter_dtype = np.dtype(\"f4\") if issubclass(dtype.type, np.float16) else dtype\n        else:\n            inter_dtype = dtype\n\n        num = self.sum(axis=axis, keepdims=keepdims, dtype=inter_dtype)\n\n        if num.ndim:\n            out = np.true_divide(num, den, casting=\"unsafe\")\n            return out.astype(dtype) if out.dtype != dtype else out\n        return np.divide(num, den, dtype=dtype, out=out)\n\n    def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n        \"\"\"\n        Compute the variance along the given axes. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to compute the variance. Uses all axes by default.\n        dtype : numpy.dtype, optional\n            The output datatype.\n        out : SparseArray, optional\n            The array to write the output to.\n        ddof : int\n            The degrees of freedom.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        numpy.ndarray.var : Equivalent numpy method.\n\n        Notes\n        -----\n        * This function internally calls :obj:`COO.sum_duplicates` to bring the\n          array into canonical form.\n\n        Examples\n        --------\n        You can use :obj:`COO.var` to compute the variance of an array across any\n        dimension.\n\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s2 = s.var(axis=1)\n        &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n        array([0.6875, 0.1875])\n\n        You can also use the :code:`keepdims` argument to keep the dimensions\n        after the variance.\n\n        &gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n        &gt;&gt;&gt; s3.shape\n        (1, 4)\n\n        You can pass in an output datatype, if needed.\n\n        &gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n        &gt;&gt;&gt; s4.dtype\n        dtype('float16')\n\n        By default, this reduces the array down to one number, computing the\n        variance along all axes.\n\n        &gt;&gt;&gt; s.var()\n        0.5\n        \"\"\"\n        axis = normalize_axis(axis, self.ndim)\n\n        if axis is None:\n            axis = tuple(range(self.ndim))\n\n        if not isinstance(axis, tuple):\n            axis = (axis,)\n\n        rcount = reduce(operator.mul, (self.shape[a] for a in axis), 1)\n        # Make this warning show up on top.\n        if ddof &gt;= rcount:\n            warnings.warn(\"Degrees of freedom &lt;= 0 for slice\", RuntimeWarning, stacklevel=1)\n\n        # Cast bool, unsigned int, and int to float64 by default\n        if dtype is None and issubclass(self.dtype.type, np.integer | np.bool_):\n            dtype = np.dtype(\"f8\")\n\n        arrmean = self.sum(axis, dtype=dtype, keepdims=True)[...]\n        np.divide(arrmean, rcount, out=arrmean)\n        x = self - arrmean\n        if issubclass(self.dtype.type, np.complexfloating):\n            x = x.real * x.real + x.imag * x.imag\n        else:\n            x = np.multiply(x, x, out=x)\n\n        ret = x.sum(axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n        # Compute degrees of freedom and make sure it is not negative.\n        rcount = max([rcount - ddof, 0])\n\n        ret = ret[...]\n        np.divide(ret, rcount, out=ret, casting=\"unsafe\")\n        return ret[()]\n\n    def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n        \"\"\"\n        Compute the standard deviation along the given axes. Uses all axes by default.\n\n        Parameters\n        ----------\n        axis : Union[int, Iterable[int]], optional\n            The axes along which to compute the standard deviation. Uses\n            all axes by default.\n        dtype : numpy.dtype, optional\n            The output datatype.\n        out : SparseArray, optional\n            The array to write the output to.\n        ddof : int\n            The degrees of freedom.\n        keepdims : bool, optional\n            Whether or not to keep the dimensions of the original array.\n\n        Returns\n        -------\n        SparseArray\n            The reduced output sparse array.\n\n        See Also\n        --------\n        numpy.ndarray.std : Equivalent numpy method.\n\n        Notes\n        -----\n        * This function internally calls :obj:`COO.sum_duplicates` to bring the\n          array into canonical form.\n\n        Examples\n        --------\n        You can use :obj:`COO.std` to compute the standard deviation of an array\n        across any dimension.\n\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n        &gt;&gt;&gt; s = COO.from_numpy(x)\n        &gt;&gt;&gt; s2 = s.std(axis=1)\n        &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n        array([0.8291562, 0.4330127])\n\n        You can also use the :code:`keepdims` argument to keep the dimensions\n        after the standard deviation.\n\n        &gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n        &gt;&gt;&gt; s3.shape\n        (1, 4)\n\n        You can pass in an output datatype, if needed.\n\n        &gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n        &gt;&gt;&gt; s4.dtype\n        dtype('float16')\n\n        By default, this reduces the array down to one number, computing the\n        standard deviation along all axes.\n\n        &gt;&gt;&gt; s.std()  # doctest: +SKIP\n        0.7071067811865476\n        \"\"\"\n        ret = self.var(axis=axis, dtype=dtype, out=out, ddof=ddof, keepdims=keepdims)\n\n        return np.sqrt(ret)\n\n    @property\n    def real(self):\n        \"\"\"The real part of the array.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n        &gt;&gt;&gt; x.real.todense()  # doctest: +SKIP\n        array([1., 0.])\n        &gt;&gt;&gt; x.real.dtype\n        dtype('float64')\n\n        Returns\n        -------\n        out : SparseArray\n            The real component of the array elements. If the array dtype is\n            real, the dtype of the array is used for the output. If the array\n            is complex, the output dtype is float.\n\n        See Also\n        --------\n        numpy.ndarray.real : NumPy equivalent attribute.\n        numpy.real : NumPy equivalent function.\n        \"\"\"\n        return self.__array_ufunc__(np.real, \"__call__\", self)\n\n    @property\n    def imag(self):\n        \"\"\"The imaginary part of the array.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n        &gt;&gt;&gt; x.imag.todense()  # doctest: +SKIP\n        array([0., 1.])\n        &gt;&gt;&gt; x.imag.dtype\n        dtype('float64')\n\n        Returns\n        -------\n        out : SparseArray\n            The imaginary component of the array elements. If the array dtype\n            is real, the dtype of the array is used for the output. If the\n            array is complex, the output dtype is float.\n\n        See Also\n        --------\n        numpy.ndarray.imag : NumPy equivalent attribute.\n        numpy.imag : NumPy equivalent function.\n        \"\"\"\n        return self.__array_ufunc__(np.imag, \"__call__\", self)\n\n    def conj(self):\n        \"\"\"Return the complex conjugate, element-wise.\n\n        The complex conjugate of a complex number is obtained by changing the\n        sign of its imaginary part.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from sparse import COO\n        &gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n        &gt;&gt;&gt; res = x.conj()\n        &gt;&gt;&gt; res.todense()  # doctest: +SKIP\n        array([1.-2.j, 2.+1.j])\n        &gt;&gt;&gt; res.dtype\n        dtype('complex128')\n\n        Returns\n        -------\n        out : SparseArray\n            The complex conjugate, with same dtype as the input.\n\n        See Also\n        --------\n        numpy.ndarray.conj : NumPy equivalent method.\n        numpy.conj : NumPy equivalent function.\n        \"\"\"\n        return np.conj(self)\n\n    def __array_namespace__(self, *, api_version=None):\n        if api_version is None:\n            api_version = \"2022.12\"\n\n        if api_version not in {\"2021.12\", \"2022.12\"}:\n            raise ValueError(f'\"{api_version}\" Array API version not supported.')\n        import sparse\n\n        return sparse\n\n    def __bool__(self):\n        \"\"\" \"\"\"\n        return self._to_scalar(bool)\n\n    def __float__(self):\n        \"\"\" \"\"\"\n        return self._to_scalar(float)\n\n    def __int__(self):\n        \"\"\" \"\"\"\n        return self._to_scalar(int)\n\n    def __index__(self):\n        \"\"\" \"\"\"\n        return self._to_scalar(int)\n\n    def __complex__(self):\n        \"\"\" \"\"\"\n        return self._to_scalar(complex)\n\n    def _to_scalar(self, builtin):\n        if self.size != 1 or self.shape != ():\n            raise ValueError(f\"{builtin} can be computed for one-element arrays only.\")\n        return builtin(self.todense().flatten()[0])\n\n    @abstractmethod\n    def isinf(self):\n        \"\"\" \"\"\"\n\n    @abstractmethod\n    def isnan(self):\n        \"\"\" \"\"\"\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.shape","title":"<code>shape = tuple(int(sh) for sh in shape)</code>  <code>instance-attribute</code>","text":""},{"location":"api/SparseArray/#sparse.SparseArray.fill_value","title":"<code>fill_value = self.dtype.type(fill_value)</code>  <code>instance-attribute</code>","text":""},{"location":"api/SparseArray/#sparse.SparseArray.dtype","title":"<code>dtype = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/SparseArray/#sparse.SparseArray.device","title":"<code>device</code>  <code>property</code>","text":""},{"location":"api/SparseArray/#sparse.SparseArray.nnz","title":"<code>nnz</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The number of nonzero elements in this array. Note that any duplicates in :code:<code>coords</code> are counted multiple times. To avoid this, call :obj:<code>COO.sum_duplicates</code>.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of nonzero elements in this array.</p> See Also <p>DOK.nnz : Equivalent :obj:<code>DOK</code> array property. numpy.count_nonzero : A similar Numpy function. scipy.sparse.coo_matrix.nnz : The Scipy equivalent property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0])\n&gt;&gt;&gt; np.count_nonzero(x)\n6\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.nnz\n6\n&gt;&gt;&gt; np.count_nonzero(x) == s.nnz\nTrue\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>The number of dimensions of this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of dimensions of this array.</p> See Also <pre><code>[DOK.ndim][sparse.DOK.ndim] : Equivalent property for [DOK][sparse.DOK] arrays.\n[numpy.ndarray.ndim][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.random.rand(1, 2, 3, 1, 2)\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.ndim\n5\n&gt;&gt;&gt; s.ndim == x.ndim\nTrue\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.size","title":"<code>size</code>  <code>property</code>","text":"<p>The number of all elements (including zeros) in this array.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of elements.</p> See Also <pre><code>[numpy.ndarray.size][] : Numpy equivalent property.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.zeros((10, 10))\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.size\n100\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.density","title":"<code>density</code>  <code>property</code>","text":"<p>The ratio of nonzero to all elements in this array.</p> <p>Returns:</p> Type Description <code>float</code> <p>The ratio of nonzero to all elements.</p> See Also <pre><code>COO.size : Number of elements.\nCOO.nnz : Number of nonzero elements.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.zeros((8, 8))\n&gt;&gt;&gt; x[0, :] = 1\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s.density\n0.125\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.amax","title":"<code>amax = max</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/SparseArray/#sparse.SparseArray.amin","title":"<code>amin = min</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/SparseArray/#sparse.SparseArray.round_","title":"<code>round_ = round</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/SparseArray/#sparse.SparseArray.real","title":"<code>real</code>  <code>property</code>","text":"<p>The real part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.real.todense()\narray([1., 0.])\n&gt;&gt;&gt; x.real.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The real component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.real : NumPy equivalent attribute. numpy.real : NumPy equivalent function.</p>"},{"location":"api/SparseArray/#sparse.SparseArray.imag","title":"<code>imag</code>  <code>property</code>","text":"<p>The imaginary part of the array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 0j, 0 + 1j])\n&gt;&gt;&gt; x.imag.todense()\narray([0., 1.])\n&gt;&gt;&gt; x.imag.dtype\ndtype('float64')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The imaginary component of the array elements. If the array dtype is real, the dtype of the array is used for the output. If the array is complex, the output dtype is float.</p> See Also <p>numpy.ndarray.imag : NumPy equivalent attribute. numpy.imag : NumPy equivalent function.</p>"},{"location":"api/SparseArray/#sparse.SparseArray.to_device","title":"<code>to_device(device, /, *, stream=None)</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def to_device(self, device, /, *, stream=None):\n    if device != \"cpu\":\n        raise ValueError(\"Only `device='cpu'` is supported.\")\n\n    return self\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.asformat","title":"<code>asformat(format)</code>  <code>abstractmethod</code>","text":"<p>Convert this sparse array to a given format.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>A format string.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The converted array.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the format isn't supported.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>@abstractmethod\ndef asformat(self, format):\n    \"\"\"\n    Convert this sparse array to a given format.\n\n    Parameters\n    ----------\n    format : str\n        A format string.\n\n    Returns\n    -------\n    out : SparseArray\n        The converted array.\n\n    Raises\n    ------\n    NotImplementedError\n        If the format isn't supported.\n    \"\"\"\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.todense","title":"<code>todense()</code>  <code>abstractmethod</code>","text":"<p>Convert this :obj:<code>SparseArray</code> array to a dense :obj:<code>numpy.ndarray</code>. Note that this may take a large amount of memory and time.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The converted dense array.</p> See Also <p>DOK.todense : Equivalent :obj:<code>DOK</code> array method. COO.todense : Equivalent :obj:<code>COO</code> array method. scipy.sparse.coo_matrix.todense : Equivalent Scipy method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = np.random.randint(100, size=(7, 3))\n&gt;&gt;&gt; s = sparse.COO.from_numpy(x)\n&gt;&gt;&gt; x2 = s.todense()\n&gt;&gt;&gt; np.array_equal(x, x2)\nTrue\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>@abstractmethod\ndef todense(self):\n    \"\"\"\n    Convert this :obj:`SparseArray` array to a dense :obj:`numpy.ndarray`. Note that\n    this may take a large amount of memory and time.\n\n    Returns\n    -------\n    numpy.ndarray\n        The converted dense array.\n\n    See Also\n    --------\n    DOK.todense : Equivalent :obj:`DOK` array method.\n    COO.todense : Equivalent :obj:`COO` array method.\n    scipy.sparse.coo_matrix.todense : Equivalent Scipy method.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = np.random.randint(100, size=(7, 3))\n    &gt;&gt;&gt; s = sparse.COO.from_numpy(x)\n    &gt;&gt;&gt; x2 = s.todense()\n    &gt;&gt;&gt; np.array_equal(x, x2)\n    True\n    \"\"\"\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.reduce","title":"<code>reduce(method, axis=(0), keepdims=False, **kwargs)</code>","text":"<p>Performs a reduction operation on this array.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>ufunc</code> <p>The method to use for performing the reduction.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to perform the reduction. Uses all axes by default.</p> <code>(0)</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Any extra arguments to pass to the reduction operation.</p> <code>{}</code> See Also <p>numpy.ufunc.reduce : A similar Numpy method. COO.reduce : This method implemented on COO arrays. GCXS.reduce : This method implemented on GCXS arrays.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def reduce(self, method, axis=(0,), keepdims=False, **kwargs):\n    \"\"\"\n    Performs a reduction operation on this array.\n\n    Parameters\n    ----------\n    method : numpy.ufunc\n        The method to use for performing the reduction.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to perform the reduction. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    **kwargs : dict\n        Any extra arguments to pass to the reduction operation.\n\n    See Also\n    --------\n    numpy.ufunc.reduce : A similar Numpy method.\n    COO.reduce : This method implemented on COO arrays.\n    GCXS.reduce : This method implemented on GCXS arrays.\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n    zero_reduce_result = method.reduce([self.fill_value, self.fill_value], **kwargs)\n    reduce_super_ufunc = _reduce_super_ufunc.get(method)\n    if not equivalent(zero_reduce_result, self.fill_value) and reduce_super_ufunc is None:\n        raise ValueError(f\"Performing this reduction operation would produce a dense result: {method!s}\")\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n    out = self._reduce_calc(method, axis, keepdims, **kwargs)\n    if len(out) == 1:\n        return out[0]\n    data, counts, axis, n_cols, arr_attrs = out\n    result_fill_value = self.fill_value\n    if reduce_super_ufunc is None:\n        missing_counts = counts != n_cols\n        data[missing_counts] = method(data[missing_counts], self.fill_value, **kwargs)\n    else:\n        data = method(\n            data,\n            reduce_super_ufunc(self.fill_value, n_cols - counts),\n        ).astype(data.dtype)\n        result_fill_value = reduce_super_ufunc(self.fill_value, n_cols)\n\n    out = self._reduce_return(data, arr_attrs, result_fill_value)\n\n    if keepdims:\n        shape = list(self.shape)\n        for ax in axis:\n            shape[ax] = 1\n        out = out.reshape(shape)\n\n    if out.ndim == 0:\n        return out[()]\n\n    return out\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.sum","title":"<code>sum(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a sum operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to sum. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.sum</code> : Equivalent numpy function. scipy.sparse.coo_matrix.sum : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def sum(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a sum operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to sum. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.sum` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.sum : Equivalent Scipy function.\n    \"\"\"\n    return np.add.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.max","title":"<code>max(axis=None, keepdims=False, out=None)</code>","text":"<p>Maximize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to maximize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.max</code> : Equivalent numpy function. scipy.sparse.coo_matrix.max : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def max(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Maximize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to maximize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.max` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.max : Equivalent Scipy function.\n    \"\"\"\n    return np.maximum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.any","title":"<code>any(axis=None, keepdims=False, out=None)</code>","text":"<p>See if any values along array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.any</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def any(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if any values along array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.any` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_or.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.all","title":"<code>all(axis=None, keepdims=False, out=None)</code>","text":"<p>See if all values in an array are <code>True</code>. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.all</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def all(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    See if all values in an array are ``True``. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.all` : Equivalent numpy function.\n    \"\"\"\n    return np.logical_and.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.min","title":"<code>min(axis=None, keepdims=False, out=None)</code>","text":"<p>Minimize along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>out</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.min</code> : Equivalent numpy function. scipy.sparse.coo_matrix.min : Equivalent Scipy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def min(self, axis=None, keepdims=False, out=None):\n    \"\"\"\n    Minimize along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    out : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.min` : Equivalent numpy function.\n    scipy.sparse.coo_matrix.min : Equivalent Scipy function.\n    \"\"\"\n    return np.minimum.reduce(self, out=out, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.prod","title":"<code>prod(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Performs a product operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to multiply. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>numpy.prod</code> : Equivalent numpy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def prod(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a product operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to multiply. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`numpy.prod` : Equivalent numpy function.\n    \"\"\"\n    return np.multiply.reduce(self, out=out, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.round","title":"<code>round(decimals=0, out=None)</code>","text":"<p>Evenly round to the given number of decimals.</p> See Also <p>:obj:<code>numpy.round</code> :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def round(self, decimals=0, out=None):\n    \"\"\"\n    Evenly round to the given number of decimals.\n\n    See Also\n    --------\n    :obj:`numpy.round` :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.round, \"__call__\", self, decimals=decimals, out=out)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.clip","title":"<code>clip(min=None, max=None, out=None)</code>","text":"<p>Clip (limit) the values in the array.</p> <p>Return an array whose values are limited to <code>[min, max]</code>. One of min or max must be given.</p> See Also <p>sparse.clip : For full documentation and more details. numpy.clip : Equivalent NumPy function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def clip(self, min=None, max=None, out=None):\n    \"\"\"\n    Clip (limit) the values in the array.\n\n    Return an array whose values are limited to ``[min, max]``. One of min\n    or max must be given.\n\n    See Also\n    --------\n    sparse.clip : For full documentation and more details.\n    numpy.clip : Equivalent NumPy function.\n    \"\"\"\n    if min is None and max is None:\n        raise ValueError(\"One of max or min must be given.\")\n    if out is not None and not isinstance(out, tuple):\n        out = (out,)\n    return self.__array_ufunc__(np.clip, \"__call__\", self, a_min=min, a_max=max, out=out)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.astype","title":"<code>astype(dtype, casting='unsafe', copy=True)</code>","text":"<p>Copy of the array, cast to a specified type.</p> See Also <p>scipy.sparse.coo_matrix.astype :     SciPy sparse equivalent function numpy.ndarray.astype :     NumPy equivalent ufunc. :obj:<code>COO.elemwise</code> :     Apply an arbitrary element-wise function to one or two     arguments.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def astype(self, dtype, casting=\"unsafe\", copy=True):\n    \"\"\"\n    Copy of the array, cast to a specified type.\n\n    See Also\n    --------\n    scipy.sparse.coo_matrix.astype :\n        SciPy sparse equivalent function\n    numpy.ndarray.astype :\n        NumPy equivalent ufunc.\n    :obj:`COO.elemwise` :\n        Apply an arbitrary element-wise function to one or two\n        arguments.\n    \"\"\"\n    # this matches numpy's behavior\n    if self.dtype == dtype and not copy:\n        return self\n    return self.__array_ufunc__(np.ndarray.astype, \"__call__\", self, dtype=dtype, copy=copy, casting=casting)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.mean","title":"<code>mean(axis=None, keepdims=False, dtype=None, out=None)</code>","text":"<p>Compute the mean along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the mean. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.mean : Equivalent numpy method. scipy.sparse.coo_matrix.mean : Equivalent Scipy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> <li>The :code:<code>out</code> parameter is provided just for compatibility with   Numpy and isn't actually supported.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.mean</code> to compute the mean of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.mean(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.5, 1.5, 0., 0.])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the mean.</p> <pre><code>&gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the mean along all axes.</p> <pre><code>&gt;&gt;&gt; s.mean()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def mean(self, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Compute the mean along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the mean. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.mean : Equivalent numpy method.\n    scipy.sparse.coo_matrix.mean : Equivalent Scipy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n    * The :code:`out` parameter is provided just for compatibility with\n      Numpy and isn't actually supported.\n\n    Examples\n    --------\n    You can use :obj:`COO.mean` to compute the mean of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.mean(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.5, 1.5, 0., 0.])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the mean.\n\n    &gt;&gt;&gt; s3 = s.mean(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.mean(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    mean along all axes.\n\n    &gt;&gt;&gt; s.mean()\n    0.5\n    \"\"\"\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n    elif not isinstance(axis, tuple):\n        axis = (axis,)\n    den = reduce(operator.mul, (self.shape[i] for i in axis), 1)\n\n    if dtype is None:\n        if issubclass(self.dtype.type, np.integer | np.bool_):\n            dtype = inter_dtype = np.dtype(\"f8\")\n        else:\n            dtype = self.dtype\n            inter_dtype = np.dtype(\"f4\") if issubclass(dtype.type, np.float16) else dtype\n    else:\n        inter_dtype = dtype\n\n    num = self.sum(axis=axis, keepdims=keepdims, dtype=inter_dtype)\n\n    if num.ndim:\n        out = np.true_divide(num, den, casting=\"unsafe\")\n        return out.astype(dtype) if out.dtype != dtype else out\n    return np.divide(num, den, dtype=dtype, out=out)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.var","title":"<code>var(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the variance along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the variance. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.var : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.var</code> to compute the variance of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.var(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.6875, 0.1875])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the variance.</p> <pre><code>&gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the variance along all axes.</p> <pre><code>&gt;&gt;&gt; s.var()\n0.5\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the variance along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the variance. Uses all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.var : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.var` to compute the variance of an array across any\n    dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.var(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.6875, 0.1875])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the variance.\n\n    &gt;&gt;&gt; s3 = s.var(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.var(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    variance along all axes.\n\n    &gt;&gt;&gt; s.var()\n    0.5\n    \"\"\"\n    axis = normalize_axis(axis, self.ndim)\n\n    if axis is None:\n        axis = tuple(range(self.ndim))\n\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n\n    rcount = reduce(operator.mul, (self.shape[a] for a in axis), 1)\n    # Make this warning show up on top.\n    if ddof &gt;= rcount:\n        warnings.warn(\"Degrees of freedom &lt;= 0 for slice\", RuntimeWarning, stacklevel=1)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None and issubclass(self.dtype.type, np.integer | np.bool_):\n        dtype = np.dtype(\"f8\")\n\n    arrmean = self.sum(axis, dtype=dtype, keepdims=True)[...]\n    np.divide(arrmean, rcount, out=arrmean)\n    x = self - arrmean\n    if issubclass(self.dtype.type, np.complexfloating):\n        x = x.real * x.real + x.imag * x.imag\n    else:\n        x = np.multiply(x, x, out=x)\n\n    ret = x.sum(axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n    # Compute degrees of freedom and make sure it is not negative.\n    rcount = max([rcount - ddof, 0])\n\n    ret = ret[...]\n    np.divide(ret, rcount, out=ret, casting=\"unsafe\")\n    return ret[()]\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.std","title":"<code>std(axis=None, dtype=None, out=None, ddof=0, keepdims=False)</code>","text":"<p>Compute the standard deviation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the standard deviation. Uses all axes by default.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The output datatype.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>The array to write the output to.</p> <code>None</code> <code>ddof</code> <code>int</code> <p>The degrees of freedom.</p> <code>0</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The reduced output sparse array.</p> See Also <p>numpy.ndarray.std : Equivalent numpy method.</p> Notes <ul> <li>This function internally calls :obj:<code>COO.sum_duplicates</code> to bring the   array into canonical form.</li> </ul> <p>Examples:</p> <p>You can use :obj:<code>COO.std</code> to compute the standard deviation of an array across any dimension.</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n&gt;&gt;&gt; s = COO.from_numpy(x)\n&gt;&gt;&gt; s2 = s.std(axis=1)\n&gt;&gt;&gt; s2.todense()\narray([0.8291562, 0.4330127])\n</code></pre> <p>You can also use the :code:<code>keepdims</code> argument to keep the dimensions after the standard deviation.</p> <pre><code>&gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n&gt;&gt;&gt; s3.shape\n(1, 4)\n</code></pre> <p>You can pass in an output datatype, if needed.</p> <pre><code>&gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n&gt;&gt;&gt; s4.dtype\ndtype('float16')\n</code></pre> <p>By default, this reduces the array down to one number, computing the standard deviation along all axes.</p> <pre><code>&gt;&gt;&gt; s.std()\n0.7071067811865476\n</code></pre> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \"\"\"\n    Compute the standard deviation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the standard deviation. Uses\n        all axes by default.\n    dtype : numpy.dtype, optional\n        The output datatype.\n    out : SparseArray, optional\n        The array to write the output to.\n    ddof : int\n        The degrees of freedom.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n\n    Returns\n    -------\n    SparseArray\n        The reduced output sparse array.\n\n    See Also\n    --------\n    numpy.ndarray.std : Equivalent numpy method.\n\n    Notes\n    -----\n    * This function internally calls :obj:`COO.sum_duplicates` to bring the\n      array into canonical form.\n\n    Examples\n    --------\n    You can use :obj:`COO.std` to compute the standard deviation of an array\n    across any dimension.\n\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = np.array([[1, 2, 0, 0], [0, 1, 0, 0]], dtype=\"i8\")\n    &gt;&gt;&gt; s = COO.from_numpy(x)\n    &gt;&gt;&gt; s2 = s.std(axis=1)\n    &gt;&gt;&gt; s2.todense()  # doctest: +SKIP\n    array([0.8291562, 0.4330127])\n\n    You can also use the :code:`keepdims` argument to keep the dimensions\n    after the standard deviation.\n\n    &gt;&gt;&gt; s3 = s.std(axis=0, keepdims=True)\n    &gt;&gt;&gt; s3.shape\n    (1, 4)\n\n    You can pass in an output datatype, if needed.\n\n    &gt;&gt;&gt; s4 = s.std(axis=0, dtype=np.float16)\n    &gt;&gt;&gt; s4.dtype\n    dtype('float16')\n\n    By default, this reduces the array down to one number, computing the\n    standard deviation along all axes.\n\n    &gt;&gt;&gt; s.std()  # doctest: +SKIP\n    0.7071067811865476\n    \"\"\"\n    ret = self.var(axis=axis, dtype=dtype, out=out, ddof=ddof, keepdims=keepdims)\n\n    return np.sqrt(ret)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.conj","title":"<code>conj()</code>","text":"<p>Return the complex conjugate, element-wise.</p> <p>The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import COO\n&gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n&gt;&gt;&gt; res = x.conj()\n&gt;&gt;&gt; res.todense()\narray([1.-2.j, 2.+1.j])\n&gt;&gt;&gt; res.dtype\ndtype('complex128')\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>The complex conjugate, with same dtype as the input.</p> See Also <p>numpy.ndarray.conj : NumPy equivalent method. numpy.conj : NumPy equivalent function.</p> Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>def conj(self):\n    \"\"\"Return the complex conjugate, element-wise.\n\n    The complex conjugate of a complex number is obtained by changing the\n    sign of its imaginary part.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sparse import COO\n    &gt;&gt;&gt; x = COO.from_numpy([1 + 2j, 2 - 1j])\n    &gt;&gt;&gt; res = x.conj()\n    &gt;&gt;&gt; res.todense()  # doctest: +SKIP\n    array([1.-2.j, 2.+1.j])\n    &gt;&gt;&gt; res.dtype\n    dtype('complex128')\n\n    Returns\n    -------\n    out : SparseArray\n        The complex conjugate, with same dtype as the input.\n\n    See Also\n    --------\n    numpy.ndarray.conj : NumPy equivalent method.\n    numpy.conj : NumPy equivalent function.\n    \"\"\"\n    return np.conj(self)\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.isinf","title":"<code>isinf()</code>  <code>abstractmethod</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>@abstractmethod\ndef isinf(self):\n    \"\"\" \"\"\"\n</code></pre>"},{"location":"api/SparseArray/#sparse.SparseArray.isnan","title":"<code>isnan()</code>  <code>abstractmethod</code>","text":"Source code in <code>sparse/numba_backend/_sparse_array.py</code> <pre><code>@abstractmethod\ndef isnan(self):\n    \"\"\" \"\"\"\n</code></pre>"},{"location":"api/abs/","title":"abs","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def abs(x, /):\n    return x.__abs__()\n</code></pre>"},{"location":"api/all/","title":"all","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def all(x, /, *, axis=None, keepdims=False):\n    return x.all(axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/any/","title":"any","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def any(x, /, *, axis=None, keepdims=False):\n    return x.any(axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/argmax/","title":"argmax","text":"<p>Returns the indices of the maximum values along a specified axis. When the maximum value occurs multiple times, only the indices corresponding to the first occurrence are returned.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>Input array. The fill value must be <code>0.0</code> and all non-zero values must be greater than <code>0.0</code>.</p> required <code>axis</code> <code>int</code> <p>Axis along which to search. If <code>None</code>, the function must return the index of the maximum value of the flattened array. Default: <code>None</code>.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>If <code>True</code>, the reduced axes (dimensions) must be included in the result as singleton dimensions, and, accordingly, the result must be compatible with the input array. Otherwise, if <code>False</code>, the reduced axes (dimensions) must not be included in the result. Default: <code>False</code>.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>If <code>axis</code> is <code>None</code>, a zero-dimensional array containing the index of the first occurrence of the maximum value. Otherwise, a non-zero-dimensional array containing the indices of the maximum values.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def argmax(x, /, *, axis=None, keepdims=False):\n    \"\"\"\n    Returns the indices of the maximum values along a specified axis.\n    When the maximum value occurs multiple times, only the indices\n    corresponding to the first occurrence are returned.\n\n    Parameters\n    ----------\n    x : SparseArray\n        Input array. The fill value must be ``0.0`` and all non-zero values\n        must be greater than ``0.0``.\n    axis : int, optional\n        Axis along which to search. If ``None``, the function must return\n        the index of the maximum value of the flattened array. Default: ``None``.\n    keepdims : bool, optional\n        If ``True``, the reduced axes (dimensions) must be included in the result\n        as singleton dimensions, and, accordingly, the result must be compatible\n        with the input array. Otherwise, if ``False``, the reduced axes (dimensions)\n        must not be included in the result. Default: ``False``.\n\n    Returns\n    -------\n    out : numpy.ndarray\n        If ``axis`` is ``None``, a zero-dimensional array containing the index of\n        the first occurrence of the maximum value. Otherwise, a non-zero-dimensional\n        array containing the indices of the maximum values.\n    \"\"\"\n    return _arg_minmax_common(x, axis=axis, keepdims=keepdims, mode=\"max\")\n</code></pre>"},{"location":"api/argmin/","title":"argmin","text":"<p>Returns the indices of the minimum values along a specified axis. When the minimum value occurs multiple times, only the indices corresponding to the first occurrence are returned.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>Input array. The fill value must be <code>0.0</code> and all non-zero values must be less than <code>0.0</code>.</p> required <code>axis</code> <code>int</code> <p>Axis along which to search. If <code>None</code>, the function must return the index of the minimum value of the flattened array. Default: <code>None</code>.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>If <code>True</code>, the reduced axes (dimensions) must be included in the result as singleton dimensions, and, accordingly, the result must be compatible with the input array. Otherwise, if <code>False</code>, the reduced axes (dimensions) must not be included in the result. Default: <code>False</code>.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>If <code>axis</code> is <code>None</code>, a zero-dimensional array containing the index of the first occurrence of the minimum value. Otherwise, a non-zero-dimensional array containing the indices of the minimum values.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def argmin(x, /, *, axis=None, keepdims=False):\n    \"\"\"\n    Returns the indices of the minimum values along a specified axis.\n    When the minimum value occurs multiple times, only the indices\n    corresponding to the first occurrence are returned.\n\n    Parameters\n    ----------\n    x : SparseArray\n        Input array. The fill value must be ``0.0`` and all non-zero values\n        must be less than ``0.0``.\n    axis : int, optional\n        Axis along which to search. If ``None``, the function must return\n        the index of the minimum value of the flattened array. Default: ``None``.\n    keepdims : bool, optional\n        If ``True``, the reduced axes (dimensions) must be included in the result\n        as singleton dimensions, and, accordingly, the result must be compatible\n        with the input array. Otherwise, if ``False``, the reduced axes (dimensions)\n        must not be included in the result. Default: ``False``.\n\n    Returns\n    -------\n    out : numpy.ndarray\n        If ``axis`` is ``None``, a zero-dimensional array containing the index of\n        the first occurrence of the minimum value. Otherwise, a non-zero-dimensional\n        array containing the indices of the minimum values.\n    \"\"\"\n    return _arg_minmax_common(x, axis=axis, keepdims=keepdims, mode=\"min\")\n</code></pre>"},{"location":"api/argwhere/","title":"argwhere","text":"<p>Find the indices of array elements that are non-zero, grouped by element.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Input data.</p> required <p>Returns:</p> Name Type Description <code>index_array</code> <code>ndarray</code> See Also <p>where, COO.nonzero</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.COO(np.arange(6).reshape((2, 3)))\n&gt;&gt;&gt; sparse.argwhere(x &gt; 1)\narray([[0, 2],\n       [1, 0],\n       [1, 1],\n       [1, 2]])\n</code></pre> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def argwhere(a):\n    \"\"\"\n    Find the indices of array elements that are non-zero, grouped by element.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n\n    Returns\n    -------\n    index_array : numpy.ndarray\n\n    See Also\n    --------\n    [where][sparse.where], [COO.nonzero][sparse.COO.nonzero]\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.COO(np.arange(6).reshape((2, 3)))\n    &gt;&gt;&gt; sparse.argwhere(x &gt; 1)\n    array([[0, 2],\n           [1, 0],\n           [1, 1],\n           [1, 2]])\n    \"\"\"\n    return np.transpose(a.nonzero())\n</code></pre>"},{"location":"api/asCOO/","title":"asCOO","text":"<p>Convert the input to :obj:<code>COO</code>. Passes through :obj:<code>COO</code> objects as-is.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[SparseArray, spmatrix, ndarray]</code> <p>The input array to convert.</p> required <code>name</code> <code>str</code> <p>The name of the operation to use in the exception.</p> <code>'asCOO'</code> <code>check</code> <code>bool_</code> <p>Whether to check for a dense input.</p> <code>True</code> <p>Returns:</p> Type Description <code>COO</code> <p>The converted :obj:<code>COO</code> array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>check</code> is true and a dense input is supplied.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def asCOO(x, name=\"asCOO\", check=True):\n    \"\"\"\n    Convert the input to :obj:`COO`. Passes through :obj:`COO` objects as-is.\n\n    Parameters\n    ----------\n    x : Union[SparseArray, scipy.sparse.spmatrix, numpy.ndarray]\n        The input array to convert.\n    name : str, optional\n        The name of the operation to use in the exception.\n    check : bool, optional\n        Whether to check for a dense input.\n\n    Returns\n    -------\n    COO\n        The converted :obj:`COO` array.\n\n    Raises\n    ------\n    ValueError\n        If ``check`` is true and a dense input is supplied.\n    \"\"\"\n    from .._common import _is_sparse\n    from .core import COO\n\n    if check and not _is_sparse(x):\n        raise ValueError(f\"Performing this operation would produce a dense result: {name}\")\n\n    if not isinstance(x, COO):\n        x = COO(x)\n\n    return x\n</code></pre>"},{"location":"api/as_coo/","title":"as_coo","text":"<p>Converts any given format to :obj:<code>COO</code>. See the \"See Also\" section for details.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray or numpy.ndarray or scipy.sparse.spmatrix or Iterable.</code> <p>The item to convert.</p> required <code>shape</code> <code>tuple[int]</code> <p>The shape of the output array. Can only be used in case of Iterable.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>COO</code> <p>The converted :obj:<code>COO</code> array.</p> See Also <p>SparseArray.asformat :     A utility function to convert between formats in this library. COO.from_numpy :     Convert a Numpy array to :obj:<code>COO</code>. COO.from_scipy_sparse :     Convert a SciPy sparse matrix to :obj:<code>COO</code>. COO.from_iter :     Convert an iterable to :obj:<code>COO</code>.</p> Source code in <code>sparse/numba_backend/_coo/core.py</code> <pre><code>def as_coo(x, shape=None, fill_value=None, idx_dtype=None):\n    \"\"\"\n    Converts any given format to :obj:`COO`. See the \"See Also\" section for details.\n\n    Parameters\n    ----------\n    x : SparseArray or numpy.ndarray or scipy.sparse.spmatrix or Iterable.\n        The item to convert.\n    shape : tuple[int], optional\n        The shape of the output array. Can only be used in case of Iterable.\n\n    Returns\n    -------\n    out : COO\n        The converted :obj:`COO` array.\n\n    See Also\n    --------\n    SparseArray.asformat :\n        A utility function to convert between formats in this library.\n    COO.from_numpy :\n        Convert a Numpy array to :obj:`COO`.\n    COO.from_scipy_sparse :\n        Convert a SciPy sparse matrix to :obj:`COO`.\n    COO.from_iter :\n        Convert an iterable to :obj:`COO`.\n    \"\"\"\n    from .._common import _is_scipy_sparse_obj\n\n    if hasattr(x, \"shape\") and shape is not None:\n        raise ValueError(\"Cannot provide a shape in combination with something that already has a shape.\")\n\n    if hasattr(x, \"fill_value\") and fill_value is not None:\n        raise ValueError(\"Cannot provide a fill-value in combination with something that already has a fill-value.\")\n\n    if isinstance(x, SparseArray):\n        return x.asformat(\"coo\")\n\n    if isinstance(x, np.ndarray) or np.isscalar(x):\n        return COO.from_numpy(x, fill_value=fill_value, idx_dtype=idx_dtype)\n\n    if _is_scipy_sparse_obj(x):\n        return COO.from_scipy_sparse(x)\n\n    if isinstance(x, Iterable | Iterator):\n        return COO.from_iter(x, shape=shape, fill_value=fill_value)\n\n    raise NotImplementedError(\n        f\"Format not supported for conversion. Supplied type is \"\n        f\"{type(x)}, see help(sparse.as_coo) for supported formats.\"\n    )\n</code></pre>"},{"location":"api/asarray/","title":"asarray","text":"<p>Convert the input to a sparse array.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>array_like</code> <p>Object to be converted to an array.</p> required <code>dtype</code> <code>dtype</code> <p>Output array data type.</p> <code>None</code> <code>format</code> <code>str</code> <p>Output array sparse format.</p> <code>'coo'</code> <code>device</code> <code>str</code> <p>Device on which to place the created array.</p> <code>None</code> <code>copy</code> <code>bool_</code> <p>Boolean indicating whether or not to copy the input.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>out</code> <code>Union[SparseArray, ndarray]</code> <p>Sparse or 0-D array containing the data from <code>obj</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.eye(8, dtype=\"i8\")\n&gt;&gt;&gt; sparse.asarray(x, format=\"COO\")\n&lt;COO: shape=(8, 8), dtype=int64, nnz=8, fill_value=0&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_check_device\ndef asarray(obj, /, *, dtype=None, format=\"coo\", copy=False, device=None):\n    \"\"\"\n    Convert the input to a sparse array.\n\n    Parameters\n    ----------\n    obj : array_like\n        Object to be converted to an array.\n    dtype : dtype, optional\n        Output array data type.\n    format : str, optional\n        Output array sparse format.\n    device : str, optional\n        Device on which to place the created array.\n    copy : bool, optional\n        Boolean indicating whether or not to copy the input.\n\n    Returns\n    -------\n    out : Union[SparseArray, numpy.ndarray]\n        Sparse or 0-D array containing the data from `obj`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.eye(8, dtype=\"i8\")\n    &gt;&gt;&gt; sparse.asarray(x, format=\"COO\")\n    &lt;COO: shape=(8, 8), dtype=int64, nnz=8, fill_value=0&gt;\n    \"\"\"\n\n    if format not in {\"coo\", \"dok\", \"gcxs\", \"csc\", \"csr\"}:\n        raise ValueError(f\"{format} format not supported.\")\n\n    from ._compressed import CSC, CSR, GCXS\n    from ._coo import COO\n    from ._dok import DOK\n\n    format_dict = {\"coo\": COO, \"dok\": DOK, \"gcxs\": GCXS, \"csc\": CSC, \"csr\": CSR}\n\n    if isinstance(obj, COO | DOK | GCXS | CSC | CSR):\n        return obj.asformat(format)\n\n    if _is_scipy_sparse_obj(obj):\n        sparse_obj = format_dict[format].from_scipy_sparse(obj)\n        if dtype is None:\n            dtype = sparse_obj.dtype\n        return sparse_obj.astype(dtype=dtype, copy=copy)\n\n    if np.isscalar(obj) or isinstance(obj, np.ndarray | Iterable):\n        sparse_obj = format_dict[format].from_numpy(np.asarray(obj))\n        if dtype is None:\n            dtype = sparse_obj.dtype\n        return sparse_obj.astype(dtype=dtype, copy=copy)\n\n    raise ValueError(f\"{type(obj)} not supported.\")\n</code></pre>"},{"location":"api/asnumpy/","title":"asnumpy","text":"<p>Returns a dense numpy array from an arbitrary source array.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <p>Arbitrary object that can be converted to numpy.ndarray.</p> required <code>order</code> <p>The desired memory layout of the output array. When <code>order</code> is 'A', it uses 'F' if <code>a</code> is fortran-contiguous and 'C' otherwise.</p> <code>None</code> <p>Returns:</p> Type Description <code>numpy.ndarray: Converted array on the host memory.</code> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def asnumpy(a, dtype=None, order=None):\n    \"\"\"Returns a dense numpy array from an arbitrary source array.\n\n    Parameters\n    ----------\n    a: array_like\n       Arbitrary object that can be converted to [numpy.ndarray][].\n    order: ({'C', 'F', 'A'})\n       The desired memory layout of the output\n       array. When ``order`` is 'A', it uses 'F' if ``a`` is\n       fortran-contiguous and 'C' otherwise.\n\n    Returns\n    -------\n    numpy.ndarray: Converted array on the host memory.\n    \"\"\"\n    from ._sparse_array import SparseArray\n\n    if isinstance(a, SparseArray):\n        a = a.todense()\n    return np.asarray(a, dtype=dtype, order=order)\n</code></pre>"},{"location":"api/astype/","title":"astype","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def astype(x, dtype, /, *, copy=True):\n    return x.astype(dtype, copy=copy)\n</code></pre>"},{"location":"api/broadcast_arrays/","title":"broadcast_arrays","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def broadcast_arrays(*arrays):\n    shape = np.broadcast_shapes(*[a.shape for a in arrays])\n    return [a.broadcast_to(shape) for a in arrays]\n</code></pre>"},{"location":"api/broadcast_to/","title":"broadcast_to","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_support_numpy\ndef broadcast_to(x, /, shape):\n    return x.broadcast_to(shape)\n</code></pre>"},{"location":"api/clip/","title":"clip","text":"<p>Clip (limit) the values in the array.</p> <p>Return an array whose values are limited to <code>[min, max]</code>. One of min or max must be given.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> required <code>a_min</code> <code>scalar or `SparseArray` or `None`</code> <p>Minimum value. If <code>None</code>, clipping is not performed on lower interval edge.</p> <code>None</code> <code>a_max</code> <code>scalar or `SparseArray` or `None`</code> <p>Maximum value. If <code>None</code>, clipping is not performed on upper interval edge.</p> <code>None</code> <code>out</code> <code>SparseArray</code> <p>If provided, the results will be placed in this array. It may be the input array for in-place clipping. <code>out</code> must be of the right shape to hold the output. Its type is preserved.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>clipped_array</code> <code>SparseArray</code> <p>An array with the elements of <code>self</code>, but where values &lt; <code>min</code> are replaced with <code>min</code>, and those &gt; <code>max</code> with <code>max</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.COO.from_numpy([0, 0, 0, 1, 2, 3])\n&gt;&gt;&gt; sparse.clip(x, a_min=1).todense()\narray([1, 1, 1, 1, 2, 3])\n&gt;&gt;&gt; sparse.clip(x, a_max=1).todense()\narray([0, 0, 0, 1, 1, 1])\n&gt;&gt;&gt; sparse.clip(x, a_min=1, a_max=2).todense()\narray([1, 1, 1, 1, 2, 2])\n</code></pre> See Also <p>numpy.clip : Equivalent NumPy function</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def clip(a, a_min=None, a_max=None, out=None):\n    \"\"\"\n    Clip (limit) the values in the array.\n\n    Return an array whose values are limited to ``[min, max]``. One of min\n    or max must be given.\n\n    Parameters\n    ----------\n    a\n    a_min : scalar or `SparseArray` or `None`\n        Minimum value. If `None`, clipping is not performed on lower\n        interval edge.\n    a_max : scalar or `SparseArray` or `None`\n        Maximum value. If `None`, clipping is not performed on upper\n        interval edge.\n    out : SparseArray, optional\n        If provided, the results will be placed in this array. It may be\n        the input array for in-place clipping. `out` must be of the right\n        shape to hold the output. Its type is preserved.\n\n    Returns\n    -------\n    clipped_array : SparseArray\n        An array with the elements of `self`, but where values &lt; `min` are\n        replaced with `min`, and those &gt; `max` with `max`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.COO.from_numpy([0, 0, 0, 1, 2, 3])\n    &gt;&gt;&gt; sparse.clip(x, a_min=1).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([1, 1, 1, 1, 2, 3])\n    &gt;&gt;&gt; sparse.clip(x, a_max=1).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([0, 0, 0, 1, 1, 1])\n    &gt;&gt;&gt; sparse.clip(x, a_min=1, a_max=2).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([1, 1, 1, 1, 2, 2])\n\n    See Also\n    --------\n    numpy.clip : Equivalent NumPy function\n    \"\"\"\n    a = asCOO(a, name=\"clip\")\n    return a.clip(a_min, a_max)\n</code></pre>"},{"location":"api/concat/","title":"concat","text":""},{"location":"api/concatenate/","title":"concatenate","text":"<p>Concatenate the input arrays along the given dimension.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[SparseArray]</code> <p>The input arrays to concatenate.</p> required <code>axis</code> <code>int</code> <p>The axis along which to concatenate the input arrays. The default is zero.</p> <code>0</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The output concatenated array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all elements of :code:<code>arrays</code> don't have the same fill-value.</p> See Also <p>numpy.concatenate : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def concatenate(arrays, axis=0, compressed_axes=None):\n    \"\"\"\n    Concatenate the input arrays along the given dimension.\n\n    Parameters\n    ----------\n    arrays : Iterable[SparseArray]\n        The input arrays to concatenate.\n    axis : int, optional\n        The axis along which to concatenate the input arrays. The default is zero.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n\n    Returns\n    -------\n    SparseArray\n        The output concatenated array.\n\n    Raises\n    ------\n    ValueError\n        If all elements of :code:`arrays` don't have the same fill-value.\n\n    See Also\n    --------\n    numpy.concatenate : NumPy equivalent function\n    \"\"\"\n    from ._compressed import GCXS\n\n    if not builtins.all(isinstance(arr, GCXS) for arr in arrays):\n        from ._coo import concatenate as coo_concat\n\n        return coo_concat(arrays, axis)\n\n    from ._compressed import concatenate as gcxs_concat\n\n    return gcxs_concat(arrays, axis, compressed_axes)\n</code></pre>"},{"location":"api/diagonal/","title":"diagonal","text":"<p>Extract diagonal from a COO array. The equivalent of :obj:<code>numpy.diagonal</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>COO</code> <p>The array to perform the operation on.</p> required <code>offset</code> <code>int</code> <p>Offset of the diagonal from the main diagonal. Defaults to main diagonal (0).</p> <code>0</code> <code>axis1</code> <code>int</code> <p>First axis from which the diagonals should be taken. Defaults to first axis (0).</p> <code>0</code> <code>axis2</code> <code>int</code> <p>Second axis from which the diagonals should be taken. Defaults to second axis (1).</p> <code>1</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.as_coo(np.arange(9).reshape(3, 3))\n&gt;&gt;&gt; sparse.diagonal(x).todense()\narray([0, 4, 8])\n&gt;&gt;&gt; sparse.diagonal(x, offset=1).todense()\narray([1, 5])\n</code></pre> <pre><code>&gt;&gt;&gt; x = sparse.as_coo(np.arange(12).reshape((2, 3, 2)))\n&gt;&gt;&gt; x_diag = sparse.diagonal(x, axis1=0, axis2=2)\n&gt;&gt;&gt; x_diag.shape\n(3, 2)\n&gt;&gt;&gt; x_diag.todense()\narray([[ 0,  7],\n       [ 2,  9],\n       [ 4, 11]])\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>COO</code> <p>The result of the operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a.shape[axis1] != a.shape[axis2]</p> See Also <p>:obj:<code>numpy.diagonal</code> : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def diagonal(a, offset=0, axis1=0, axis2=1):\n    \"\"\"\n    Extract diagonal from a COO array. The equivalent of :obj:`numpy.diagonal`.\n\n    Parameters\n    ----------\n    a : COO\n        The array to perform the operation on.\n    offset : int, optional\n        Offset of the diagonal from the main diagonal. Defaults to main diagonal (0).\n    axis1 : int, optional\n        First axis from which the diagonals should be taken.\n        Defaults to first axis (0).\n    axis2 : int, optional\n        Second axis from which the diagonals should be taken.\n        Defaults to second axis (1).\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.as_coo(np.arange(9).reshape(3, 3))\n    &gt;&gt;&gt; sparse.diagonal(x).todense()\n    array([0, 4, 8])\n    &gt;&gt;&gt; sparse.diagonal(x, offset=1).todense()\n    array([1, 5])\n\n    &gt;&gt;&gt; x = sparse.as_coo(np.arange(12).reshape((2, 3, 2)))\n    &gt;&gt;&gt; x_diag = sparse.diagonal(x, axis1=0, axis2=2)\n    &gt;&gt;&gt; x_diag.shape\n    (3, 2)\n    &gt;&gt;&gt; x_diag.todense()\n    array([[ 0,  7],\n           [ 2,  9],\n           [ 4, 11]])\n\n    Returns\n    -------\n    out: COO\n        The result of the operation.\n\n    Raises\n    ------\n    ValueError\n        If a.shape[axis1] != a.shape[axis2]\n\n    See Also\n    --------\n    :obj:`numpy.diagonal` : NumPy equivalent function\n    \"\"\"\n    from .core import COO\n\n    if a.shape[axis1] != a.shape[axis2]:\n        raise ValueError(\"a.shape[axis1] != a.shape[axis2]\")\n\n    diag_axes = [axis for axis in range(len(a.shape)) if axis != axis1 and axis != axis2] + [axis1]\n    diag_shape = [a.shape[axis] for axis in diag_axes]\n    diag_shape[-1] -= abs(offset)\n\n    diag_idx = _diagonal_idx(a.coords, axis1, axis2, offset)\n\n    diag_coords = [a.coords[axis][diag_idx] for axis in diag_axes]\n    diag_data = a.data[diag_idx]\n\n    return COO(diag_coords, diag_data, diag_shape)\n</code></pre>"},{"location":"api/diagonalize/","title":"diagonalize","text":"<p>Diagonalize a COO array. The new dimension is appended at the end.</p> <p>.. WARNING:: :obj:<code>diagonalize</code> is not :obj:<code>numpy</code> compatible as there is no direct :obj:<code>numpy</code> equivalent. The   API may change in the future.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[COO, ndarray, spmatrix]</code> <p>The array to diagonalize.</p> required <code>axis</code> <code>int</code> <p>The axis to diagonalize. Defaults to first axis (0).</p> <code>0</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.as_coo(np.arange(1, 4))\n&gt;&gt;&gt; sparse.diagonalize(x).todense()\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])\n</code></pre> <pre><code>&gt;&gt;&gt; x = sparse.as_coo(np.arange(24).reshape((2, 3, 4)))\n&gt;&gt;&gt; x_diag = sparse.diagonalize(x, axis=1)\n&gt;&gt;&gt; x_diag.shape\n(2, 3, 4, 3)\n</code></pre> <p>:obj:<code>diagonalize</code> is the inverse of :obj:<code>diagonal</code></p> <pre><code>&gt;&gt;&gt; a = sparse.random((3, 3, 3, 3, 3), density=0.3)\n&gt;&gt;&gt; a_diag = sparse.diagonalize(a, axis=2)\n&gt;&gt;&gt; (sparse.diagonal(a_diag, axis1=2, axis2=5) == a.transpose([0, 1, 3, 4, 2])).all()\nTrue\n</code></pre> <p>Returns:</p> Name Type Description <code>out</code> <code>COO</code> <p>The result of the operation.</p> See Also <p>:obj:<code>numpy.diag</code> : NumPy equivalent for 1D array</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def diagonalize(a, axis=0):\n    \"\"\"\n    Diagonalize a COO array. The new dimension is appended at the end.\n\n    .. WARNING:: :obj:`diagonalize` is not :obj:`numpy` compatible as there is no direct :obj:`numpy` equivalent. The\n      API may change in the future.\n\n    Parameters\n    ----------\n    a : Union[COO, np.ndarray, scipy.sparse.spmatrix]\n        The array to diagonalize.\n    axis : int, optional\n        The axis to diagonalize. Defaults to first axis (0).\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.as_coo(np.arange(1, 4))\n    &gt;&gt;&gt; sparse.diagonalize(x).todense()\n    array([[1, 0, 0],\n           [0, 2, 0],\n           [0, 0, 3]])\n\n    &gt;&gt;&gt; x = sparse.as_coo(np.arange(24).reshape((2, 3, 4)))\n    &gt;&gt;&gt; x_diag = sparse.diagonalize(x, axis=1)\n    &gt;&gt;&gt; x_diag.shape\n    (2, 3, 4, 3)\n\n    :obj:`diagonalize` is the inverse of :obj:`diagonal`\n\n    &gt;&gt;&gt; a = sparse.random((3, 3, 3, 3, 3), density=0.3)\n    &gt;&gt;&gt; a_diag = sparse.diagonalize(a, axis=2)\n    &gt;&gt;&gt; (sparse.diagonal(a_diag, axis1=2, axis2=5) == a.transpose([0, 1, 3, 4, 2])).all()\n    True\n\n    Returns\n    -------\n    out: COO\n        The result of the operation.\n\n    See Also\n    --------\n    :obj:`numpy.diag` : NumPy equivalent for 1D array\n    \"\"\"\n    from .core import COO, as_coo\n\n    a = as_coo(a)\n\n    diag_shape = a.shape + (a.shape[axis],)\n    diag_coords = np.vstack([a.coords, a.coords[axis]])\n\n    return COO(diag_coords, a.data, diag_shape)\n</code></pre>"},{"location":"api/dot/","title":"dot","text":"<p>Perform the equivalent of :obj:<code>numpy.dot</code> on two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[SparseArray, ndarray, spmatrix]</code> <p>The arrays to perform the :code:<code>dot</code> operation on.</p> required <code>b</code> <code>Union[SparseArray, ndarray, spmatrix]</code> <p>The arrays to perform the :code:<code>dot</code> operation on.</p> required <p>Returns:</p> Type Description <code>Union[SparseArray, ndarray]</code> <p>The result of the operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all arguments don't have zero fill-values.</p> See Also <p>numpy.dot : NumPy equivalent function. COO.dot : Equivalent function for COO objects.</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def dot(a, b):\n    \"\"\"\n    Perform the equivalent of :obj:`numpy.dot` on two arrays.\n\n    Parameters\n    ----------\n    a, b : Union[SparseArray, np.ndarray, scipy.sparse.spmatrix]\n        The arrays to perform the :code:`dot` operation on.\n\n    Returns\n    -------\n    Union[SparseArray, numpy.ndarray]\n        The result of the operation.\n\n    Raises\n    ------\n    ValueError\n        If all arguments don't have zero fill-values.\n\n    See Also\n    --------\n    numpy.dot : NumPy equivalent function.\n    COO.dot : Equivalent function for COO objects.\n    \"\"\"\n    check_zero_fill_value(a, b)\n    if not hasattr(a, \"ndim\") or not hasattr(b, \"ndim\"):\n        raise TypeError(f\"Cannot perform dot product on types {type(a)}, {type(b)}\")\n\n    if a.ndim == 1 and b.ndim == 1:\n        if isinstance(a, SparseArray):\n            a = asCOO(a)\n        if isinstance(b, SparseArray):\n            b = asCOO(b)\n        return (a * b).sum()\n\n    a_axis = -1\n    b_axis = -2\n\n    if b.ndim == 1:\n        b_axis = -1\n    return tensordot(a, b, axes=(a_axis, b_axis))\n</code></pre>"},{"location":"api/einsum/","title":"einsum","text":"<p>Perform the equivalent of :obj:<code>numpy.einsum</code>.</p> <p>Parameters:</p> Name Type Description Default <code>subscripts</code> <code>str</code> <p>Specifies the subscripts for summation as comma separated list of subscript labels. An implicit (classical Einstein summation) calculation is performed unless the explicit indicator '-&gt;' is included as well as subscript labels of the precise output form.</p> required <code>operands</code> <code>sequence of SparseArray</code> <p>These are the arrays for the operation.</p> <code>()</code> <code>dtype</code> <code>data - type</code> <p>If provided, forces the calculation to use the data type specified. Default is <code>None</code>.</p> required <code>**kwargs</code> <code>dict</code> <p>Any additional arguments to pass to the function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>output</code> <code>SparseArray</code> <p>The calculation based on the Einstein summation convention.</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def einsum(*operands, **kwargs):\n    \"\"\"\n    Perform the equivalent of :obj:`numpy.einsum`.\n\n    Parameters\n    ----------\n    subscripts : str\n        Specifies the subscripts for summation as comma separated list of\n        subscript labels. An implicit (classical Einstein summation)\n        calculation is performed unless the explicit indicator '-&gt;' is\n        included as well as subscript labels of the precise output form.\n    operands : sequence of SparseArray\n        These are the arrays for the operation.\n    dtype : data-type, optional\n        If provided, forces the calculation to use the data type specified.\n        Default is ``None``.\n    **kwargs : dict, optional\n        Any additional arguments to pass to the function.\n\n    Returns\n    -------\n    output : SparseArray\n        The calculation based on the Einstein summation convention.\n    \"\"\"\n\n    lhs, rhs, operands = _parse_einsum_input(operands)  # Parse input\n\n    check_zero_fill_value(*operands)\n\n    if \"dtype\" in kwargs and kwargs[\"dtype\"] is not None:\n        operands = [o.astype(kwargs[\"dtype\"]) for o in operands]\n\n    if len(operands) == 1:\n        return _einsum_single(lhs, rhs, operands[0])\n\n    # if multiple arrays: align, broadcast multiply and then use single einsum\n    # for example:\n    #     \"aab,cbd-&gt;dac\"\n    # we first perform single term reductions and align:\n    #     aab -&gt; ab..\n    #     cbd -&gt; .bcd\n    # (where dots represent broadcastable size 1 dimensions), then multiply all\n    # to form the 'minimal outer product' and do a final single term einsum:\n    #     abcd -&gt; dac\n\n    # get ordered union of indices from all terms, indicies that only appear\n    # on a single term will be removed in the 'preparation' step below\n    terms = lhs.split(\",\")\n    total = {}\n    sizes = {}\n    for t, term in enumerate(terms):\n        shape = operands[t].shape\n        for ix, d in zip(term, shape, strict=False):\n            if d != sizes.setdefault(ix, d):\n                raise ValueError(f\"Inconsistent shape for index '{ix}'.\")\n            total.setdefault(ix, set()).add(t)\n    for ix in rhs:\n        total[ix].add(-1)\n    aligned_term = \"\".join(ix for ix, apps in total.items() if len(apps) &gt; 1)\n\n    # NB: if every index appears exactly twice,\n    # we could identify and dispatch to tensordot here?\n\n    parrays = []\n    for term, array in zip(terms, operands, strict=True):\n        # calc the target indices for this term\n        pterm = \"\".join(ix for ix in aligned_term if ix in term)\n        if pterm != term:\n            # perform necessary transpose and reductions\n            array = _einsum_single(term, pterm, array)\n        # calc broadcastable shape\n        shape = tuple(array.shape[pterm.index(ix)] if ix in pterm else 1 for ix in aligned_term)\n        parrays.append(array.reshape(shape) if array.shape != shape else array)\n\n    aligned_array = reduce(mul, parrays)\n\n    return _einsum_single(aligned_term, rhs, aligned_array)\n</code></pre>"},{"location":"api/elemwise/","title":"elemwise","text":"<p>Apply a function to any number of arguments.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>The function to apply. Must support broadcasting.</p> required <code>*args</code> <code>tuple</code> <p>The arguments to the function. Can be :obj:<code>SparseArray</code> objects or :obj:<code>scipy.sparse.spmatrix</code> objects.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Any additional arguments to pass to the function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The result of applying the function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the operation would result in a dense matrix, or if the operands don't have broadcastable shapes.</p> See Also <p>:obj:<code>numpy.ufunc</code> :     A similar Numpy construct. Note that any :code:<code>ufunc</code> can be used     as the :code:<code>func</code> input to this function.</p> Notes <p>Previously, operations with Numpy arrays were sometimes supported. Now, it is necessary to convert Numpy arrays to :obj:<code>COO</code> objects.</p> Source code in <code>sparse/numba_backend/_umath.py</code> <pre><code>def elemwise(func, *args, **kwargs):\n    \"\"\"\n    Apply a function to any number of arguments.\n\n    Parameters\n    ----------\n    func : Callable\n        The function to apply. Must support broadcasting.\n    *args : tuple, optional\n        The arguments to the function. Can be :obj:`SparseArray` objects\n        or :obj:`scipy.sparse.spmatrix` objects.\n    **kwargs : dict, optional\n        Any additional arguments to pass to the function.\n\n    Returns\n    -------\n    SparseArray\n        The result of applying the function.\n\n    Raises\n    ------\n    ValueError\n        If the operation would result in a dense matrix, or if the operands\n        don't have broadcastable shapes.\n\n    See Also\n    --------\n    :obj:`numpy.ufunc` :\n        A similar Numpy construct. Note that any :code:`ufunc` can be used\n        as the :code:`func` input to this function.\n\n    Notes\n    -----\n    Previously, operations with Numpy arrays were sometimes supported. Now,\n    it is necessary to convert Numpy arrays to :obj:`COO` objects.\n    \"\"\"\n\n    return _Elemwise(func, *args, **kwargs).get_result()\n</code></pre>"},{"location":"api/empty/","title":"empty","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def empty(shape, dtype=float, format=\"coo\", *, device=None, **kwargs):\n    return full(shape, fill_value=0, dtype=np.dtype(dtype), format=format, device=device, **kwargs)\n</code></pre>"},{"location":"api/empty_like/","title":"empty_like","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def empty_like(a, dtype=None, shape=None, format=None, *, device=None, **kwargs):\n    return full_like(a, fill_value=0, dtype=dtype, shape=shape, format=format, device=device, **kwargs)\n</code></pre>"},{"location":"api/equal/","title":"equal","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def equal(x1, x2, /):\n    return x1 == x2\n</code></pre>"},{"location":"api/expand_dims/","title":"expand_dims","text":"<p>Expands the shape of an array by inserting a new axis (dimension) of size one at the position specified by <code>axis</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>COO</code> <p>Input COO array.</p> required <code>axis</code> <code>int</code> <p>Position in the expanded axes where the new axis is placed.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>result</code> <code>COO</code> <p>An expanded output COO array having the same data type as <code>x</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.COO.from_numpy([[1, 0, 0, 0, 2, -3]])\n&gt;&gt;&gt; x.shape\n(1, 6)\n&gt;&gt;&gt; y1 = sparse.expand_dims(x, axis=1)\n&gt;&gt;&gt; y1.shape\n(1, 1, 6)\n&gt;&gt;&gt; y2 = sparse.expand_dims(x, axis=2)\n&gt;&gt;&gt; y2.shape\n(1, 6, 1)\n</code></pre> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def expand_dims(x, /, *, axis=0):\n    \"\"\"\n    Expands the shape of an array by inserting a new axis (dimension) of size\n    one at the position specified by ``axis``.\n\n    Parameters\n    ----------\n    a : COO\n        Input COO array.\n    axis : int\n        Position in the expanded axes where the new axis is placed.\n\n    Returns\n    -------\n    result : COO\n        An expanded output COO array having the same data type as ``x``.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.COO.from_numpy([[1, 0, 0, 0, 2, -3]])\n    &gt;&gt;&gt; x.shape\n    (1, 6)\n    &gt;&gt;&gt; y1 = sparse.expand_dims(x, axis=1)\n    &gt;&gt;&gt; y1.shape\n    (1, 1, 6)\n    &gt;&gt;&gt; y2 = sparse.expand_dims(x, axis=2)\n    &gt;&gt;&gt; y2.shape\n    (1, 6, 1)\n\n    \"\"\"\n\n    x = _validate_coo_input(x)\n\n    if not isinstance(axis, int):\n        raise IndexError(f\"Invalid axis position: {axis}\")\n\n    axis = normalize_axis(axis, x.ndim + 1)\n\n    new_coords = np.insert(x.coords, obj=axis, values=np.zeros(x.nnz, dtype=np.intp), axis=0)\n    new_shape = list(x.shape)\n    new_shape.insert(axis, 1)\n    new_shape = tuple(new_shape)\n\n    from .core import COO\n\n    return COO(\n        new_coords,\n        x.data,\n        shape=new_shape,\n        fill_value=x.fill_value,\n    )\n</code></pre>"},{"location":"api/eye/","title":"eye","text":"<p>Return a 2-D array in the specified format with ones on the diagonal and zeros elsewhere.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>int</code> <p>Number of rows in the output.</p> required <code>M</code> <code>int</code> <p>Number of columns in the output. If None, defaults to <code>N</code>.</p> <code>None</code> <code>k</code> <code>int</code> <p>Index of the diagonal: 0 (the default) refers to the main diagonal, a positive value refers to an upper diagonal, and a negative value to a lower diagonal.</p> <code>0</code> <code>dtype</code> <code>data - type</code> <p>Data-type of the returned array.</p> <code>float</code> <code>format</code> <code>str</code> <p>A format string.</p> <code>'coo'</code> <p>Returns:</p> Name Type Description <code>I</code> <code>SparseArray of shape (N, M)</code> <p>An array where all elements are equal to zero, except for the <code>k</code>-th diagonal, whose values are equal to one.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; eye(2, dtype=int).todense()\narray([[1, 0],\n       [0, 1]])\n&gt;&gt;&gt; eye(3, k=1).todense()\narray([[0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 0.]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_check_device\ndef eye(N, M=None, k=0, dtype=float, format=\"coo\", *, device=None, **kwargs):\n    \"\"\"Return a 2-D array in the specified format with ones on the diagonal and zeros elsewhere.\n\n    Parameters\n    ----------\n    N : int\n        Number of rows in the output.\n    M : int, optional\n        Number of columns in the output. If None, defaults to `N`.\n    k : int, optional\n        Index of the diagonal: 0 (the default) refers to the main diagonal,\n        a positive value refers to an upper diagonal, and a negative value\n        to a lower diagonal.\n    dtype : data-type, optional\n        Data-type of the returned array.\n    format : str, optional\n        A format string.\n\n    Returns\n    -------\n    I : SparseArray of shape (N, M)\n        An array where all elements are equal to zero, except for the `k`-th\n        diagonal, whose values are equal to one.\n\n    Examples\n    --------\n    &gt;&gt;&gt; eye(2, dtype=int).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[1, 0],\n           [0, 1]])\n    &gt;&gt;&gt; eye(3, k=1).todense()  # doctest: +SKIP\n    array([[0., 1., 0.],\n           [0., 0., 1.],\n           [0., 0., 0.]])\n    \"\"\"\n    from ._coo import COO\n\n    if M is None:\n        M = N\n\n    N = int(N)\n    M = int(M)\n    k = int(k)\n\n    data_length = builtins.min(N, M)\n\n    if k &gt; 0:\n        data_length = builtins.max(builtins.min(data_length, M - k), 0)\n        n_coords = np.arange(data_length, dtype=np.intp)\n        m_coords = n_coords + k\n    elif k &lt; 0:\n        data_length = builtins.max(builtins.min(data_length, N + k), 0)\n        m_coords = np.arange(data_length, dtype=np.intp)\n        n_coords = m_coords - k\n    else:\n        n_coords = m_coords = np.arange(data_length, dtype=np.intp)\n\n    coords = np.stack([n_coords, m_coords])\n    data = np.array(1, dtype=dtype)\n\n    return COO(coords, data=data, shape=(N, M), has_duplicates=False, sorted=True).asformat(format, **kwargs)\n</code></pre>"},{"location":"api/flip/","title":"flip","text":"<p>Reverses the order of elements in an array along the given axis.</p> <p>The shape of the array is preserved.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>COO</code> <p>Input COO array.</p> required <code>axis</code> <code>int or tuple of ints</code> <p>Axis (or axes) along which to flip. If <code>axis</code> is <code>None</code>, the function must flip all input array axes. If <code>axis</code> is negative, the function must count from the last dimension. If provided more than one axis, the function must flip only the specified axes. Default: <code>None</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>result</code> <code>COO</code> <p>An output array having the same data type and shape as <code>x</code> and whose elements, relative to <code>x</code>, are reordered.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def flip(x, /, *, axis=None):\n    \"\"\"\n    Reverses the order of elements in an array along the given axis.\n\n    The shape of the array is preserved.\n\n    Parameters\n    ----------\n    a : COO\n        Input COO array.\n    axis : int or tuple of ints, optional\n        Axis (or axes) along which to flip. If ``axis`` is ``None``, the function must\n        flip all input array axes. If ``axis`` is negative, the function must count from\n        the last dimension. If provided more than one axis, the function must flip only\n        the specified axes. Default: ``None``.\n\n    Returns\n    -------\n    result : COO\n        An output array having the same data type and shape as ``x`` and whose elements,\n        relative to ``x``, are reordered.\n\n    \"\"\"\n\n    x = _validate_coo_input(x)\n\n    if axis is None:\n        axis = range(x.ndim)\n    if not isinstance(axis, Iterable):\n        axis = (axis,)\n\n    new_coords = x.coords.copy()\n    for ax in axis:\n        new_coords[ax, :] = x.shape[ax] - 1 - x.coords[ax, :]\n\n    from .core import COO\n\n    return COO(\n        new_coords,\n        x.data,\n        shape=x.shape,\n        fill_value=x.fill_value,\n    )\n</code></pre>"},{"location":"api/full/","title":"full","text":"<p>Return a SparseArray of given shape and type, filled with <code>fill_value</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>int or tuple of ints</code> <p>Shape of the new array, e.g., <code>(2, 3)</code> or <code>2</code>.</p> required <code>fill_value</code> <code>scalar</code> <p>Fill value.</p> required <code>dtype</code> <code>data - type</code> <p>The desired data-type for the array. The default, <code>None</code>, means <code>np.array(fill_value).dtype</code>.</p> <code>None</code> <code>format</code> <code>str</code> <p>A format string.</p> <code>'coo'</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> required <code>order</code> <code>(C, None)</code> <p>Values except these are not currently supported and raise a NotImplementedError.</p> <code>'C'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>Array of <code>fill_value</code> with the given shape and dtype.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; full(5, 9).todense()\narray([9, 9, 9, 9, 9])\n</code></pre> <pre><code>&gt;&gt;&gt; full((2, 2), 9, dtype=float).todense()\narray([[9., 9.],\n       [9., 9.]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_check_device\ndef full(shape, fill_value, dtype=None, format=\"coo\", order=\"C\", *, device=None, **kwargs):\n    \"\"\"Return a SparseArray of given shape and type, filled with `fill_value`.\n\n    Parameters\n    ----------\n    shape : int or tuple of ints\n        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n    fill_value : scalar\n        Fill value.\n    dtype : data-type, optional\n        The desired data-type for the array. The default, `None`, means\n        `np.array(fill_value).dtype`.\n    format : str, optional\n        A format string.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n    order : {'C', None}\n        Values except these are not currently supported and raise a\n        NotImplementedError.\n\n    Returns\n    -------\n    out : SparseArray\n        Array of `fill_value` with the given shape and dtype.\n\n    Examples\n    --------\n    &gt;&gt;&gt; full(5, 9).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([9, 9, 9, 9, 9])\n\n    &gt;&gt;&gt; full((2, 2), 9, dtype=float).todense()  # doctest: +SKIP\n    array([[9., 9.],\n           [9., 9.]])\n    \"\"\"\n    from sparse import COO\n\n    if dtype is None:\n        dtype = np.array(fill_value).dtype\n    if not isinstance(shape, tuple):\n        shape = (shape,)\n    if order not in {\"C\", None}:\n        raise NotImplementedError(\"Currently, only 'C' and None are supported.\")\n    data = np.empty(0, dtype=dtype)\n    coords = np.empty((len(shape), 0), dtype=np.intp)\n    return COO(\n        coords,\n        data=data,\n        shape=shape,\n        fill_value=fill_value,\n        has_duplicates=False,\n        sorted=True,\n    ).asformat(format, **kwargs)\n</code></pre>"},{"location":"api/full_like/","title":"full_like","text":"<p>Return a full array with the same shape and type as a given array.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>The shape and data-type of the result will match those of <code>a</code>.</p> required <code>dtype</code> <code>data - type</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>format</code> <code>str</code> <p>A format string.</p> <code>None</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>Array of <code>fill_value</code> with the same shape and type as <code>a</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.ones((2, 3), dtype=\"i8\")\n&gt;&gt;&gt; full_like(x, 9.0).todense()\narray([[9, 9, 9],\n       [9, 9, 9]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_check_device\ndef full_like(a, fill_value, dtype=None, shape=None, format=None, *, device=None, **kwargs):\n    \"\"\"Return a full array with the same shape and type as a given array.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of the result will match those of `a`.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n    format : str, optional\n        A format string.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n\n    Returns\n    -------\n    out : SparseArray\n        Array of `fill_value` with the same shape and type as `a`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.ones((2, 3), dtype=\"i8\")\n    &gt;&gt;&gt; full_like(x, 9.0).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[9, 9, 9],\n           [9, 9, 9]])\n    \"\"\"\n    if format is None and not isinstance(a, np.ndarray):\n        format = type(a).__name__.lower()\n    elif format is None:\n        format = \"coo\"\n\n    compressed_axes = kwargs.pop(\"compressed_axes\", None)\n    if hasattr(a, \"compressed_axes\") and compressed_axes is None:\n        compressed_axes = a.compressed_axes\n    return full(\n        a.shape if shape is None else shape,\n        fill_value,\n        dtype=(a.dtype if dtype is None else dtype),\n        format=format,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/imag/","title":"imag","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def imag(x, /):\n    return x.imag\n</code></pre>"},{"location":"api/isinf/","title":"isinf","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_support_numpy\ndef isinf(x, /):\n    return x.isinf()\n</code></pre>"},{"location":"api/isnan/","title":"isnan","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_support_numpy\ndef isnan(x, /):\n    return x.isnan()\n</code></pre>"},{"location":"api/isneginf/","title":"isneginf","text":"<p>Test element-wise for negative infinity, return result as sparse <code>bool</code> array.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Input</p> required <code>out</code> <p>Output array</p> <code>None</code> <code>optional</code> <p>Output array</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.as_coo(np.array([-np.inf]))\n&gt;&gt;&gt; sparse.isneginf(x).todense()\narray([ True])\n</code></pre> See Also <p>numpy.isneginf : The NumPy equivalent</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def isneginf(x, out=None):\n    \"\"\"\n    Test element-wise for negative infinity, return result as sparse ``bool`` array.\n\n    Parameters\n    ----------\n    x\n        Input\n    out, optional\n        Output array\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.as_coo(np.array([-np.inf]))\n    &gt;&gt;&gt; sparse.isneginf(x).todense()\n    array([ True])\n\n    See Also\n    --------\n    numpy.isneginf : The NumPy equivalent\n    \"\"\"\n    from .core import elemwise\n\n    return elemwise(lambda x, out=None, dtype=None: np.isneginf(x, out=out), x, out=out)\n</code></pre>"},{"location":"api/isposinf/","title":"isposinf","text":"<p>Test element-wise for positive infinity, return result as sparse <code>bool</code> array.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Input</p> required <code>out</code> <p>Output array</p> <code>None</code> <code>optional</code> <p>Output array</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.as_coo(np.array([np.inf]))\n&gt;&gt;&gt; sparse.isposinf(x).todense()\narray([ True])\n</code></pre> See Also <p>numpy.isposinf : The NumPy equivalent</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def isposinf(x, out=None):\n    \"\"\"\n    Test element-wise for positive infinity, return result as sparse ``bool`` array.\n\n    Parameters\n    ----------\n    x\n        Input\n    out, optional\n        Output array\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.as_coo(np.array([np.inf]))\n    &gt;&gt;&gt; sparse.isposinf(x).todense()\n    array([ True])\n\n    See Also\n    --------\n    numpy.isposinf : The NumPy equivalent\n    \"\"\"\n    from .core import elemwise\n\n    return elemwise(lambda x, out=None, dtype=None: np.isposinf(x, out=out), x, out=out)\n</code></pre>"},{"location":"api/kron/","title":"kron","text":"<p>Kronecker product of 2 sparse arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>SparseArray, scipy.sparse.spmatrix, or np.ndarray</code> <p>The arrays over which to compute the Kronecker product.</p> required <code>b</code> <code>SparseArray, scipy.sparse.spmatrix, or np.ndarray</code> <p>The arrays over which to compute the Kronecker product.</p> required <p>Returns:</p> Name Type Description <code>res</code> <code>COO</code> <p>The kronecker product</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all arguments are dense or arguments have nonzero fill-values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import eye\n&gt;&gt;&gt; a = eye(3, dtype=\"i8\")\n&gt;&gt;&gt; b = np.array([1, 2, 3], dtype=\"i8\")\n&gt;&gt;&gt; res = kron(a, b)\n&gt;&gt;&gt; res.todense()\narray([[1, 2, 3, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 2, 3, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 2, 3]], dtype=int64)\n</code></pre> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def kron(a, b):\n    \"\"\"Kronecker product of 2 sparse arrays.\n\n    Parameters\n    ----------\n    a, b : SparseArray, scipy.sparse.spmatrix, or np.ndarray\n        The arrays over which to compute the Kronecker product.\n\n    Returns\n    -------\n    res : COO\n        The kronecker product\n\n    Raises\n    ------\n    ValueError\n        If all arguments are dense or arguments have nonzero fill-values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sparse import eye\n    &gt;&gt;&gt; a = eye(3, dtype=\"i8\")\n    &gt;&gt;&gt; b = np.array([1, 2, 3], dtype=\"i8\")\n    &gt;&gt;&gt; res = kron(a, b)\n    &gt;&gt;&gt; res.todense()  # doctest: +SKIP\n    array([[1, 2, 3, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 1, 2, 3, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 1, 2, 3]], dtype=int64)\n    \"\"\"\n    from .._common import _is_sparse\n    from .._umath import _cartesian_product\n    from .core import COO\n\n    check_zero_fill_value(a, b)\n\n    a_sparse = _is_sparse(a)\n    b_sparse = _is_sparse(b)\n    a_ndim = np.ndim(a)\n    b_ndim = np.ndim(b)\n\n    if not (a_sparse or b_sparse):\n        raise ValueError(\"Performing this operation would produce a dense result: kron\")\n\n    if a_ndim == 0 or b_ndim == 0:\n        return a * b\n\n    a = asCOO(a, check=False)\n    b = asCOO(b, check=False)\n\n    # Match dimensions\n    max_dim = max(a.ndim, b.ndim)\n    a = a.reshape((1,) * (max_dim - a.ndim) + a.shape)\n    b = b.reshape((1,) * (max_dim - b.ndim) + b.shape)\n\n    a_idx, b_idx = _cartesian_product(np.arange(a.nnz), np.arange(b.nnz))\n\n    a_expanded_coords = a.coords[:, a_idx]\n    b_expanded_coords = b.coords[:, b_idx]\n    o_coords = a_expanded_coords * np.asarray(b.shape)[:, None] + b_expanded_coords\n    o_data = a.data[a_idx] * b.data[b_idx]\n    o_shape = tuple(i * j for i, j in zip(a.shape, b.shape, strict=True))\n\n    return COO(o_coords, o_data, shape=o_shape, has_duplicates=False)\n</code></pre>"},{"location":"api/load_npz/","title":"load_npz","text":"<p>Load a sparse matrix in numpy's <code>.npz</code> format from disk. Note: This is not binary compatible with scipy's <code>save_npz()</code> output. This binary format is not currently stable. Will only load files saved by this package.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>file-like object, string, or pathlib.Path</code> <p>The file to read. File-like objects must support the <code>seek()</code> and <code>read()</code> methods.</p> required <p>Returns:</p> Type Description <code>SparseArray</code> <p>The sparse matrix at path <code>filename</code>.</p> <p>Examples:</p> <p>See :obj:<code>save_npz</code> for usage examples.</p> See Also <p>save_npz scipy.sparse.save_npz scipy.sparse.load_npz numpy.savez numpy.load</p> Source code in <code>sparse/numba_backend/_io.py</code> <pre><code>def load_npz(filename):\n    \"\"\"Load a sparse matrix in numpy's ``.npz`` format from disk.\n    Note: This is not binary compatible with scipy's ``save_npz()``\n    output. This binary format is not currently stable.\n    Will only load files saved by this package.\n\n    Parameters\n    ----------\n    filename : file-like object, string, or pathlib.Path\n        The file to read. File-like objects must support the\n        ``seek()`` and ``read()`` methods.\n\n    Returns\n    -------\n    SparseArray\n        The sparse matrix at path ``filename``.\n\n    Examples\n    --------\n    See :obj:`save_npz` for usage examples.\n\n    See Also\n    --------\n    save_npz\n    scipy.sparse.save_npz\n    scipy.sparse.load_npz\n    numpy.savez\n    numpy.load\n\n    \"\"\"\n\n    with np.load(filename) as fp:\n        try:\n            coords = fp[\"coords\"]\n            data = fp[\"data\"]\n            shape = tuple(fp[\"shape\"])\n            fill_value = fp[\"fill_value\"][()]\n            return COO(\n                coords=coords,\n                data=data,\n                shape=shape,\n                sorted=True,\n                has_duplicates=False,\n                fill_value=fill_value,\n            )\n        except KeyError:\n            pass\n        try:\n            data = fp[\"data\"]\n            indices = fp[\"indices\"]\n            indptr = fp[\"indptr\"]\n            comp_axes = fp[\"compressed_axes\"]\n            shape = tuple(fp[\"shape\"])\n            fill_value = fp[\"fill_value\"][()]\n            return GCXS(\n                (data, indices, indptr),\n                shape=shape,\n                fill_value=fill_value,\n                compressed_axes=comp_axes,\n            )\n        except KeyError as e:\n            raise RuntimeError(f\"The file {filename!s} does not contain a valid sparse matrix\") from e\n</code></pre>"},{"location":"api/matmul/","title":"matmul","text":"<p>Perform the equivalent of :obj:<code>numpy.matmul</code> on two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[SparseArray, ndarray, spmatrix]</code> <p>The arrays to perform the :code:<code>matmul</code> operation on.</p> required <code>b</code> <code>Union[SparseArray, ndarray, spmatrix]</code> <p>The arrays to perform the :code:<code>matmul</code> operation on.</p> required <p>Returns:</p> Type Description <code>Union[SparseArray, ndarray]</code> <p>The result of the operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all arguments don't have zero fill-values, or the shape of the two arrays is not broadcastable.</p> See Also <p>numpy.matmul : NumPy equivalent function. COO.matmul : Equivalent function for COO objects.</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def matmul(a, b):\n    \"\"\"Perform the equivalent of :obj:`numpy.matmul` on two arrays.\n\n    Parameters\n    ----------\n    a, b : Union[SparseArray, np.ndarray, scipy.sparse.spmatrix]\n        The arrays to perform the :code:`matmul` operation on.\n\n    Returns\n    -------\n    Union[SparseArray, numpy.ndarray]\n        The result of the operation.\n\n    Raises\n    ------\n    ValueError\n        If all arguments don't have zero fill-values, or the shape of the two arrays is not broadcastable.\n\n    See Also\n    --------\n    numpy.matmul : NumPy equivalent function.\n    COO.__matmul__ : Equivalent function for COO objects.\n    \"\"\"\n    check_zero_fill_value(a, b)\n    if not hasattr(a, \"ndim\") or not hasattr(b, \"ndim\"):\n        raise TypeError(f\"Cannot perform dot product on types {type(a)}, {type(b)}\")\n\n    if check_class_nan(a) or check_class_nan(b):\n        warnings.warn(\"Nan will not be propagated in matrix multiplication\", RuntimeWarning, stacklevel=1)\n\n    # When b is 2-d, it is equivalent to dot\n    if b.ndim &lt;= 2:\n        return dot(a, b)\n\n    # when a is 2-d, we need to transpose result after dot\n    if a.ndim &lt;= 2:\n        res = dot(a, b)\n        axes = list(range(res.ndim))\n        axes.insert(-1, axes.pop(0))\n        return res.transpose(axes)\n\n    # If a can be squeeze to a vector, use dot will be faster\n    if a.ndim &lt;= b.ndim and np.prod(a.shape[:-1]) == 1:\n        res = dot(a.reshape(-1), b)\n        shape = list(res.shape)\n        shape.insert(-1, 1)\n        return res.reshape(shape)\n\n    # If b can be squeeze to a matrix, use dot will be faster\n    if b.ndim &lt;= a.ndim and np.prod(b.shape[:-2]) == 1:\n        return dot(a, b.reshape(b.shape[-2:]))\n\n    if a.ndim &lt; b.ndim:\n        a = a[(None,) * (b.ndim - a.ndim)]\n    if a.ndim &gt; b.ndim:\n        b = b[(None,) * (a.ndim - b.ndim)]\n    for i, j in zip(a.shape[:-2], b.shape[:-2], strict=True):\n        if i != 1 and j != 1 and i != j:\n            raise ValueError(\"shapes of a and b are not broadcastable\")\n\n    def _matmul_recurser(a, b):\n        if a.ndim == 2:\n            return dot(a, b)\n        res = []\n        for i in range(builtins.max(a.shape[0], b.shape[0])):\n            a_i = a[0] if a.shape[0] == 1 else a[i]\n            b_i = b[0] if b.shape[0] == 1 else b[i]\n            res.append(_matmul_recurser(a_i, b_i))\n        mask = [isinstance(x, SparseArray) for x in res]\n        if builtins.all(mask):\n            return stack(res)\n\n        res = [x.todense() if isinstance(x, SparseArray) else x for x in res]\n        return np.stack(res)\n\n    return _matmul_recurser(a, b)\n</code></pre>"},{"location":"api/matrix_transpose/","title":"matrix_transpose","text":"<p>Transposes a matrix or a stack of matrices.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>Input array.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>COO</code> <p>Transposed COO array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input array isn't and can't be converted to COO format, or if <code>x.ndim &lt; 2</code>.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def matrix_transpose(x, /):\n    \"\"\"\n    Transposes a matrix or a stack of matrices.\n\n    Parameters\n    ----------\n    x : SparseArray\n        Input array.\n\n    Returns\n    -------\n    out : COO\n        Transposed COO array.\n\n    Raises\n    ------\n    ValueError\n        If the input array isn't and can't be converted to COO format, or if ``x.ndim &lt; 2``.\n    \"\"\"\n    if hasattr(x, \"ndim\") and x.ndim &lt; 2:\n        raise ValueError(\"`x.ndim &gt;= 2` must hold.\")\n    x = _validate_coo_input(x)\n    transpose_axes = list(range(x.ndim))\n    transpose_axes[-2:] = transpose_axes[-2:][::-1]\n\n    return x.transpose(transpose_axes)\n</code></pre>"},{"location":"api/max/","title":"max","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def max(x, /, *, axis=None, keepdims=False):\n    return x.max(axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/mean/","title":"mean","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def mean(x, /, *, axis=None, keepdims=False, dtype=None):\n    return x.mean(axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/min/","title":"min","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def min(x, /, *, axis=None, keepdims=False):\n    return x.min(axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"api/moveaxis/","title":"moveaxis","text":"<p>Move axes of an array to new positions.</p> <p>Other axes remain in their original order.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>SparseArray</code> <p>The array whose axes should be reordered.</p> required <code>source</code> <code>int or List[int]</code> <p>Original positions of the axes to move. These must be unique.</p> required <code>destination</code> <code>int or List[int]</code> <p>Destination positions for each of the original axes. These must also be unique.</p> required <p>Returns:</p> Type Description <code>SparseArray</code> <p>Array with moved axes.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.COO.from_numpy(np.ones((2, 3, 4, 5)))\n&gt;&gt;&gt; sparse.moveaxis(x, (0, 1), (2, 3))\n&lt;COO: shape=(4, 5, 2, 3), dtype=float64, nnz=120, fill_value=0.0&gt;\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def moveaxis(a, source, destination):\n    \"\"\"\n    Move axes of an array to new positions.\n\n    Other axes remain in their original order.\n\n    Parameters\n    ----------\n    a : SparseArray\n        The array whose axes should be reordered.\n    source : int or List[int]\n        Original positions of the axes to move. These must be unique.\n    destination : int or List[int]\n        Destination positions for each of the original axes. These must also be unique.\n\n    Returns\n    -------\n    SparseArray\n        Array with moved axes.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.COO.from_numpy(np.ones((2, 3, 4, 5)))\n    &gt;&gt;&gt; sparse.moveaxis(x, (0, 1), (2, 3))\n    &lt;COO: shape=(4, 5, 2, 3), dtype=float64, nnz=120, fill_value=0.0&gt;\n    \"\"\"\n\n    if not isinstance(source, Iterable):\n        source = (source,)\n    if not isinstance(destination, Iterable):\n        destination = (destination,)\n\n    source = normalize_axis(source, a.ndim)\n    destination = normalize_axis(destination, a.ndim)\n\n    if len(source) != len(destination):\n        raise ValueError(\"`source` and `destination` arguments must have the same number of elements\")\n\n    order = [n for n in range(a.ndim) if n not in source]\n\n    for dest, src in sorted(zip(destination, source, strict=True)):\n        order.insert(dest, src)\n\n    return a.transpose(order)\n</code></pre>"},{"location":"api/nanmax/","title":"nanmax","text":"<p>Maximize along the given axes, skipping <code>NaN</code> values. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>The array to perform the reduction on.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to maximize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>COO.max</code> : Function without <code>NaN</code> skipping. numpy.nanmax : Equivalent Numpy function.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def nanmax(x, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Maximize along the given axes, skipping ``NaN`` values. Uses all axes by default.\n\n    Parameters\n    ----------\n    x : SparseArray\n        The array to perform the reduction on.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to maximize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    COO\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`COO.max` : Function without ``NaN`` skipping.\n    numpy.nanmax : Equivalent Numpy function.\n    \"\"\"\n    assert out is None\n    x = asCOO(x, name=\"nanmax\")\n\n    ar = x.reduce(np.fmax, axis=axis, keepdims=keepdims, dtype=dtype)\n\n    if (isscalar(ar) and np.isnan(ar)) or np.isnan(ar.data).any():\n        warnings.warn(\"All-NaN slice encountered\", RuntimeWarning, stacklevel=1)\n\n    return ar\n</code></pre>"},{"location":"api/nanmean/","title":"nanmean","text":"<p>Performs a <code>NaN</code> skipping mean operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>The array to perform the reduction on.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to compute the mean. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>COO.mean</code> : Function without <code>NaN</code> skipping. numpy.nanmean : Equivalent Numpy function.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def nanmean(x, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a ``NaN`` skipping mean operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    x : SparseArray\n        The array to perform the reduction on.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to compute the mean. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    COO\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`COO.mean` : Function without ``NaN`` skipping.\n    numpy.nanmean : Equivalent Numpy function.\n    \"\"\"\n    assert out is None\n    x = asCOO(x, name=\"nanmean\")\n\n    if not (np.issubdtype(x.dtype, np.floating) or np.issubdtype(x.dtype, np.complexfloating)):\n        return x.mean(axis=axis, keepdims=keepdims, dtype=dtype)\n\n    mask = np.isnan(x)\n    x2 = where(mask, 0, x)\n\n    # Count the number non-nan elements along axis\n    nancount = mask.sum(axis=axis, dtype=\"i8\", keepdims=keepdims)\n    if axis is None:\n        axis = tuple(range(x.ndim))\n    elif not isinstance(axis, tuple):\n        axis = (axis,)\n    den = reduce(operator.mul, (x.shape[i] for i in axis), 1)\n    den -= nancount\n\n    if (den == 0).any():\n        warnings.warn(\"Mean of empty slice\", RuntimeWarning, stacklevel=1)\n\n    num = np.sum(x2, axis=axis, dtype=dtype, keepdims=keepdims)\n\n    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n        if num.ndim:\n            return np.true_divide(num, den, casting=\"unsafe\")\n        return (num / den).astype(dtype if dtype is not None else x.dtype)\n</code></pre>"},{"location":"api/nanmin/","title":"nanmin","text":"<p>Minimize along the given axes, skipping <code>NaN</code> values. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>The array to perform the reduction on.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to minimize. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>COO.min</code> : Function without <code>NaN</code> skipping. numpy.nanmin : Equivalent Numpy function.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def nanmin(x, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Minimize along the given axes, skipping ``NaN`` values. Uses all axes by default.\n\n    Parameters\n    ----------\n    x : SparseArray\n        The array to perform the reduction on.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to minimize. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    COO\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`COO.min` : Function without ``NaN`` skipping.\n    numpy.nanmin : Equivalent Numpy function.\n    \"\"\"\n    assert out is None\n    x = asCOO(x, name=\"nanmin\")\n\n    ar = x.reduce(np.fmin, axis=axis, keepdims=keepdims, dtype=dtype)\n\n    if (isscalar(ar) and np.isnan(ar)) or np.isnan(ar.data).any():\n        warnings.warn(\"All-NaN slice encountered\", RuntimeWarning, stacklevel=1)\n\n    return ar\n</code></pre>"},{"location":"api/nanprod/","title":"nanprod","text":"<p>Performs a product operation along the given axes, skipping <code>NaN</code> values. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>The array to perform the reduction on.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to multiply. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>COO.prod</code> : Function without <code>NaN</code> skipping. numpy.nanprod : Equivalent Numpy function.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def nanprod(x, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a product operation along the given axes, skipping ``NaN`` values.\n    Uses all axes by default.\n\n    Parameters\n    ----------\n    x : SparseArray\n        The array to perform the reduction on.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to multiply. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    COO\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`COO.prod` : Function without ``NaN`` skipping.\n    numpy.nanprod : Equivalent Numpy function.\n    \"\"\"\n    assert out is None\n    x = asCOO(x)\n    return nanreduce(x, np.multiply, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/nanreduce/","title":"nanreduce","text":"<p>Performs an <code>NaN</code> skipping reduction on this array. See the documentation on :obj:<code>COO.reduce</code> for examples.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>COO</code> <p>The array to reduce.</p> required <code>method</code> <code>ufunc</code> <p>The method to use for performing the reduction.</p> required <code>identity</code> <code>number</code> <p>The identity value for this reduction. Inferred from <code>method</code> if not given. Note that some <code>ufunc</code> objects don't have this, so it may be necessary to give it.</p> <code>None</code> <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to perform the reduction. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Any extra arguments to pass to the reduction operation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>COO</code> <p>The result of the reduction operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If reducing an all-zero axis would produce a nonzero result.</p> See Also <p>COO.reduce : Similar method without <code>NaN</code> skipping functionality.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def nanreduce(x, method, identity=None, axis=None, keepdims=False, **kwargs):\n    \"\"\"\n    Performs an ``NaN`` skipping reduction on this array. See the documentation\n    on :obj:`COO.reduce` for examples.\n\n    Parameters\n    ----------\n    x : COO\n        The array to reduce.\n    method : numpy.ufunc\n        The method to use for performing the reduction.\n    identity : numpy.number\n        The identity value for this reduction. Inferred from ``method`` if not given.\n        Note that some ``ufunc`` objects don't have this, so it may be necessary to give it.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to perform the reduction. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    **kwargs : dict\n        Any extra arguments to pass to the reduction operation.\n\n    Returns\n    -------\n    COO\n        The result of the reduction operation.\n\n    Raises\n    ------\n    ValueError\n        If reducing an all-zero axis would produce a nonzero result.\n\n    See Also\n    --------\n    COO.reduce : Similar method without ``NaN`` skipping functionality.\n    \"\"\"\n    arr = _replace_nan(x, method.identity if identity is None else identity)\n    return arr.reduce(method, axis, keepdims, **kwargs)\n</code></pre>"},{"location":"api/nansum/","title":"nansum","text":"<p>Performs a <code>NaN</code> skipping sum operation along the given axes. Uses all axes by default.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>The array to perform the reduction on.</p> required <code>axis</code> <code>Union[int, Iterable[int]]</code> <p>The axes along which to sum. Uses all axes by default.</p> <code>None</code> <code>keepdims</code> <code>bool_</code> <p>Whether or not to keep the dimensions of the original array.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>The data type of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The reduced output sparse array.</p> See Also <p>:obj:<code>COO.sum</code> : Function without <code>NaN</code> skipping. numpy.nansum : Equivalent Numpy function.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def nansum(x, axis=None, keepdims=False, dtype=None, out=None):\n    \"\"\"\n    Performs a ``NaN`` skipping sum operation along the given axes. Uses all axes by default.\n\n    Parameters\n    ----------\n    x : SparseArray\n        The array to perform the reduction on.\n    axis : Union[int, Iterable[int]], optional\n        The axes along which to sum. Uses all axes by default.\n    keepdims : bool, optional\n        Whether or not to keep the dimensions of the original array.\n    dtype : numpy.dtype\n        The data type of the output array.\n\n    Returns\n    -------\n    COO\n        The reduced output sparse array.\n\n    See Also\n    --------\n    :obj:`COO.sum` : Function without ``NaN`` skipping.\n    numpy.nansum : Equivalent Numpy function.\n    \"\"\"\n    assert out is None\n    x = asCOO(x, name=\"nansum\")\n    return nanreduce(x, np.add, axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/nonzero/","title":"nonzero","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def nonzero(x, /):\n    return x.nonzero()\n</code></pre>"},{"location":"api/ones/","title":"ones","text":"<p>Return a SparseArray of given shape and type, filled with ones.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>int or tuple of ints</code> <p>Shape of the new array, e.g., <code>(2, 3)</code> or <code>2</code>.</p> required <code>dtype</code> <code>data - type</code> <p>The desired data-type for the array, e.g., <code>numpy.int8</code>.  Default is <code>numpy.float64</code>.</p> <code>float</code> <code>format</code> <code>str</code> <p>A format string.</p> <code>'coo'</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>Array of ones with the given shape and dtype.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ones(5).todense()\narray([1., 1., 1., 1., 1.])\n</code></pre> <pre><code>&gt;&gt;&gt; ones((2, 2), dtype=int).todense()\narray([[1, 1],\n       [1, 1]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def ones(shape, dtype=float, format=\"coo\", *, device=None, **kwargs):\n    \"\"\"Return a SparseArray of given shape and type, filled with ones.\n\n    Parameters\n    ----------\n    shape : int or tuple of ints\n        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n    dtype : data-type, optional\n        The desired data-type for the array, e.g., `numpy.int8`.  Default is\n        `numpy.float64`.\n    format : str, optional\n        A format string.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n\n    Returns\n    -------\n    out : SparseArray\n        Array of ones with the given shape and dtype.\n\n    Examples\n    --------\n    &gt;&gt;&gt; ones(5).todense()  # doctest: +SKIP\n    array([1., 1., 1., 1., 1.])\n\n    &gt;&gt;&gt; ones((2, 2), dtype=int).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[1, 1],\n           [1, 1]])\n    \"\"\"\n    return full(shape, fill_value=1, dtype=np.dtype(dtype), format=format, device=device, **kwargs)\n</code></pre>"},{"location":"api/ones_like/","title":"ones_like","text":"<p>Return a SparseArray of ones with the same shape and type as <code>a</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>The shape and data-type of the result will match those of <code>a</code>.</p> required <code>dtype</code> <code>data - type</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>format</code> <code>str</code> <p>A format string.</p> <code>None</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>Array of ones with the same shape and type as <code>a</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.ones((2, 3), dtype=\"i8\")\n&gt;&gt;&gt; ones_like(x).todense()\narray([[1, 1, 1],\n       [1, 1, 1]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def ones_like(a, dtype=None, shape=None, format=None, *, device=None, **kwargs):\n    \"\"\"Return a SparseArray of ones with the same shape and type as ``a``.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of the result will match those of `a`.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n    format : str, optional\n        A format string.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n\n    Returns\n    -------\n    out : SparseArray\n        Array of ones with the same shape and type as `a`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.ones((2, 3), dtype=\"i8\")\n    &gt;&gt;&gt; ones_like(x).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[1, 1, 1],\n           [1, 1, 1]])\n    \"\"\"\n    return full_like(a, fill_value=1, dtype=dtype, shape=shape, format=format, device=device, **kwargs)\n</code></pre>"},{"location":"api/outer/","title":"outer","text":"<p>Return outer product of two sparse arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>SparseArray</code> <p>The input arrays.</p> required <code>b</code> <code>SparseArray</code> <p>The input arrays.</p> required <code>out</code> <code>SparseArray</code> <p>The output array.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; a = sparse.COO(np.arange(4))\n&gt;&gt;&gt; o = sparse.outer(a, a)\n&gt;&gt;&gt; o.todense()\narray([[0, 0, 0, 0],\n       [0, 1, 2, 3],\n       [0, 2, 4, 6],\n       [0, 3, 6, 9]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def outer(a, b, out=None):\n    \"\"\"\n    Return outer product of two sparse arrays.\n\n    Parameters\n    ----------\n    a, b : sparse.SparseArray\n        The input arrays.\n    out : sparse.SparseArray\n        The output array.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; a = sparse.COO(np.arange(4))\n    &gt;&gt;&gt; o = sparse.outer(a, a)\n    &gt;&gt;&gt; o.todense()\n    array([[0, 0, 0, 0],\n           [0, 1, 2, 3],\n           [0, 2, 4, 6],\n           [0, 3, 6, 9]])\n    \"\"\"\n    from ._coo import COO\n    from ._sparse_array import SparseArray\n\n    if isinstance(a, SparseArray):\n        a = COO(a)\n    if isinstance(b, SparseArray):\n        b = COO(b)\n    return np.multiply.outer(a.flatten(), b.flatten(), out=out)\n</code></pre>"},{"location":"api/pad/","title":"pad","text":"<p>Performs the equivalent of :obj:<code>numpy.pad</code> for :obj:<code>SparseArray</code>. Note that this function returns a new array instead of a view.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>SparseArray</code> <p>Sparse array which is to be padded.</p> required <code>pad_width</code> <code>(sequence, array_like, int)</code> <p>Number of values padded to the edges of each axis. ((before_1, after_1), \u2026 (before_N, after_N)) unique pad widths for each axis. ((before, after),) yields same before and after pad for each axis. (pad,) or int is a shortcut for before = after = pad width for all axes.</p> <code>sequence</code> <code>mode</code> <code>str</code> <p>Pads to a constant value which is fill value. Currently only constant mode is implemented</p> <code>'constant'</code> <code>constant_values</code> <code>int</code> <p>The values to set the padded values for each axis. Default is 0. This must be same as fill value.</p> required <p>Returns:</p> Type Description <code>SparseArray</code> <p>The padded sparse array.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If mode != 'constant' or there are unknown arguments.</p> <code>ValueError</code> <p>If constant_values != self.fill_value</p> See Also <p>:obj:<code>numpy.pad</code> : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def pad(array, pad_width, mode=\"constant\", **kwargs):\n    \"\"\"\n    Performs the equivalent of :obj:`numpy.pad` for :obj:`SparseArray`. Note that\n    this function returns a new array instead of a view.\n\n    Parameters\n    ----------\n    array : SparseArray\n        Sparse array which is to be padded.\n\n    pad_width : {sequence, array_like, int}\n        Number of values padded to the edges of each axis. ((before_1, after_1), \u2026 (before_N, after_N)) unique pad\n        widths for each axis. ((before, after),) yields same before and after pad for each axis. (pad,) or int is a\n        shortcut for before = after = pad width for all axes.\n\n    mode : str\n        Pads to a constant value which is fill value. Currently only constant mode is implemented\n\n    constant_values : int\n        The values to set the padded values for each axis. Default is 0. This must be same as fill value.\n\n    Returns\n    -------\n    SparseArray\n        The padded sparse array.\n\n    Raises\n    ------\n    NotImplementedError\n        If mode != 'constant' or there are unknown arguments.\n\n    ValueError\n        If constant_values != self.fill_value\n\n    See Also\n    --------\n    :obj:`numpy.pad` : NumPy equivalent function\n\n    \"\"\"\n    if not isinstance(array, SparseArray):\n        raise NotImplementedError(\"Input array is not compatible.\")\n\n    if mode.lower() != \"constant\":\n        raise NotImplementedError(f\"Mode '{mode}' is not yet supported.\")\n\n    if not equivalent(kwargs.pop(\"constant_values\", _zero_of_dtype(array.dtype)), array.fill_value):\n        raise ValueError(\"constant_values can only be equal to fill value.\")\n\n    if kwargs:\n        raise NotImplementedError(\"Additional Unknown arguments present.\")\n\n    from ._coo import COO\n\n    array = array.asformat(\"coo\")\n\n    pad_width = np.broadcast_to(pad_width, (len(array.shape), 2))\n    new_coords = array.coords + pad_width[:, 0:1]\n    new_shape = tuple([array.shape[i] + pad_width[i, 0] + pad_width[i, 1] for i in range(len(array.shape))])\n    new_data = array.data\n    return COO(new_coords, new_data, new_shape, fill_value=array.fill_value)\n</code></pre>"},{"location":"api/permute_dims/","title":"permute_dims","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def permute_dims(x, /, axes=None):\n    return x.transpose(axes=axes)\n</code></pre>"},{"location":"api/prod/","title":"prod","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def prod(x, /, *, axis=None, dtype=None, keepdims=False):\n    return x.prod(axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/random/","title":"random","text":"<p>Generate a random sparse multidimensional array</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Tuple[int]</code> <p>Shape of the array</p> required <code>density</code> <code>float</code> <p>Density of the generated array; default is 0.01. Mutually exclusive with <code>nnz</code>.</p> <code>None</code> <code>nnz</code> <code>int</code> <p>Number of nonzero elements in the generated array. Mutually exclusive with <code>density</code>.</p> <code>None</code> <code>random_state</code> <code>Union[Generator, int]</code> <p>Random number generator or random seed. If not given, the singleton numpy.random will be used. This random state will be used for sampling the sparsity structure, but not necessarily for sampling the values of the structurally nonzero entries of the matrix.</p> <code>None</code> <code>data_rvs</code> <code>Callable</code> <p>Data generation callback. Must accept one single parameter: number of :code:<code>nnz</code> elements, and return one single NumPy array of exactly that length.</p> <code>None</code> <code>format</code> <code>str</code> <p>The format to return the output array in.</p> <code>'coo'</code> <code>fill_value</code> <code>scalar</code> <p>The fill value of the output array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The generated random matrix.</p> See Also <p>:obj:<code>scipy.sparse.rand</code> : Equivalent Scipy function. :obj:<code>numpy.random.rand</code> : Similar Numpy function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sparse import random\n&gt;&gt;&gt; from scipy import stats\n&gt;&gt;&gt; rvs = lambda x: stats.poisson(25, loc=10).rvs(x, random_state=np.random.RandomState(1))\n&gt;&gt;&gt; s = random((2, 3, 4), density=0.25, random_state=np.random.RandomState(1), data_rvs=rvs)\n&gt;&gt;&gt; s.todense()\narray([[[ 0,  0,  0,   0],\n        [34,  0, 29,  30],\n        [ 0,  0,  0,  0]],\n\n       [[33,  0,  0, 34],\n        [34,  0,  0,  0],\n        [ 0,  0,  0,  0]]])\n</code></pre> Source code in <code>sparse/numba_backend/_utils.py</code> <pre><code>def random(\n    shape,\n    density=None,\n    nnz=None,\n    random_state=None,\n    data_rvs=None,\n    format=\"coo\",\n    fill_value=None,\n    idx_dtype=None,\n    **kwargs,\n):\n    \"\"\"Generate a random sparse multidimensional array\n\n    Parameters\n    ----------\n    shape : Tuple[int]\n        Shape of the array\n    density : float, optional\n        Density of the generated array; default is 0.01.\n        Mutually exclusive with `nnz`.\n    nnz : int, optional\n        Number of nonzero elements in the generated array.\n        Mutually exclusive with `density`.\n    random_state : Union[numpy.random.Generator, int], optional\n        Random number generator or random seed. If not given, the\n        singleton numpy.random will be used. This random state will be used\n        for sampling the sparsity structure, but not necessarily for sampling\n        the values of the structurally nonzero entries of the matrix.\n    data_rvs : Callable\n        Data generation callback. Must accept one single parameter: number of\n        :code:`nnz` elements, and return one single NumPy array of exactly\n        that length.\n    format : str\n        The format to return the output array in.\n    fill_value : scalar\n        The fill value of the output array.\n\n    Returns\n    -------\n    SparseArray\n        The generated random matrix.\n\n    See Also\n    --------\n    :obj:`scipy.sparse.rand` : Equivalent Scipy function.\n    :obj:`numpy.random.rand` : Similar Numpy function.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sparse import random\n    &gt;&gt;&gt; from scipy import stats\n    &gt;&gt;&gt; rvs = lambda x: stats.poisson(25, loc=10).rvs(x, random_state=np.random.RandomState(1))\n    &gt;&gt;&gt; s = random((2, 3, 4), density=0.25, random_state=np.random.RandomState(1), data_rvs=rvs)\n    &gt;&gt;&gt; s.todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[[ 0,  0,  0,   0],\n            [34,  0, 29,  30],\n            [ 0,  0,  0,  0]],\n    &lt;BLANKLINE&gt;\n           [[33,  0,  0, 34],\n            [34,  0,  0,  0],\n            [ 0,  0,  0,  0]]])\n\n    \"\"\"\n    # Copied, in large part, from scipy.sparse.random\n    # See https://github.com/scipy/scipy/blob/main/LICENSE.txt\n    from ._coo import COO\n\n    if density is not None and nnz is not None:\n        raise ValueError(\"'density' and 'nnz' are mutually exclusive\")\n\n    if density is None:\n        density = 0.01\n    if not (0 &lt;= density &lt;= 1):\n        raise ValueError(f\"density {density} is not in the unit interval\")\n\n    elements = np.prod(shape, dtype=np.intp)\n\n    if nnz is None:\n        nnz = int(elements * density)\n    if not (0 &lt;= nnz &lt;= elements):\n        raise ValueError(f\"cannot generate {nnz} nonzero elements for an array with {elements} total elements\")\n\n    if random_state is None:\n        random_state = default_rng\n    elif isinstance(random_state, Integral):\n        random_state = np.random.default_rng(random_state)\n    if data_rvs is None:\n        data_rvs = random_state.random\n\n    if nnz == elements or density &gt;= 1:\n        ind = np.arange(elements)\n    elif nnz &lt; 2:\n        ind = random_state.choice(elements, nnz)\n    # Faster to find non-sampled indices and remove them for dens &gt; .5\n    elif elements - nnz &lt; 2:\n        ind = reverse(random_state.choice(elements, elements - nnz), elements)\n    elif nnz &gt; elements / 2:\n        nnztemp = elements - nnz\n        # Using algorithm A for dens &gt; .1\n        if elements &gt; 10 * nnztemp:\n            ind = reverse(\n                algD(nnztemp, elements, random_state),\n                elements,\n            )\n        else:\n            ind = reverse(\n                algA(nnztemp, elements, random_state),\n                elements,\n            )\n    else:\n        ind = algD(nnz, elements, random_state) if elements &gt; 10 * nnz else algA(nnz, elements, random_state)\n    data = data_rvs(nnz)\n\n    ar = COO(\n        ind[None, :],\n        data,\n        shape=elements,\n        fill_value=fill_value,\n    ).reshape(shape)\n\n    if idx_dtype:\n        if can_store(idx_dtype, max(shape)):\n            ar.coords = ar.coords.astype(idx_dtype)\n        else:\n            raise ValueError(f\"cannot cast array with shape {shape} to dtype {idx_dtype}.\")\n\n    return ar.asformat(format, **kwargs)\n</code></pre>"},{"location":"api/real/","title":"real","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def real(x, /):\n    return x.real\n</code></pre>"},{"location":"api/reshape/","title":"reshape","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def reshape(x, /, shape, *, copy=None):\n    return x.reshape(shape=shape)\n</code></pre>"},{"location":"api/result_type/","title":"result_type","text":"<p>Returns the type that results from applying the NumPy type promotion rules to the arguments.</p> See Also <p>numpy.result_type : The NumPy equivalent</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def result_type(*arrays_and_dtypes):\n    \"\"\"Returns the type that results from applying the NumPy type promotion rules to the\n    arguments.\n\n    See Also\n    --------\n    numpy.result_type : The NumPy equivalent\n    \"\"\"\n    return np.result_type(*(_as_result_type_arg(x) for x in arrays_and_dtypes))\n</code></pre>"},{"location":"api/roll/","title":"roll","text":"<p>Shifts elements of an array along specified axis. Elements that roll beyond the last position are circulated and re-introduced at the first.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>COO</code> <p>Input array</p> required <code>shift</code> <code>int or tuple of ints</code> <p>Number of index positions that elements are shifted. If a tuple is provided, then axis must be a tuple of the same size, and each of the given axes is shifted by the corresponding number. If an int while axis is a tuple of ints, then broadcasting is used so the same shift is applied to all axes.</p> required <code>axis</code> <code>int or tuple of ints</code> <p>Axis or tuple specifying multiple axes. By default, the array is flattened before shifting, after which the original shape is restored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>res</code> <code>ndarray</code> <p>Output array, with the same shape as a.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def roll(a, shift, axis=None):\n    \"\"\"\n    Shifts elements of an array along specified axis. Elements that roll beyond\n    the last position are circulated and re-introduced at the first.\n\n    Parameters\n    ----------\n    a : COO\n        Input array\n    shift : int or tuple of ints\n        Number of index positions that elements are shifted. If a tuple is\n        provided, then axis must be a tuple of the same size, and each of the\n        given axes is shifted by the corresponding number. If an int while axis\n        is a tuple of ints, then broadcasting is used so the same shift is\n        applied to all axes.\n    axis : int or tuple of ints, optional\n        Axis or tuple specifying multiple axes. By default, the\n        array is flattened before shifting, after which the original shape is\n        restored.\n\n    Returns\n    -------\n    res : ndarray\n        Output array, with the same shape as a.\n    \"\"\"\n    from .core import COO, as_coo\n\n    a = as_coo(a)\n\n    # roll flattened array\n    if axis is None:\n        return roll(a.reshape((-1,)), shift, 0).reshape(a.shape)\n\n    # roll across specified axis\n    # parse axis input, wrap in tuple\n    axis = normalize_axis(axis, a.ndim)\n    if not isinstance(axis, tuple):\n        axis = (axis,)\n\n    # make shift iterable\n    if not isinstance(shift, Iterable):\n        shift = (shift,)\n\n    elif np.ndim(shift) &gt; 1:\n        raise ValueError(\"'shift' and 'axis' must be integers or 1D sequences.\")\n\n    # handle broadcasting\n    if len(shift) == 1:\n        shift = np.full(len(axis), shift)\n\n    # check if dimensions are consistent\n    if len(axis) != len(shift):\n        raise ValueError(\"If 'shift' is a 1D sequence, 'axis' must have equal length.\")\n\n    if not can_store(a.coords.dtype, max(a.shape + shift)):\n        raise ValueError(\n            f\"cannot roll with coords.dtype {a.coords.dtype} and shift {shift}. Try casting coords to a larger dtype.\"\n        )\n\n    # shift elements\n    coords, data = np.copy(a.coords), np.copy(a.data)\n    try:\n        for sh, ax in zip(shift, axis, strict=True):\n            coords[ax] += sh\n            coords[ax] %= a.shape[ax]\n    except TypeError as e:\n        if is_unsigned_dtype(coords.dtype):\n            raise ValueError(\n                f\"rolling with coords.dtype as {coords.dtype} is not safe. Try using a signed dtype.\"\n            ) from e\n\n    return COO(\n        coords,\n        data=data,\n        shape=a.shape,\n        has_duplicates=False,\n        fill_value=a.fill_value,\n    )\n</code></pre>"},{"location":"api/round/","title":"round","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_support_numpy\ndef round(x, /, decimals=0, out=None):\n    return x.round(decimals=decimals, out=out)\n</code></pre>"},{"location":"api/save_npz/","title":"save_npz","text":"<p>Save a sparse matrix to disk in numpy's <code>.npz</code> format. Note: This is not binary compatible with scipy's <code>save_npz()</code>. This binary format is not currently stable. Will save a file that can only be opend with this package's <code>load_npz()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>string or file</code> <p>Either the file name (string) or an open file (file-like object) where the data will be saved. If file is a string or a Path, the <code>.npz</code> extension will be appended to the file name if it is not already there</p> required <code>matrix</code> <code>SparseArray</code> <p>The matrix to save to disk</p> required <code>compressed</code> <code>bool_</code> <p>Whether to save in compressed or uncompressed mode</p> <code>True</code> <p>Examples:</p> <p>Store sparse matrix to disk, and load it again:</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; dense_mat = np.array([[[0.0, 0.0], [0.0, 0.70677779]], [[0.0, 0.0], [0.0, 0.86522495]]])\n&gt;&gt;&gt; mat = sparse.COO(dense_mat)\n&gt;&gt;&gt; mat\n&lt;COO: shape=(2, 2, 2), dtype=float64, nnz=2, fill_value=0.0&gt;\n&gt;&gt;&gt; sparse.save_npz(\"mat.npz\", mat)\n&gt;&gt;&gt; loaded_mat = sparse.load_npz(\"mat.npz\")\n&gt;&gt;&gt; loaded_mat\n&lt;COO: shape=(2, 2, 2), dtype=float64, nnz=2, fill_value=0.0&gt;\n&gt;&gt;&gt; os.remove(\"mat.npz\")\n</code></pre> See Also <p>load_npz scipy.sparse.save_npz scipy.sparse.load_npz numpy.savez numpy.load</p> Source code in <code>sparse/numba_backend/_io.py</code> <pre><code>def save_npz(filename, matrix, compressed=True):\n    \"\"\"Save a sparse matrix to disk in numpy's ``.npz`` format.\n    Note: This is not binary compatible with scipy's ``save_npz()``.\n    This binary format is not currently stable. Will save a file\n    that can only be opend with this package's ``load_npz()``.\n\n    Parameters\n    ----------\n    filename : string or file\n        Either the file name (string) or an open file (file-like object)\n        where the data will be saved. If file is a string or a Path, the\n        ``.npz`` extension will be appended to the file name if it is not\n        already there\n    matrix : SparseArray\n        The matrix to save to disk\n    compressed : bool\n        Whether to save in compressed or uncompressed mode\n\n    Examples\n    --------\n    Store sparse matrix to disk, and load it again:\n\n    &gt;&gt;&gt; import os\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; dense_mat = np.array([[[0.0, 0.0], [0.0, 0.70677779]], [[0.0, 0.0], [0.0, 0.86522495]]])\n    &gt;&gt;&gt; mat = sparse.COO(dense_mat)\n    &gt;&gt;&gt; mat\n    &lt;COO: shape=(2, 2, 2), dtype=float64, nnz=2, fill_value=0.0&gt;\n    &gt;&gt;&gt; sparse.save_npz(\"mat.npz\", mat)\n    &gt;&gt;&gt; loaded_mat = sparse.load_npz(\"mat.npz\")\n    &gt;&gt;&gt; loaded_mat\n    &lt;COO: shape=(2, 2, 2), dtype=float64, nnz=2, fill_value=0.0&gt;\n    &gt;&gt;&gt; os.remove(\"mat.npz\")\n\n    See Also\n    --------\n    load_npz\n    scipy.sparse.save_npz\n    scipy.sparse.load_npz\n    numpy.savez\n    numpy.load\n\n    \"\"\"\n\n    nodes = {\n        \"data\": matrix.data,\n        \"shape\": matrix.shape,\n        \"fill_value\": matrix.fill_value,\n    }\n\n    if type(matrix) == COO:\n        nodes[\"coords\"] = matrix.coords\n    elif type(matrix) == GCXS:\n        nodes[\"indices\"] = matrix.indices\n        nodes[\"indptr\"] = matrix.indptr\n        nodes[\"compressed_axes\"] = matrix.compressed_axes\n\n    if compressed:\n        np.savez_compressed(filename, **nodes)\n    else:\n        np.savez(filename, **nodes)\n</code></pre>"},{"location":"api/sort/","title":"sort","text":"<p>Returns a sorted copy of an input array <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>Input array. Should have a real-valued data type.</p> required <code>axis</code> <code>int</code> <p>Axis along which to sort. If set to <code>-1</code>, the function must sort along the last axis. Default: <code>-1</code>.</p> <code>-1</code> <code>descending</code> <code>bool_</code> <p>Sort order. If <code>True</code>, the array must be sorted in descending order (by value). If <code>False</code>, the array must be sorted in ascending order (by value). Default: <code>False</code>.</p> <code>False</code> <code>stable</code> <code>bool_</code> <p>Whether the sort is stable. Only <code>False</code> is supported currently.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>out</code> <code>COO</code> <p>A sorted array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input array isn't and can't be converted to COO format.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.COO.from_numpy([1, 0, 2, 0, 2, -3])\n&gt;&gt;&gt; sparse.sort(x).todense()\narray([-3, 0, 0, 1, 2, 2])\n&gt;&gt;&gt; sparse.sort(x, descending=True).todense()\narray([ 2, 2, 1, 0, 0, -3])\n</code></pre> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def sort(x, /, *, axis=-1, descending=False, stable=False):\n    \"\"\"\n    Returns a sorted copy of an input array ``x``.\n\n    Parameters\n    ----------\n    x : SparseArray\n        Input array. Should have a real-valued data type.\n    axis : int\n        Axis along which to sort. If set to ``-1``, the function must sort along\n        the last axis. Default: ``-1``.\n    descending : bool\n        Sort order. If ``True``, the array must be sorted in descending order (by value).\n        If ``False``, the array must be sorted in ascending order (by value).\n        Default: ``False``.\n    stable : bool\n        Whether the sort is stable. Only ``False`` is supported currently.\n\n    Returns\n    -------\n    out : COO\n        A sorted array.\n\n    Raises\n    ------\n    ValueError\n        If the input array isn't and can't be converted to COO format.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.COO.from_numpy([1, 0, 2, 0, 2, -3])\n    &gt;&gt;&gt; sparse.sort(x).todense()\n    array([-3, 0, 0, 1, 2, 2])\n    &gt;&gt;&gt; sparse.sort(x, descending=True).todense()\n    array([ 2, 2, 1, 0, 0, -3])\n\n    \"\"\"\n    from .._common import moveaxis\n    from .core import COO\n\n    x = _validate_coo_input(x)\n\n    if stable:\n        raise ValueError(\"`stable=True` isn't currently supported.\")\n\n    original_ndim = x.ndim\n    if x.ndim == 1:\n        x = x[None, :]\n        axis = -1\n\n    x = moveaxis(x, source=axis, destination=-1)\n    x_shape = x.shape\n    x = x.reshape((-1, x_shape[-1]))\n\n    new_coords, new_data = _sort_coo(x.coords, x.data, x.fill_value, sort_axis_len=x_shape[-1], descending=descending)\n\n    x = COO(new_coords, new_data, x.shape, has_duplicates=False, sorted=True, fill_value=x.fill_value)\n\n    x = x.reshape(x_shape[:-1] + (x_shape[-1],))\n    x = moveaxis(x, source=-1, destination=axis)\n\n    return x if original_ndim == x.ndim else x.squeeze()\n</code></pre>"},{"location":"api/squeeze/","title":"squeeze","text":"<p>Remove singleton dimensions from array.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>Input array.</p> required <code>axis</code> <code>int or tuple[int, ...]</code> <p>The singleton axes to remove. By default all singleton axes are removed.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>output</code> <code>SparseArray</code> <p>Array with singleton dimensions removed.</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>@_support_numpy\ndef squeeze(x, /, axis=None):\n    \"\"\"Remove singleton dimensions from array.\n\n    Parameters\n    ----------\n    x : SparseArray\n        Input array.\n    axis : int or tuple[int, ...], optional\n        The singleton axes to remove. By default all singleton axes are removed.\n\n    Returns\n    -------\n    output : SparseArray\n        Array with singleton dimensions removed.\n    \"\"\"\n    return x.squeeze(axis=axis)\n</code></pre>"},{"location":"api/stack/","title":"stack","text":"<p>Stack the input arrays along the given dimension.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[SparseArray]</code> <p>The input arrays to stack.</p> required <code>axis</code> <code>int</code> <p>The axis along which to stack the input arrays.</p> <code>0</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> <code>None</code> <p>Returns:</p> Type Description <code>SparseArray</code> <p>The output stacked array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all elements of :code:<code>arrays</code> don't have the same fill-value.</p> See Also <p>numpy.stack : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def stack(arrays, axis=0, compressed_axes=None):\n    \"\"\"\n    Stack the input arrays along the given dimension.\n\n    Parameters\n    ----------\n    arrays : Iterable[SparseArray]\n        The input arrays to stack.\n    axis : int, optional\n        The axis along which to stack the input arrays.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n\n    Returns\n    -------\n    SparseArray\n        The output stacked array.\n\n    Raises\n    ------\n    ValueError\n        If all elements of :code:`arrays` don't have the same fill-value.\n\n    See Also\n    --------\n    numpy.stack : NumPy equivalent function\n    \"\"\"\n    from ._compressed import GCXS\n\n    if not builtins.all(isinstance(arr, GCXS) for arr in arrays):\n        from ._coo import stack as coo_stack\n\n        return coo_stack(arrays, axis)\n\n    from ._compressed import stack as gcxs_stack\n\n    return gcxs_stack(arrays, axis, compressed_axes)\n</code></pre>"},{"location":"api/std/","title":"std","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def std(x, /, *, axis=None, correction=0.0, keepdims=False):\n    return x.std(axis=axis, ddof=correction, keepdims=keepdims)\n</code></pre>"},{"location":"api/sum/","title":"sum","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def sum(x, /, *, axis=None, dtype=None, keepdims=False):\n    return x.sum(axis=axis, keepdims=keepdims, dtype=dtype)\n</code></pre>"},{"location":"api/take/","title":"take","text":"<p>Returns elements of an array along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>SparseArray</code> <p>Input array.</p> required <code>indices</code> <code>ndarray</code> <p>Array indices. The array must be one-dimensional and have an integer data type.</p> required <code>axis</code> <code>int</code> <p>Axis over which to select values. If <code>axis</code> is negative, the function must determine the axis along which to select values by counting from the last dimension. For <code>None</code>, the flattened input array is used. Default: <code>None</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>COO</code> <p>A COO array with requested indices.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input array isn't and can't be converted to COO format.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def take(x, indices, /, *, axis=None):\n    \"\"\"\n    Returns elements of an array along an axis.\n\n    Parameters\n    ----------\n    x : SparseArray\n        Input array.\n    indices : ndarray\n        Array indices. The array must be one-dimensional and have an integer data type.\n    axis : int\n        Axis over which to select values. If ``axis`` is negative, the function must\n        determine the axis along which to select values by counting from the last dimension.\n        For ``None``, the flattened input array is used. Default: ``None``.\n\n    Returns\n    -------\n    out : COO\n        A COO array with requested indices.\n\n    Raises\n    ------\n    ValueError\n        If the input array isn't and can't be converted to COO format.\n    \"\"\"\n\n    x = _validate_coo_input(x)\n\n    if axis is None:\n        x = x.flatten()\n        return x[indices]\n\n    axis = normalize_axis(axis, x.ndim)\n    full_index = (slice(None),) * axis + (indices, ...)\n    return x[full_index]\n</code></pre>"},{"location":"api/tensordot/","title":"tensordot","text":"<p>Perform the equivalent of :obj:<code>numpy.tensordot</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[SparseArray, ndarray, spmatrix]</code> <p>The arrays to perform the :code:<code>tensordot</code> operation on.</p> required <code>b</code> <code>Union[SparseArray, ndarray, spmatrix]</code> <p>The arrays to perform the :code:<code>tensordot</code> operation on.</p> required <code>axes</code> <code>tuple[Union[int, tuple[int], Union[int, tuple[int]]</code> <p>The axes to match when performing the sum.</p> <code>2</code> <code>return_type</code> <code>(None, COO, ndarray)</code> <p>Type of returned array.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[SparseArray, ndarray]</code> <p>The result of the operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all arguments don't have zero fill-values.</p> See Also <p>numpy.tensordot : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def tensordot(a, b, axes=2, *, return_type=None):\n    \"\"\"\n    Perform the equivalent of :obj:`numpy.tensordot`.\n\n    Parameters\n    ----------\n    a, b : Union[SparseArray, np.ndarray, scipy.sparse.spmatrix]\n        The arrays to perform the :code:`tensordot` operation on.\n    axes : tuple[Union[int, tuple[int], Union[int, tuple[int]], optional\n        The axes to match when performing the sum.\n    return_type : {None, COO, np.ndarray}, optional\n        Type of returned array.\n\n    Returns\n    -------\n    Union[SparseArray, numpy.ndarray]\n        The result of the operation.\n\n    Raises\n    ------\n    ValueError\n        If all arguments don't have zero fill-values.\n\n    See Also\n    --------\n    numpy.tensordot : NumPy equivalent function\n    \"\"\"\n    from ._compressed import GCXS\n\n    # Much of this is stolen from numpy/core/numeric.py::tensordot\n    # Please see license at https://github.com/numpy/numpy/blob/main/LICENSE.txt\n    check_zero_fill_value(a, b)\n\n    if _is_scipy_sparse_obj(a):\n        a = GCXS.from_scipy_sparse(a)\n    if _is_scipy_sparse_obj(b):\n        b = GCXS.from_scipy_sparse(b)\n\n    try:\n        iter(axes)\n    except TypeError:\n        axes_a = list(range(-axes, 0))\n        axes_b = list(range(axes))\n    else:\n        axes_a, axes_b = axes\n    try:\n        na = len(axes_a)\n        axes_a = list(axes_a)\n    except TypeError:\n        axes_a = [axes_a]\n        na = 1\n    try:\n        nb = len(axes_b)\n        axes_b = list(axes_b)\n    except TypeError:\n        axes_b = [axes_b]\n        nb = 1\n\n    # a, b = asarray(a), asarray(b)  # &lt;--- modified\n    as_ = a.shape\n    nda = a.ndim\n    bs = b.shape\n    ndb = b.ndim\n    equal = True\n    if nda == 0 or ndb == 0:\n        pos = int(nda != 0)\n        raise ValueError(f\"Input {pos} operand does not have enough dimensions\")\n    if na != nb:\n        equal = False\n    else:\n        for k in range(na):\n            if as_[axes_a[k]] != bs[axes_b[k]]:\n                equal = False\n                break\n            if axes_a[k] &lt; 0:\n                axes_a[k] += nda\n            if axes_b[k] &lt; 0:\n                axes_b[k] += ndb\n    if not equal:\n        raise ValueError(\"shape-mismatch for sum\")\n\n    # Move the axes to sum over to the end of \"a\"\n    # and to the front of \"b\"\n    notin = [k for k in range(nda) if k not in axes_a]\n    newaxes_a = notin + axes_a\n    N2 = 1\n    for axis in axes_a:\n        N2 *= as_[axis]\n    newshape_a = (-1, N2)\n    olda = [as_[axis] for axis in notin]\n\n    notin = [k for k in range(ndb) if k not in axes_b]\n    newaxes_b = axes_b + notin\n    N2 = 1\n    for axis in axes_b:\n        N2 *= bs[axis]\n    newshape_b = (N2, -1)\n    oldb = [bs[axis] for axis in notin]\n\n    if builtins.any(dim == 0 for dim in chain(newshape_a, newshape_b)):\n        res = asCOO(np.empty(olda + oldb), check=False)\n        if isinstance(a, np.ndarray) or isinstance(b, np.ndarray):\n            res = res.todense()\n\n        return res\n\n    at = a.transpose(newaxes_a).reshape(newshape_a)\n    bt = b.transpose(newaxes_b).reshape(newshape_b)\n    res = _dot(at, bt, return_type)\n    return res.reshape(olda + oldb)\n</code></pre>"},{"location":"api/tril/","title":"tril","text":"<p>Returns an array with all elements above the k-th diagonal set to zero.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>COO</code> <p>The input array.</p> required <code>k</code> <code>int</code> <p>The diagonal above which elements are set to zero. The default is zero, which corresponds to the main diagonal.</p> <code>0</code> <p>Returns:</p> Type Description <code>COO</code> <p>The output lower-triangular matrix.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If :code:<code>x</code> doesn't have zero fill-values.</p> See Also <p>numpy.tril : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def tril(x, k=0):\n    \"\"\"\n    Returns an array with all elements above the k-th diagonal set to zero.\n\n    Parameters\n    ----------\n    x : COO\n        The input array.\n    k : int, optional\n        The diagonal above which elements are set to zero. The default is\n        zero, which corresponds to the main diagonal.\n\n    Returns\n    -------\n    COO\n        The output lower-triangular matrix.\n\n    Raises\n    ------\n    ValueError\n        If :code:`x` doesn't have zero fill-values.\n\n    See Also\n    --------\n    numpy.tril : NumPy equivalent function\n    \"\"\"\n    from .core import COO\n\n    check_zero_fill_value(x)\n\n    if not x.ndim &gt;= 2:\n        raise NotImplementedError(\"sparse.tril is not implemented for scalars or 1-D arrays.\")\n\n    mask = x.coords[-2] + k &gt;= x.coords[-1]\n\n    coords = x.coords[:, mask]\n    data = x.data[mask]\n\n    return COO(coords, data, shape=x.shape, has_duplicates=False, sorted=True)\n</code></pre>"},{"location":"api/triu/","title":"triu","text":"<p>Returns an array with all elements below the k-th diagonal set to zero.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>COO</code> <p>The input array.</p> required <code>k</code> <code>int</code> <p>The diagonal below which elements are set to zero. The default is zero, which corresponds to the main diagonal.</p> <code>0</code> <p>Returns:</p> Type Description <code>COO</code> <p>The output upper-triangular matrix.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If :code:<code>x</code> doesn't have zero fill-values.</p> See Also <p>numpy.triu : NumPy equivalent function</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def triu(x, k=0):\n    \"\"\"\n    Returns an array with all elements below the k-th diagonal set to zero.\n\n    Parameters\n    ----------\n    x : COO\n        The input array.\n    k : int, optional\n        The diagonal below which elements are set to zero. The default is\n        zero, which corresponds to the main diagonal.\n\n    Returns\n    -------\n    COO\n        The output upper-triangular matrix.\n\n    Raises\n    ------\n    ValueError\n        If :code:`x` doesn't have zero fill-values.\n\n    See Also\n    --------\n    numpy.triu : NumPy equivalent function\n    \"\"\"\n    from .core import COO\n\n    check_zero_fill_value(x)\n\n    if not x.ndim &gt;= 2:\n        raise NotImplementedError(\"sparse.triu is not implemented for scalars or 1-D arrays.\")\n\n    mask = x.coords[-2] + k &lt;= x.coords[-1]\n\n    coords = x.coords[:, mask]\n    data = x.data[mask]\n\n    return COO(coords, data, shape=x.shape, has_duplicates=False, sorted=True)\n</code></pre>"},{"location":"api/unique_counts/","title":"unique_counts","text":"<p>Returns the unique elements of an input array <code>x</code>, and the corresponding counts for each unique element in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>COO</code> <p>Input COO array. It will be flattened if it is not already 1-D.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>namedtuple</code> <p>The result containing: * values - The unique elements of an input array. * counts - The corresponding counts for each unique element.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input array is in a different format than COO.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.COO.from_numpy([1, 0, 2, 1, 2, -3])\n&gt;&gt;&gt; sparse.unique_counts(x)\nUniqueCountsResult(values=array([-3,  0,  1,  2]), counts=array([1, 1, 2, 2]))\n</code></pre> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def unique_counts(x, /):\n    \"\"\"\n    Returns the unique elements of an input array `x`, and the corresponding\n    counts for each unique element in `x`.\n\n    Parameters\n    ----------\n    x : COO\n        Input COO array. It will be flattened if it is not already 1-D.\n\n    Returns\n    -------\n    out : namedtuple\n        The result containing:\n        * values - The unique elements of an input array.\n        * counts - The corresponding counts for each unique element.\n\n    Raises\n    ------\n    ValueError\n        If the input array is in a different format than COO.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.COO.from_numpy([1, 0, 2, 1, 2, -3])\n    &gt;&gt;&gt; sparse.unique_counts(x)\n    UniqueCountsResult(values=array([-3,  0,  1,  2]), counts=array([1, 1, 2, 2]))\n    \"\"\"\n\n    x = _validate_coo_input(x)\n\n    x = x.flatten()\n    values, counts = np.unique(x.data, return_counts=True)\n    if x.nnz &lt; x.size:\n        values = np.concatenate([[x.fill_value], values])\n        counts = np.concatenate([[x.size - x.nnz], counts])\n        sorted_indices = np.argsort(values)\n        values[sorted_indices] = values.copy()\n        counts[sorted_indices] = counts.copy()\n\n    return UniqueCountsResult(values, counts)\n</code></pre>"},{"location":"api/unique_values/","title":"unique_values","text":"<p>Returns the unique elements of an input array <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>COO</code> <p>Input COO array. It will be flattened if it is not already 1-D.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>The unique elements of an input array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input array is in a different format than COO.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sparse\n&gt;&gt;&gt; x = sparse.COO.from_numpy([1, 0, 2, 1, 2, -3])\n&gt;&gt;&gt; sparse.unique_values(x)\narray([-3, 0, 1, 2])\n</code></pre> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def unique_values(x, /):\n    \"\"\"\n    Returns the unique elements of an input array `x`.\n\n    Parameters\n    ----------\n    x : COO\n        Input COO array. It will be flattened if it is not already 1-D.\n\n    Returns\n    -------\n    out : ndarray\n        The unique elements of an input array.\n\n    Raises\n    ------\n    ValueError\n        If the input array is in a different format than COO.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import sparse\n    &gt;&gt;&gt; x = sparse.COO.from_numpy([1, 0, 2, 1, 2, -3])\n    &gt;&gt;&gt; sparse.unique_values(x)\n    array([-3, 0, 1, 2])\n    \"\"\"\n\n    x = _validate_coo_input(x)\n\n    x = x.flatten()\n    values = np.unique(x.data)\n    if x.nnz &lt; x.size:\n        values = np.sort(np.concatenate([[x.fill_value], values]))\n    return values\n</code></pre>"},{"location":"api/var/","title":"var","text":"Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def var(x, /, *, axis=None, correction=0.0, keepdims=False):\n    return x.var(axis=axis, ddof=correction, keepdims=keepdims)\n</code></pre>"},{"location":"api/vecdot/","title":"vecdot","text":"<p>Computes the (vector) dot product of two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>array_like</code> <p>Input sparse arrays</p> required <code>x2</code> <code>array_like</code> <p>Input sparse arrays</p> required <code>axis</code> <code>int</code> <p>The axis to reduce over.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>out</code> <code>Union[SparseArray, ndarray]</code> <p>Sparse or 0-D array containing dot product.</p> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def vecdot(x1, x2, /, *, axis=-1):\n    \"\"\"\n    Computes the (vector) dot product of two arrays.\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n        Input sparse arrays\n    axis : int\n        The axis to reduce over.\n\n    Returns\n    -------\n    out : Union[SparseArray, numpy.ndarray]\n        Sparse or 0-D array containing dot product.\n    \"\"\"\n    ndmin = builtins.min((x1.ndim, x2.ndim))\n    if not (-ndmin &lt;= axis &lt; ndmin) or x1.shape[axis] != x2.shape[axis]:\n        raise ValueError(\"Shapes must match along `axis`.\")\n\n    if np.issubdtype(x1.dtype, np.complexfloating):\n        x1 = np.conjugate(x1)\n\n    return np.sum(x1 * x2, axis=axis)\n</code></pre>"},{"location":"api/where/","title":"where","text":"<p>Select values from either <code>x</code> or <code>y</code> depending on <code>condition</code>. If <code>x</code> and <code>y</code> are not given, returns indices where <code>condition</code> is nonzero.</p> <p>Performs the equivalent of :obj:<code>numpy.where</code>.</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>SparseArray</code> <p>The condition based on which to select values from either <code>x</code> or <code>y</code>.</p> required <code>x</code> <code>SparseArray</code> <p>The array to select values from if <code>condition</code> is nonzero.</p> <code>None</code> <code>y</code> <code>SparseArray</code> <p>The array to select values from if <code>condition</code> is zero.</p> <code>None</code> <p>Returns:</p> Type Description <code>COO</code> <p>The output array with selected values if <code>x</code> and <code>y</code> are given; else where the array is nonzero.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the operation would produce a dense result; or exactly one of <code>x</code> and <code>y</code> are given.</p> See Also <p>numpy.where : Equivalent Numpy function.</p> Source code in <code>sparse/numba_backend/_coo/common.py</code> <pre><code>def where(condition, x=None, y=None):\n    \"\"\"\n    Select values from either ``x`` or ``y`` depending on ``condition``.\n    If ``x`` and ``y`` are not given, returns indices where ``condition``\n    is nonzero.\n\n    Performs the equivalent of :obj:`numpy.where`.\n\n    Parameters\n    ----------\n    condition : SparseArray\n        The condition based on which to select values from\n        either ``x`` or ``y``.\n    x : SparseArray, optional\n        The array to select values from if ``condition`` is nonzero.\n    y : SparseArray, optional\n        The array to select values from if ``condition`` is zero.\n\n    Returns\n    -------\n    COO\n        The output array with selected values if ``x`` and ``y`` are given;\n        else where the array is nonzero.\n\n    Raises\n    ------\n    ValueError\n        If the operation would produce a dense result; or exactly one of\n        ``x`` and ``y`` are given.\n\n    See Also\n    --------\n    numpy.where : Equivalent Numpy function.\n    \"\"\"\n    from .._umath import elemwise\n\n    x_given = x is not None\n    y_given = y is not None\n\n    if not (x_given or y_given):\n        check_zero_fill_value(condition)\n        condition = asCOO(condition, name=str(np.where))\n        return tuple(condition.coords)\n\n    if x_given != y_given:\n        raise ValueError(\"either both or neither of x and y should be given\")\n\n    return elemwise(np.where, condition, x, y)\n</code></pre>"},{"location":"api/zeros/","title":"zeros","text":"<p>Return a SparseArray of given shape and type, filled with zeros.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>int or tuple of ints</code> <p>Shape of the new array, e.g., <code>(2, 3)</code> or <code>2</code>.</p> required <code>dtype</code> <code>data - type</code> <p>The desired data-type for the array, e.g., <code>numpy.int8</code>.  Default is <code>numpy.float64</code>.</p> <code>float</code> <code>format</code> <code>str</code> <p>A format string.</p> <code>'coo'</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>Array of zeros with the given shape and dtype.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zeros(5).todense()\narray([0., 0., 0., 0., 0.])\n</code></pre> <pre><code>&gt;&gt;&gt; zeros((2, 2), dtype=int).todense()\narray([[0, 0],\n       [0, 0]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def zeros(shape, dtype=float, format=\"coo\", *, device=None, **kwargs):\n    \"\"\"Return a SparseArray of given shape and type, filled with zeros.\n\n    Parameters\n    ----------\n    shape : int or tuple of ints\n        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n    dtype : data-type, optional\n        The desired data-type for the array, e.g., `numpy.int8`.  Default is\n        `numpy.float64`.\n    format : str, optional\n        A format string.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n\n    Returns\n    -------\n    out : SparseArray\n        Array of zeros with the given shape and dtype.\n\n    Examples\n    --------\n    &gt;&gt;&gt; zeros(5).todense()  # doctest: +SKIP\n    array([0., 0., 0., 0., 0.])\n\n    &gt;&gt;&gt; zeros((2, 2), dtype=int).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[0, 0],\n           [0, 0]])\n    \"\"\"\n    return full(shape, fill_value=0, dtype=np.dtype(dtype), format=format, device=device, **kwargs)\n</code></pre>"},{"location":"api/zeros_like/","title":"zeros_like","text":"<p>Return a SparseArray of zeros with the same shape and type as <code>a</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>The shape and data-type of the result will match those of <code>a</code>.</p> required <code>dtype</code> <code>data - type</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>format</code> <code>str</code> <p>A format string.</p> <code>None</code> <code>compressed_axes</code> <code>iterable</code> <p>The axes to compress if returning a GCXS array.</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>SparseArray</code> <p>Array of zeros with the same shape and type as <code>a</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.ones((2, 3), dtype=\"i8\")\n&gt;&gt;&gt; zeros_like(x).todense()\narray([[0, 0, 0],\n       [0, 0, 0]])\n</code></pre> Source code in <code>sparse/numba_backend/_common.py</code> <pre><code>def zeros_like(a, dtype=None, shape=None, format=None, *, device=None, **kwargs):\n    \"\"\"Return a SparseArray of zeros with the same shape and type as ``a``.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of the result will match those of `a`.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n    format : str, optional\n        A format string.\n    compressed_axes : iterable, optional\n        The axes to compress if returning a GCXS array.\n\n    Returns\n    -------\n    out : SparseArray\n        Array of zeros with the same shape and type as `a`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.ones((2, 3), dtype=\"i8\")\n    &gt;&gt;&gt; zeros_like(x).todense()  # doctest: +NORMALIZE_WHITESPACE\n    array([[0, 0, 0],\n           [0, 0, 0]])\n    \"\"\"\n    return full_like(a, fill_value=0, dtype=dtype, shape=shape, format=format, device=device, **kwargs)\n</code></pre>"}]}